{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df726742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m pip install \"gymnasium[atari]\"\n",
    "# !python -m pip install \"gymnasium[accept-rom-license, atari]\"\n",
    "# !pip install shimmy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "567e4d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import gymnasium as gym\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "import ale_py\n",
    "import shimmy\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "from gym import wrappers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b7597b",
   "metadata": {},
   "source": [
    "| **Value** | **Meaning** |\n",
    "|:---------:|:-----------:|\n",
    "| 0 | NOOP |\n",
    "| 1 | FIRE |\n",
    "| 2 | RIGHT |\n",
    "| 3 | LEFT |\n",
    "| 4 | RIGHTFIRE |\n",
    "| 5 | LEFTFIRE |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0baec494",
   "metadata": {},
   "source": [
    "# General Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28496867",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_obs(obs):\n",
    "    \"\"\" \n",
    "    Simple display of image observation \n",
    "    \n",
    "    Args:\n",
    "    `obs` : np.ndarray\n",
    "    - Observation from the environment\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(16,10))\n",
    "    plt.imshow(obs)\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f502cc94",
   "metadata": {},
   "source": [
    "# Policy Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15a4713e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discount_rewards(rewards, gamma=.99):\n",
    "    \"\"\" \n",
    "    Take 1D array of rewards and compute discounted version\n",
    "    Most recent action has the greatest weight \n",
    "    \n",
    "    Args:\n",
    "    `rewards` : np.ndarray\n",
    "    - Observed rewards over time\n",
    "    - ndim : 1\n",
    "    \"\"\"\n",
    "    discounted_rewards = torch.zeros(len(rewards)).double()\n",
    "    running_add = 0\n",
    "    for t in reversed(range(0, len(rewards))):\n",
    "        running_add = running_add * gamma + rewards[t]\n",
    "        discounted_rewards[t] = running_add\n",
    "    return discounted_rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ffbd68",
   "metadata": {},
   "source": [
    "# Run Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e7513bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config flags - video output and res\n",
    "resume = True # resume training from previous checkpoint (from save.p  file)?\n",
    "render = False # render video output?\n",
    "print_ = False # print each observation\n",
    "show = False\n",
    "no_grad = False\n",
    "corner_correct = True\n",
    "\n",
    "timer_i = 1000 # number of iterations without reward before noise is intentionally greater than signal\n",
    "\n",
    "record_probs = True\n",
    "record_rewards = True\n",
    "record_eps_iters = True\n",
    "save_path = 'model.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ead628",
   "metadata": {},
   "source": [
    "# Model Instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc47b8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape: (170, 130)\n",
      "Input Dimensionality: 22100\n"
     ]
    }
   ],
   "source": [
    "OBS_SHAPE = (210, 160)\n",
    "XMIN = 26\n",
    "XMAX = 196\n",
    "YMIN = 14\n",
    "YMAX = 144\n",
    "SHAPE = (XMAX - XMIN, YMAX - YMIN)\n",
    "DOWNSAMPLE = False\n",
    "DIM = np.prod(SHAPE) // 4 if DOWNSAMPLE else np.prod(SHAPE)\n",
    "\n",
    "action_dict = {\n",
    "    0 : 'NOOP',\n",
    "    1 : 'FIRE',\n",
    "    2 : 'RIGHT',\n",
    "    3 : 'LEFT',\n",
    "    4 : 'RIGHTFIRE',\n",
    "    5 : 'LEFTFIRE'\n",
    "}\n",
    "ACTIONS = [0,1,2,3,4,5] # modify to limit available actions\n",
    "N_CLASSES = len(ACTIONS)\n",
    "\n",
    "print('Input Shape:', SHAPE)\n",
    "print('Input Dimensionality:', DIM)\n",
    "\n",
    "def preprocess(obs, downsample=True, xmin=26, xmax=196, ymin=10, ymax=144):\n",
    "    assert obs.shape == (210, 160)\n",
    "    I = obs[xmin:xmax,ymin:ymax] # crop - remove 35px from start & 25px from end of image in x, to reduce redundant parts of image (i.e. after ball passes paddle)\n",
    "    if downsample:\n",
    "        I = I[::2,:]\n",
    "    I[I == 144] = 0 # erase background (background type 1)\n",
    "    I[I == 109] = 0 # erase background (background type 2)\n",
    "    I[I != 0] = 1 # everything else to 1\n",
    "    return I.astype(np.float32).ravel() # ravel flattens an array and collapses it into a column vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8576d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_x = None # used in computing the difference frame\n",
    "# xs, hs, dlogps, drs = list(), list(), list(), list()\n",
    "dlogps, drs = list(), list()\n",
    "running_reward = None\n",
    "\n",
    "reward_sum = 0\n",
    "adj_reward_sum = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15faaca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(probs, i, i_since_r, timer_i, buffer=None, print_=False):\n",
    "    if buffer is None:\n",
    "        buffer = timer_i // 2\n",
    "    n = len(probs)\n",
    "    sigma = 2 / n\n",
    "    noise = np.random.normal(0, sigma, size=n)\n",
    "    noise = noise - np.mean(noise)\n",
    "    \n",
    "    scale = i_since_r / (timer_i - buffer)\n",
    "    noise = noise * scale\n",
    "    assert not round(np.mean(noise), 3), noise\n",
    "    if print_ and not i % 100:\n",
    "        print(probs)\n",
    "        print(noise)\n",
    "    new_probs = probs.detach().numpy() + noise\n",
    "    pmin = np.amin(new_probs)\n",
    "    if pmin < 0:\n",
    "        new_probs -= pmin\n",
    "        new_probs /= np.sum(new_probs)\n",
    "    new_probs = torch.from_numpy(new_probs)\n",
    "    return new_probs\n",
    "\n",
    "def balance_lr(probs, i_since_r, timer_i, buffer=None):\n",
    "#    ACTIONS = [NOOP,1,2,3,4,5]\n",
    "    if i_since_r < timer_i // 4:\n",
    "        pass\n",
    "    elif i_since_r < timer_i // 2:\n",
    "        equal_n = (probs[2] + probs[3]) / 2\n",
    "        equal_y = (probs[4] + probs[5]) / 2\n",
    "        probs[2] = equal_n\n",
    "        probs[3] = equal_n\n",
    "        probs[4] = equal_y\n",
    "        probs[5] = equal_y\n",
    "    elif i_since_r < 3 * timer_i // 4:\n",
    "        probs[2], probs[3] = probs[3], probs[2]\n",
    "        probs[4], probs[5] = probs[5], probs[4]\n",
    "    return probs\n",
    "    \n",
    "def modify_reward(action, reward, info, prev_lives):\n",
    "    if info['lives'] < prev_lives:\n",
    "        reward -= 15\n",
    "    if reward <= 0 and action in [1,4,5]:\n",
    "        reward -= 1\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5295c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class AtariReward(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AtariReward, self).__init__()\n",
    "\n",
    "    def forward(self, reward):\n",
    "        if isinstance(reward, np.ndarray):\n",
    "            reward = torch.from_numpy(reward)\n",
    "        loss = -reward       \n",
    "        return loss\n",
    "\n",
    "class TwoLayerReinforcement(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(TwoLayerReinforcement, self).__init__()\n",
    "        \n",
    "        self.log_probss = list()\n",
    "        self.rewards = list()\n",
    "        \n",
    "        self.layer1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        return\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.from_numpy(x).double()\n",
    "        x = self.layer1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.layer2(x)\n",
    "#         probs = self.softmax(x)\n",
    "        print(x)\n",
    "        probs = torch.nn.functional.softmax(x, dim=0)\n",
    "        print(probs)\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc7f00dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1026,  0.1316,  0.0839,  0.0355,  0.0153,  0.0877],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1439, 0.1818, 0.1733, 0.1651, 0.1619, 0.1740], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1\n",
      "1\n",
      "Episode 0 of 100 episodes                \r",
      "tensor([-0.0988,  0.1389,  0.0636,  0.0234,  0.0628,  0.0795],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1440, 0.1826, 0.1694, 0.1627, 0.1692, 0.1721], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "2\n",
      "2\n",
      "tensor([-0.1066,  0.1261,  0.0540,  0.0224,  0.0720,  0.0877],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1432, 0.1807, 0.1681, 0.1629, 0.1712, 0.1739], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "3\n",
      "3\n",
      "tensor([-0.0949,  0.1326,  0.0547,  0.0230,  0.0710,  0.0890],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1444, 0.1813, 0.1677, 0.1625, 0.1705, 0.1736], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "4\n",
      "4\n",
      "tensor([-0.0925,  0.1304,  0.0483,  0.0218,  0.0663,  0.0776],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1454, 0.1817, 0.1673, 0.1630, 0.1704, 0.1723], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "5\n",
      "5\n",
      "tensor([-0.1060,  0.1331,  0.0618,  0.0300,  0.0568,  0.1018],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1427, 0.1813, 0.1688, 0.1635, 0.1680, 0.1757], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "6\n",
      "6\n",
      "tensor([-0.1201,  0.1306,  0.0350,  0.0322,  0.0446,  0.0963],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1421, 0.1826, 0.1659, 0.1655, 0.1675, 0.1764], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "7\n",
      "7\n",
      "tensor([-0.0918,  0.1314,  0.0694,  0.0242,  0.0849,  0.1076],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1436, 0.1796, 0.1688, 0.1613, 0.1714, 0.1753], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "8\n",
      "8\n",
      "tensor([-0.0767,  0.1525,  0.0624,  0.0290,  0.0647,  0.0532],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1469, 0.1847, 0.1688, 0.1632, 0.1692, 0.1672], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "9\n",
      "9\n",
      "tensor([-0.0819,  0.1290,  0.0576,  0.0390,  0.0461,  0.1008],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1460, 0.1803, 0.1678, 0.1647, 0.1659, 0.1752], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "10\n",
      "10\n",
      "tensor([-0.1075,  0.1334,  0.0576,  0.0242,  0.0625,  0.1337],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1418, 0.1805, 0.1673, 0.1618, 0.1681, 0.1805], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "11\n",
      "11\n",
      "tensor([-0.0916,  0.1403,  0.0616,  0.0056,  0.0647,  0.1035],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1446, 0.1824, 0.1686, 0.1594, 0.1691, 0.1758], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "12\n",
      "12\n",
      "tensor([-0.0970,  0.1276,  0.0438,  0.0089,  0.0613,  0.0704],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1456, 0.1823, 0.1676, 0.1619, 0.1706, 0.1721], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "13\n",
      "13\n",
      "tensor([-0.0945,  0.1218,  0.0733,  0.0345,  0.0756,  0.0994],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1437, 0.1783, 0.1699, 0.1634, 0.1703, 0.1744], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "14\n",
      "14\n",
      "tensor([-0.0987,  0.1322,  0.0467,  0.0406,  0.0450,  0.1005],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1441, 0.1815, 0.1666, 0.1656, 0.1663, 0.1758], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "15\n",
      "15\n",
      "tensor([-0.0912,  0.1277,  0.0473,  0.0387,  0.0740,  0.0994],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1445, 0.1798, 0.1659, 0.1645, 0.1704, 0.1748], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "16\n",
      "16\n",
      "tensor([-0.0788,  0.1258,  0.0711,  0.0311,  0.0576,  0.0912],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1463, 0.1795, 0.1699, 0.1633, 0.1677, 0.1734], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "17\n",
      "17\n",
      "tensor([-0.0917,  0.1491,  0.0472,  0.0528,  0.0465,  0.0858],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1445, 0.1839, 0.1661, 0.1670, 0.1659, 0.1726], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "18\n",
      "18\n",
      "tensor([-0.1132,  0.1226,  0.0541,  0.0301,  0.0781,  0.1028],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1418, 0.1795, 0.1676, 0.1636, 0.1717, 0.1759], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "19\n",
      "19\n",
      "tensor([-0.0918,  0.1259,  0.0775,  0.0344,  0.0614,  0.0857],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1445, 0.1796, 0.1711, 0.1639, 0.1684, 0.1725], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "20\n",
      "20\n",
      "tensor([-0.1172,  0.1216,  0.0654,  0.0179,  0.0477,  0.1044],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1420, 0.1803, 0.1704, 0.1626, 0.1675, 0.1772], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "21\n",
      "21\n",
      "tensor([-0.0748,  0.1404,  0.0591,  0.0283,  0.0662,  0.0941],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1465, 0.1816, 0.1675, 0.1624, 0.1687, 0.1734], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "22\n",
      "22\n",
      "tensor([-0.1282,  0.1490,  0.0617,  0.0377,  0.0454,  0.0835],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1402, 0.1849, 0.1695, 0.1655, 0.1667, 0.1732], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "23\n",
      "23\n",
      "tensor([-0.0950,  0.1312,  0.0572,  0.0298,  0.0383,  0.1127],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1444, 0.1811, 0.1682, 0.1636, 0.1650, 0.1777], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "24\n",
      "24\n",
      "tensor([-0.0911,  0.1550,  0.0941,  0.0669,  0.0475,  0.0683],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1434, 0.1834, 0.1725, 0.1679, 0.1647, 0.1681], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "25\n",
      "25\n",
      "tensor([-0.0895,  0.1340,  0.0484, -0.0108,  0.0424,  0.1056],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1463, 0.1829, 0.1679, 0.1583, 0.1669, 0.1778], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "26\n",
      "26\n",
      "tensor([-0.1353,  0.1320,  0.0629,  0.0786,  0.0469,  0.0929],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1385, 0.1809, 0.1689, 0.1715, 0.1662, 0.1740], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "27\n",
      "27\n",
      "tensor([-0.0888,  0.1362,  0.0685,  0.0425,  0.0670,  0.0961],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1442, 0.1806, 0.1688, 0.1644, 0.1685, 0.1735], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "28\n",
      "28\n",
      "tensor([-0.0878,  0.1231,  0.0526,  0.0072,  0.0417,  0.1052],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1463, 0.1806, 0.1683, 0.1609, 0.1665, 0.1774], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "29\n",
      "29\n",
      "tensor([-0.0974,  0.1309,  0.0417,  0.0439,  0.0700,  0.0897],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1440, 0.1809, 0.1655, 0.1658, 0.1702, 0.1736], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "30\n",
      "30\n",
      "tensor([-0.1030,  0.1500,  0.0748,  0.0260,  0.0381,  0.1040],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1428, 0.1839, 0.1706, 0.1625, 0.1645, 0.1757], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "31\n",
      "31\n",
      "tensor([-0.0781,  0.1494,  0.0382,  0.0214,  0.0831,  0.1047],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1458, 0.1830, 0.1638, 0.1611, 0.1713, 0.1750], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "32\n",
      "32\n",
      "tensor([-0.1089,  0.1205,  0.0710,  0.0301,  0.0806,  0.0998],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1420, 0.1785, 0.1699, 0.1631, 0.1716, 0.1749], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "33\n",
      "33\n",
      "tensor([-0.0914,  0.1261,  0.0624,  0.0053,  0.0424,  0.0931],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1459, 0.1813, 0.1701, 0.1607, 0.1667, 0.1754], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "34\n",
      "34\n",
      "tensor([-0.0977,  0.1312,  0.0556,  0.0117,  0.0514,  0.0949],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1447, 0.1819, 0.1686, 0.1614, 0.1679, 0.1754], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "35\n",
      "35\n",
      "tensor([-0.1289,  0.1380,  0.0662,  0.0214,  0.0719,  0.0786],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1401, 0.1830, 0.1703, 0.1628, 0.1713, 0.1724], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "36\n",
      "36\n",
      "tensor([-0.1014,  0.1632,  0.0201,  0.0608,  0.0703,  0.0918],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1427, 0.1859, 0.1611, 0.1678, 0.1694, 0.1731], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "37\n",
      "37\n",
      "tensor([-0.1119,  0.1384,  0.0643,  0.0302,  0.0574,  0.0803],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1423, 0.1828, 0.1697, 0.1641, 0.1686, 0.1725], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "38\n",
      "38\n",
      "tensor([-0.1003,  0.1604,  0.0812,  0.0146,  0.0328,  0.0954],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1433, 0.1860, 0.1718, 0.1608, 0.1637, 0.1743], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "39\n",
      "39\n",
      "tensor([-0.0935,  0.1332,  0.0482,  0.0050,  0.0585,  0.0838],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1456, 0.1826, 0.1678, 0.1607, 0.1695, 0.1738], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "40\n",
      "40\n",
      "tensor([-0.0730,  0.1733,  0.0789,  0.0286,  0.0507,  0.0652],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1464, 0.1873, 0.1704, 0.1621, 0.1657, 0.1681], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "41\n",
      "41\n",
      "tensor([-0.1090,  0.1464,  0.0723,  0.0437,  0.0537,  0.1190],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1411, 0.1821, 0.1691, 0.1644, 0.1660, 0.1772], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "42\n",
      "42\n",
      "tensor([-0.0740,  0.1707,  0.0342,  0.0488,  0.0410,  0.1204],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1458, 0.1862, 0.1625, 0.1648, 0.1636, 0.1771], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "43\n",
      "43\n",
      "tensor([-0.0965,  0.1421,  0.0435,  0.0236,  0.0588,  0.0929],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1444, 0.1834, 0.1661, 0.1629, 0.1687, 0.1745], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "44\n",
      "44\n",
      "tensor([-0.1301,  0.1344,  0.0726,  0.0199,  0.0459,  0.0787],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1406, 0.1831, 0.1722, 0.1633, 0.1676, 0.1732], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "45\n",
      "45\n",
      "tensor([-0.0791,  0.1387,  0.0527,  0.0260,  0.0584,  0.0820],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1467, 0.1824, 0.1673, 0.1629, 0.1683, 0.1723], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "46\n",
      "46\n",
      "tensor([-0.0624,  0.1307,  0.0595,  0.0315,  0.0591,  0.0668],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1491, 0.1808, 0.1684, 0.1637, 0.1683, 0.1696], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "47\n",
      "47\n",
      "tensor([-0.1250,  0.1519,  0.0438,  0.0241,  0.0510,  0.1012],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1406, 0.1855, 0.1665, 0.1633, 0.1677, 0.1763], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "48\n",
      "48\n",
      "tensor([-0.0700,  0.1456,  0.0614,  0.0287,  0.0741,  0.0697],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1473, 0.1827, 0.1680, 0.1626, 0.1701, 0.1694], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "49\n",
      "49\n",
      "tensor([-0.1134,  0.1146,  0.0733,  0.0348,  0.0426,  0.0831],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1427, 0.1793, 0.1720, 0.1655, 0.1668, 0.1737], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "50\n",
      "50\n",
      "tensor([-0.0740,  0.1424,  0.0415,  0.0146,  0.0468,  0.1035],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1475, 0.1831, 0.1656, 0.1612, 0.1664, 0.1762], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "51\n",
      "51\n",
      "tensor([-0.1049,  0.1301,  0.0528,  0.0061,  0.0745,  0.0825],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1438, 0.1819, 0.1683, 0.1606, 0.1720, 0.1734], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "52\n",
      "52\n",
      "tensor([-0.0665,  0.1403,  0.0445,  0.0514,  0.0305,  0.0816],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1485, 0.1826, 0.1659, 0.1671, 0.1636, 0.1722], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "53\n",
      "53\n",
      "tensor([-0.0668,  0.1131,  0.0698,  0.0212,  0.0832,  0.1039],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1474, 0.1765, 0.1690, 0.1610, 0.1713, 0.1749], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "54\n",
      "54\n",
      "tensor([-0.1223,  0.1583,  0.0718,  0.0414,  0.0160,  0.1090],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1404, 0.1858, 0.1704, 0.1653, 0.1612, 0.1769], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "55\n",
      "55\n",
      "tensor([-0.0601,  0.1529,  0.0644,  0.0828,  0.0517,  0.0985],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1468, 0.1816, 0.1662, 0.1693, 0.1641, 0.1720], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "56\n",
      "56\n",
      "tensor([-0.1072,  0.1515,  0.0302,  0.0088,  0.0302,  0.0694],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1448, 0.1876, 0.1661, 0.1626, 0.1661, 0.1728], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "57\n",
      "57\n",
      "tensor([-0.1067,  0.1088,  0.0608,  0.0002,  0.0522,  0.0944],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1443, 0.1790, 0.1706, 0.1606, 0.1691, 0.1764], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "58\n",
      "58\n",
      "tensor([-0.0814,  0.1607,  0.0557,  0.0315,  0.0486,  0.1157],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1450, 0.1847, 0.1663, 0.1623, 0.1651, 0.1766], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "59\n",
      "59\n",
      "tensor([-0.1302,  0.1354,  0.0636,  0.0117,  0.0406,  0.1006],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1405, 0.1833, 0.1706, 0.1619, 0.1667, 0.1770], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "60\n",
      "60\n",
      "tensor([-0.1023,  0.1229,  0.0286,  0.0255,  0.0835,  0.0705],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1445, 0.1810, 0.1647, 0.1642, 0.1740, 0.1717], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "61\n",
      "61\n",
      "tensor([-0.0988,  0.1214,  0.0598,  0.0131,  0.0435,  0.1041],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1446, 0.1802, 0.1695, 0.1617, 0.1667, 0.1772], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "62\n",
      "62\n",
      "tensor([-0.0943,  0.1483,  0.0233,  0.0459,  0.0502,  0.1040],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1444, 0.1841, 0.1624, 0.1661, 0.1669, 0.1761], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "63\n",
      "63\n",
      "tensor([-0.1189,  0.1082,  0.0684,  0.0583,  0.0728,  0.0708],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1413, 0.1774, 0.1705, 0.1687, 0.1712, 0.1709], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "64\n",
      "64\n",
      "tensor([-0.0931,  0.1447,  0.0114,  0.0400,  0.0268,  0.0823],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1462, 0.1854, 0.1623, 0.1670, 0.1648, 0.1742], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "65\n",
      "65\n",
      "tensor([-0.1130,  0.1535,  0.0700,  0.0273,  0.0558,  0.1118],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1410, 0.1840, 0.1693, 0.1622, 0.1669, 0.1765], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "66\n",
      "66\n",
      "tensor([-0.0528,  0.1540,  0.0426,  0.1027,  0.0843,  0.0445],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1482, 0.1823, 0.1631, 0.1731, 0.1700, 0.1634], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "67\n",
      "67\n",
      "tensor([-0.1127,  0.1357,  0.0748,  0.0138,  0.0186,  0.1327],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1420, 0.1821, 0.1713, 0.1612, 0.1619, 0.1815], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "68\n",
      "68\n",
      "tensor([-0.1004,  0.1379,  0.0732, -0.0074,  0.0664,  0.0805],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1442, 0.1830, 0.1715, 0.1582, 0.1704, 0.1728], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "69\n",
      "69\n",
      "tensor([-0.1221,  0.1279,  0.0754,  0.0766,  0.0905,  0.1009],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1387, 0.1781, 0.1690, 0.1692, 0.1716, 0.1734], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n",
      "70\n",
      "tensor([-0.0839,  0.1359,  0.0506,  0.0239,  0.0676,  0.0975],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1456, 0.1815, 0.1666, 0.1622, 0.1695, 0.1746], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "71\n",
      "71\n",
      "tensor([-0.1085,  0.1519,  0.0689,  0.0434,  0.0569,  0.0790],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1420, 0.1843, 0.1696, 0.1653, 0.1676, 0.1713], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "72\n",
      "72\n",
      "tensor([-0.0824,  0.1169,  0.0465,  0.0287,  0.0607,  0.1279],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1457, 0.1778, 0.1657, 0.1628, 0.1681, 0.1798], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "73\n",
      "73\n",
      "tensor([-0.0979,  0.1405,  0.0517,  0.0654,  0.0546,  0.0935],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1432, 0.1817, 0.1663, 0.1686, 0.1668, 0.1734], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "74\n",
      "74\n",
      "tensor([-0.1225,  0.1431,  0.0820,  0.0213,  0.0421,  0.0748],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1412, 0.1841, 0.1732, 0.1630, 0.1664, 0.1720], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "75\n",
      "75\n",
      "tensor([-0.0753,  0.1263,  0.0390,  0.0406,  0.0697,  0.1145],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1464, 0.1791, 0.1641, 0.1643, 0.1692, 0.1770], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "76\n",
      "76\n",
      "tensor([-0.0887,  0.1411,  0.0734, -0.0084,  0.0699,  0.1131],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1446, 0.1820, 0.1701, 0.1567, 0.1695, 0.1770], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "77\n",
      "77\n",
      "tensor([-0.1391,  0.1147,  0.0553,  0.0239,  0.0487,  0.0894],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1400, 0.1804, 0.1700, 0.1648, 0.1689, 0.1759], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "78\n",
      "78\n",
      "tensor([-0.1117,  0.1764,  0.0418,  0.0519,  0.0579,  0.0955],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1410, 0.1881, 0.1644, 0.1661, 0.1671, 0.1734], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "79\n",
      "79\n",
      "tensor([-0.0738,  0.1295,  0.0520,  0.0270,  0.1115,  0.1215],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1453, 0.1780, 0.1647, 0.1607, 0.1748, 0.1766], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "80\n",
      "80\n",
      "tensor([-0.0779,  0.1425,  0.0546,  0.0362,  0.0288,  0.0673],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1475, 0.1839, 0.1684, 0.1654, 0.1641, 0.1706], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "81\n",
      "81\n",
      "tensor([-0.0866,  0.1170,  0.0792,  0.0328,  0.0612,  0.0982],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1450, 0.1778, 0.1712, 0.1634, 0.1681, 0.1745], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "82\n",
      "82\n",
      "tensor([-0.1143,  0.1547,  0.0239,  0.0190,  0.0765,  0.0869],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1422, 0.1861, 0.1633, 0.1625, 0.1721, 0.1739], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "83\n",
      "83\n",
      "tensor([-0.0875,  0.1212,  0.0741,  0.0253,  0.0428,  0.0904],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1458, 0.1796, 0.1713, 0.1632, 0.1660, 0.1741], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "84\n",
      "84\n",
      "tensor([-0.1320,  0.1279,  0.0649,  0.0248,  0.0840,  0.1117],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1389, 0.1801, 0.1691, 0.1624, 0.1723, 0.1772], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "85\n",
      "85\n",
      "tensor([-0.0819,  0.1414,  0.0443,  0.0047,  0.0484,  0.1023],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1467, 0.1834, 0.1664, 0.1600, 0.1671, 0.1764], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "86\n",
      "86\n",
      "tensor([-0.1202,  0.1275,  0.0607,  0.0591,  0.0379,  0.1039],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1409, 0.1805, 0.1688, 0.1685, 0.1650, 0.1763], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "87\n",
      "87\n",
      "tensor([-0.0881,  0.1396,  0.0343,  0.0135,  0.0815,  0.0828],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1457, 0.1829, 0.1647, 0.1613, 0.1726, 0.1728], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "88\n",
      "88\n",
      "tensor([-0.0703,  0.1526,  0.0788,  0.0211,  0.0352,  0.1120],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1467, 0.1833, 0.1703, 0.1607, 0.1630, 0.1760], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "89\n",
      "89\n",
      "tensor([-0.0873,  0.1177,  0.0472,  0.0219,  0.0714,  0.0794],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1462, 0.1795, 0.1672, 0.1631, 0.1713, 0.1727], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "90\n",
      "90\n",
      "tensor([-0.1217,  0.1724,  0.0354,  0.0206,  0.0489,  0.1092],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1406, 0.1887, 0.1645, 0.1621, 0.1668, 0.1772], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "91\n",
      "91\n",
      "tensor([-0.0496,  0.1147,  0.0706,  0.0456,  0.0524,  0.1089],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1496, 0.1763, 0.1687, 0.1645, 0.1656, 0.1753], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "92\n",
      "92\n",
      "tensor([-0.1233,  0.0900,  0.0481,  0.0076,  0.0988,  0.0845],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1420, 0.1757, 0.1685, 0.1618, 0.1773, 0.1748], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "93\n",
      "93\n",
      "tensor([-0.1025,  0.1524,  0.0488,  0.0407,  0.0646,  0.0871],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1429, 0.1844, 0.1662, 0.1649, 0.1689, 0.1727], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "94\n",
      "94\n",
      "tensor([-0.0742,  0.1633,  0.0977,  0.0373,  0.0684,  0.0966],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1447, 0.1834, 0.1718, 0.1617, 0.1668, 0.1716], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "95\n",
      "95\n",
      "tensor([-0.0868,  0.1093,  0.0329,  0.0743,  0.0669,  0.0747],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1458, 0.1774, 0.1643, 0.1713, 0.1700, 0.1713], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "96\n",
      "96\n",
      "tensor([-0.1021,  0.1472,  0.0429,  0.0292,  0.0925,  0.1251],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1418, 0.1820, 0.1640, 0.1618, 0.1723, 0.1780], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "97\n",
      "97\n",
      "tensor([-0.0762,  0.1370,  0.0598,  0.0607,  0.0801,  0.1186],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1446, 0.1790, 0.1657, 0.1658, 0.1691, 0.1757], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "98\n",
      "98\n",
      "tensor([-0.0737,  0.1472,  0.0647,  0.0385,  0.0112,  0.0805],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1477, 0.1842, 0.1696, 0.1652, 0.1608, 0.1723], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "99\n",
      "99\n",
      "tensor([-0.1154,  0.1138,  0.0723,  0.0446,  0.0576,  0.1052],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1414, 0.1778, 0.1706, 0.1659, 0.1681, 0.1763], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "100\n",
      "100\n",
      "tensor([-0.0936,  0.1370,  0.0448,  0.0222,  0.0780,  0.0892],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1445, 0.1820, 0.1660, 0.1623, 0.1716, 0.1735], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "101\n",
      "101\n",
      "Episode 0 of 100 episodes                \r",
      "tensor([-0.0676,  0.1337,  0.0333,  0.0369,  0.0508,  0.0862],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1486, 0.1817, 0.1643, 0.1649, 0.1672, 0.1733], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "102\n",
      "102\n",
      "tensor([-0.0956,  0.1454,  0.0367,  0.0509,  0.0716,  0.0767],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1441, 0.1833, 0.1644, 0.1668, 0.1703, 0.1711], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "103\n",
      "103\n",
      "tensor([-0.1128,  0.1518,  0.0540,  0.0339,  0.0132,  0.1011],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1426, 0.1857, 0.1684, 0.1651, 0.1617, 0.1765], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "104\n",
      "104\n",
      "tensor([-0.0710,  0.1231,  0.0581,  0.0465,  0.0608,  0.0768],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1476, 0.1792, 0.1679, 0.1660, 0.1684, 0.1711], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "105\n",
      "105\n",
      "tensor([-0.0807,  0.1781,  0.0597,  0.0108,  0.0573,  0.1252],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1445, 0.1872, 0.1663, 0.1584, 0.1659, 0.1776], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "106\n",
      "106\n",
      "tensor([-0.1249,  0.1403,  0.0452,  0.0115,  0.0433,  0.0777],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1420, 0.1851, 0.1683, 0.1627, 0.1680, 0.1739], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "107\n",
      "107\n",
      "tensor([-0.1093,  0.1467,  0.0857,  0.0897,  0.0460,  0.1092],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1401, 0.1809, 0.1702, 0.1709, 0.1636, 0.1743], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "108\n",
      "108\n",
      "tensor([-0.0999,  0.1284,  0.0514,  0.0256,  0.0601,  0.0919],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1441, 0.1811, 0.1677, 0.1634, 0.1691, 0.1746], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "109\n",
      "109\n",
      "tensor([-0.0730,  0.1367,  0.0728,  0.0019,  0.0600,  0.0724],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1478, 0.1823, 0.1710, 0.1593, 0.1688, 0.1709], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "110\n",
      "110\n",
      "tensor([-0.1023,  0.1404,  0.0410,  0.1006,  0.0658,  0.1218],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1411, 0.1798, 0.1628, 0.1728, 0.1669, 0.1765], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "111\n",
      "111\n",
      "tensor([-0.0953,  0.1336,  0.0807,  0.0440,  0.0631,  0.1098],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1429, 0.1796, 0.1704, 0.1643, 0.1674, 0.1754], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "112\n",
      "112\n",
      "tensor([-0.1045,  0.1230,  0.0554,  0.0240,  0.0530,  0.0715],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1443, 0.1812, 0.1693, 0.1641, 0.1689, 0.1721], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "113\n",
      "113\n",
      "tensor([-0.0964,  0.1454,  0.0680,  0.0299,  0.0717,  0.1269],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1424, 0.1814, 0.1679, 0.1616, 0.1685, 0.1781], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "114\n",
      "114\n",
      "tensor([-0.0723,  0.1451,  0.0845,  0.0133,  0.0825,  0.0747],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1465, 0.1820, 0.1713, 0.1596, 0.1710, 0.1697], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "115\n",
      "115\n",
      "tensor([-0.1196,  0.1009,  0.0625,  0.0325,  0.0498,  0.1048],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1419, 0.1769, 0.1702, 0.1652, 0.1681, 0.1776], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "116\n",
      "116\n",
      "tensor([-0.1016,  0.1408,  0.0619,  0.0517,  0.0343,  0.0791],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1437, 0.1831, 0.1692, 0.1675, 0.1646, 0.1721], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "117\n",
      "117\n",
      "tensor([-0.1017,  0.1401,  0.0722, -0.0096,  0.0795,  0.0911],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1434, 0.1827, 0.1707, 0.1573, 0.1719, 0.1740], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "118\n",
      "118\n",
      "tensor([-0.0879,  0.1395,  0.0559,  0.0434,  0.0549,  0.1088],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1445, 0.1814, 0.1668, 0.1648, 0.1667, 0.1759], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "119\n",
      "119\n",
      "tensor([-0.0999,  0.1314,  0.0563,  0.0432,  0.0551,  0.0967],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1435, 0.1809, 0.1678, 0.1656, 0.1676, 0.1747], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "120\n",
      "120\n",
      "tensor([-0.0822,  0.1524,  0.0357,  0.0353,  0.0441,  0.0786],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1466, 0.1853, 0.1649, 0.1648, 0.1663, 0.1721], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "121\n",
      "121\n",
      "tensor([-0.0796,  0.1432,  0.0600,  0.0464,  0.0635,  0.1120],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1450, 0.1811, 0.1667, 0.1644, 0.1673, 0.1756], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "122\n",
      "122\n",
      "tensor([-0.1072,  0.1448,  0.0616,  0.0430,  0.0676,  0.0840],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1422, 0.1829, 0.1683, 0.1652, 0.1693, 0.1721], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "123\n",
      "123\n",
      "tensor([-0.0714,  0.1221,  0.0913,  0.0495,  0.0479,  0.1240],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1458, 0.1769, 0.1715, 0.1645, 0.1642, 0.1772], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "124\n",
      "124\n",
      "tensor([-0.1149,  0.1124,  0.0618,  0.0338,  0.0590,  0.0769],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1426, 0.1791, 0.1702, 0.1655, 0.1697, 0.1728], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "125\n",
      "125\n",
      "tensor([-0.0783,  0.1501,  0.0511,  0.0481,  0.0701,  0.1069],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1451, 0.1823, 0.1651, 0.1646, 0.1683, 0.1746], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "126\n",
      "126\n",
      "tensor([-0.0957,  0.1307,  0.0742,  0.0480,  0.0466,  0.0955],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1437, 0.1803, 0.1703, 0.1659, 0.1657, 0.1740], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "127\n",
      "127\n",
      "tensor([-0.1035,  0.1431,  0.0482, -0.0248,  0.0553,  0.0860],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1448, 0.1853, 0.1685, 0.1567, 0.1697, 0.1750], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "128\n",
      "128\n",
      "tensor([-0.0958,  0.1193,  0.0610,  0.0542,  0.0301,  0.0956],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1446, 0.1793, 0.1691, 0.1680, 0.1640, 0.1751], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "129\n",
      "129\n",
      "tensor([-0.0939,  0.1584,  0.0532,  0.0446,  0.0606,  0.1044],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1433, 0.1844, 0.1660, 0.1645, 0.1672, 0.1747], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "130\n",
      "130\n",
      "tensor([-0.1055,  0.1306,  0.0628,  0.0148,  0.0444,  0.1084],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1433, 0.1815, 0.1696, 0.1616, 0.1665, 0.1775], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "131\n",
      "131\n",
      "tensor([-0.0829,  0.1377,  0.0605,  0.0461,  0.0773,  0.1122],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1443, 0.1800, 0.1666, 0.1642, 0.1694, 0.1754], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "132\n",
      "132\n",
      "tensor([-0.1278,  0.1275,  0.0415,  0.0090,  0.0831,  0.0784],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1411, 0.1822, 0.1672, 0.1618, 0.1743, 0.1734], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "133\n",
      "133\n",
      "tensor([-0.0972,  0.1201,  0.0583,  0.0362,  0.0384,  0.0938],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1447, 0.1799, 0.1691, 0.1654, 0.1657, 0.1752], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "134\n",
      "134\n",
      "tensor([-0.0995,  0.1319,  0.0576,  0.0295,  0.0683,  0.0958],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1435, 0.1809, 0.1680, 0.1633, 0.1698, 0.1745], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "135\n",
      "135\n",
      "tensor([-0.0982,  0.1520,  0.0594,  0.0328,  0.0515,  0.1204],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1428, 0.1834, 0.1672, 0.1628, 0.1659, 0.1777], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "136\n",
      "136\n",
      "tensor([-0.0947,  0.1196,  0.0357,  0.0172,  0.0771,  0.1026],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1449, 0.1795, 0.1651, 0.1620, 0.1720, 0.1765], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "137\n",
      "137\n",
      "tensor([-0.1224,  0.1480,  0.0846,  0.0499,  0.0923,  0.0962],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1387, 0.1817, 0.1705, 0.1647, 0.1719, 0.1725], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "138\n",
      "138\n",
      "tensor([-0.0920,  0.1486,  0.0459,  0.0587,  0.0712,  0.1139],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1431, 0.1820, 0.1643, 0.1664, 0.1685, 0.1758], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "139\n",
      "139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1131,  0.1209,  0.0488,  0.0293,  0.0756,  0.0611],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1431, 0.1808, 0.1682, 0.1650, 0.1728, 0.1703], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "140\n",
      "140\n",
      "tensor([-0.0732,  0.1475,  0.0364, -0.0024,  0.0566,  0.0943],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1480, 0.1845, 0.1651, 0.1588, 0.1685, 0.1750], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "141\n",
      "141\n",
      "tensor([-0.0790,  0.1511,  0.0437,  0.0334,  0.0791,  0.1299],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1447, 0.1821, 0.1636, 0.1619, 0.1695, 0.1783], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "142\n",
      "142\n",
      "tensor([-0.0989,  0.1118,  0.0678,  0.0449,  0.0750,  0.1012],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1432, 0.1768, 0.1692, 0.1654, 0.1704, 0.1749], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "143\n",
      "143\n",
      "tensor([-0.0906,  0.1352,  0.0584, -0.0067,  0.0513,  0.0597],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1467, 0.1839, 0.1703, 0.1595, 0.1691, 0.1705], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "144\n",
      "144\n",
      "tensor([-0.0914,  0.1250,  0.0799,  0.0444,  0.0541,  0.1061],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1439, 0.1787, 0.1708, 0.1648, 0.1664, 0.1753], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "145\n",
      "145\n",
      "tensor([-0.0997,  0.1341,  0.0333,  0.0154,  0.0547,  0.0750],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1452, 0.1835, 0.1659, 0.1629, 0.1695, 0.1730], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "146\n",
      "146\n",
      "tensor([-0.0673,  0.1344,  0.0625,  0.0705,  0.0943,  0.1057],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1455, 0.1780, 0.1656, 0.1670, 0.1710, 0.1730], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "147\n",
      "147\n",
      "tensor([-0.1087,  0.1184,  0.0692,  0.0209,  0.0545,  0.0723],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1436, 0.1802, 0.1716, 0.1635, 0.1691, 0.1721], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "148\n",
      "148\n",
      "tensor([-0.1236,  0.1328,  0.0521,  0.0241,  0.0586,  0.1242],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1404, 0.1814, 0.1673, 0.1627, 0.1684, 0.1798], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "149\n",
      "149\n",
      "tensor([-0.1023,  0.1483,  0.0720,  0.0171,  0.0341,  0.0972],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1435, 0.1844, 0.1708, 0.1617, 0.1645, 0.1752], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "150\n",
      "150\n",
      "tensor([-0.0949,  0.1230,  0.0430,  0.0546,  0.0656,  0.0953],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1442, 0.1793, 0.1655, 0.1674, 0.1693, 0.1744], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "151\n",
      "151\n",
      "tensor([-0.0650,  0.1221,  0.0394,  0.0213,  0.0411,  0.0807],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1498, 0.1807, 0.1663, 0.1633, 0.1666, 0.1733], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "152\n",
      "152\n",
      "tensor([-0.1083,  0.1402,  0.0518,  0.0252,  0.0675,  0.0733],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1431, 0.1834, 0.1679, 0.1635, 0.1706, 0.1716], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "153\n",
      "153\n",
      "tensor([-0.1134,  0.1190,  0.0377,  0.0104,  0.0888,  0.0924],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1427, 0.1800, 0.1659, 0.1615, 0.1747, 0.1753], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "154\n",
      "154\n",
      "tensor([-0.0816,  0.1529,  0.0701,  0.1113,  0.0411,  0.1112],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1432, 0.1810, 0.1666, 0.1736, 0.1619, 0.1736], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "155\n",
      "155\n",
      "tensor([-0.0845,  0.1191,  0.0620,  0.0528,  0.0786,  0.0937],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1449, 0.1776, 0.1677, 0.1662, 0.1705, 0.1731], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "156\n",
      "156\n",
      "tensor([-0.0885,  0.1756,  0.0757,  0.0338,  0.0173,  0.1213],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1438, 0.1872, 0.1694, 0.1625, 0.1598, 0.1773], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "157\n",
      "157\n",
      "tensor([-0.0891,  0.1382,  0.0613,  0.0175,  0.0478,  0.0742],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1459, 0.1831, 0.1696, 0.1623, 0.1673, 0.1718], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "158\n",
      "158\n",
      "tensor([-0.0902,  0.1455,  0.0525,  0.0326,  0.0823,  0.1078],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1437, 0.1819, 0.1658, 0.1625, 0.1708, 0.1752], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "159\n",
      "159\n",
      "tensor([-0.0930,  0.1230,  0.0647,  0.0595,  0.0880,  0.0861],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1434, 0.1780, 0.1680, 0.1671, 0.1719, 0.1716], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "160\n",
      "160\n",
      "tensor([-0.1134,  0.1395,  0.0231, -0.0060,  0.0440,  0.1166],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1433, 0.1846, 0.1643, 0.1596, 0.1678, 0.1804], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "161\n",
      "161\n",
      "tensor([-0.1091,  0.1269,  0.0651,  0.0306,  0.0662,  0.0803],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1427, 0.1807, 0.1699, 0.1641, 0.1701, 0.1725], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "162\n",
      "162\n",
      "tensor([-0.0832,  0.1340,  0.0463,  0.0687,  0.0503,  0.1002],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1452, 0.1804, 0.1652, 0.1690, 0.1659, 0.1744], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "163\n",
      "163\n",
      "tensor([-0.1118,  0.1440,  0.0567,  0.0207,  0.0417,  0.0694],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1432, 0.1850, 0.1695, 0.1635, 0.1670, 0.1717], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "164\n",
      "164\n",
      "tensor([-0.1161,  0.1415,  0.0566,  0.0327,  0.0624,  0.1145],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1409, 0.1823, 0.1675, 0.1635, 0.1684, 0.1774], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "165\n",
      "165\n",
      "tensor([-0.0837,  0.1525,  0.0287, -0.0030,  0.0430,  0.0845],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1473, 0.1866, 0.1648, 0.1597, 0.1672, 0.1743], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "166\n",
      "166\n",
      "tensor([-0.1093,  0.1306,  0.0663,  0.0697,  0.0836,  0.0975],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1408, 0.1790, 0.1678, 0.1684, 0.1708, 0.1732], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "167\n",
      "167\n",
      "tensor([-0.0802,  0.1410,  0.0674,  0.0273,  0.0528,  0.0768],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1464, 0.1826, 0.1696, 0.1630, 0.1672, 0.1712], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "168\n",
      "168\n",
      "tensor([-0.0901,  0.1147,  0.0584,  0.0248,  0.0776,  0.1125],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1446, 0.1775, 0.1677, 0.1622, 0.1710, 0.1771], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "169\n",
      "169\n",
      "tensor([-0.0986,  0.1496,  0.0208,  0.0377,  0.0285,  0.0849],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1451, 0.1860, 0.1635, 0.1663, 0.1648, 0.1743], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "170\n",
      "170\n",
      "tensor([-0.0992,  0.1482,  0.0789,  0.0188,  0.1023,  0.0937],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1421, 0.1820, 0.1698, 0.1599, 0.1738, 0.1723], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "171\n",
      "171\n",
      "tensor([-0.1374,  0.1364,  0.0395,  0.0377,  0.0368,  0.1068],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1395, 0.1835, 0.1665, 0.1662, 0.1661, 0.1781], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "172\n",
      "172\n",
      "tensor([-0.1004,  0.1346,  0.0941,  0.0446,  0.0481,  0.0535],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1436, 0.1817, 0.1745, 0.1660, 0.1666, 0.1675], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "173\n",
      "173\n",
      "tensor([-0.0833,  0.1467,  0.0479,  0.0225,  0.0556,  0.1005],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1457, 0.1834, 0.1662, 0.1620, 0.1675, 0.1752], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "174\n",
      "174\n",
      "tensor([-0.1005,  0.1129,  0.0607,  0.0298,  0.0710,  0.0952],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1438, 0.1780, 0.1689, 0.1638, 0.1707, 0.1749], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "175\n",
      "175\n",
      "tensor([-0.0977,  0.1274,  0.0419,  0.0352,  0.0471,  0.0813],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1450, 0.1816, 0.1667, 0.1656, 0.1676, 0.1734], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "176\n",
      "176\n",
      "tensor([-0.0891,  0.1267,  0.0852,  0.0479,  0.0653,  0.0764],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1444, 0.1792, 0.1719, 0.1656, 0.1685, 0.1704], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "177\n",
      "177\n",
      "tensor([-0.0797,  0.1209,  0.0516,  0.0006,  0.0461,  0.0841],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1480, 0.1808, 0.1687, 0.1603, 0.1678, 0.1743], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "178\n",
      "178\n",
      "tensor([-0.1154,  0.1403,  0.0482,  0.0261,  0.0968,  0.1195],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1404, 0.1813, 0.1654, 0.1617, 0.1736, 0.1776], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "179\n",
      "179\n",
      "tensor([-0.1323,  0.1217,  0.0708,  0.0456,  0.0750,  0.0874],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1392, 0.1794, 0.1705, 0.1663, 0.1712, 0.1734], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "180\n",
      "180\n",
      "tensor([-0.0825,  0.1245,  0.0685,  0.0432,  0.0709,  0.0983],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1451, 0.1785, 0.1688, 0.1646, 0.1692, 0.1739], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "181\n",
      "181\n",
      "tensor([-0.0844,  0.1655,  0.0542,  0.0072,  0.0404,  0.0981],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1457, 0.1871, 0.1674, 0.1597, 0.1651, 0.1749], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "182\n",
      "182\n",
      "tensor([-0.1073,  0.1282,  0.0612,  0.0277,  0.0576,  0.1021],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1427, 0.1806, 0.1689, 0.1634, 0.1683, 0.1760], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "183\n",
      "183\n",
      "tensor([-0.0799,  0.1211,  0.0702,  0.0115,  0.0470,  0.1024],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1467, 0.1794, 0.1705, 0.1608, 0.1666, 0.1761], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "184\n",
      "184\n",
      "tensor([-0.0952,  0.1444,  0.0332,  0.0270,  0.0737,  0.0992],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1442, 0.1832, 0.1639, 0.1629, 0.1707, 0.1751], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "185\n",
      "185\n",
      "tensor([-0.0752,  0.1391,  0.0566,  0.0442,  0.0504,  0.0775],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1469, 0.1821, 0.1676, 0.1656, 0.1666, 0.1712], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "186\n",
      "186\n",
      "tensor([-0.1239,  0.1355,  0.0810,  0.0109,  0.0711,  0.1231],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1396, 0.1809, 0.1714, 0.1597, 0.1697, 0.1787], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "187\n",
      "187\n",
      "tensor([-0.1044,  0.1255,  0.0668,  0.0280,  0.0531,  0.0788],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1437, 0.1809, 0.1705, 0.1640, 0.1682, 0.1726], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "188\n",
      "188\n",
      "tensor([-0.0908,  0.1563,  0.0540,  0.0148,  0.0585,  0.0959],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1446, 0.1852, 0.1672, 0.1607, 0.1679, 0.1743], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "189\n",
      "189\n",
      "tensor([-0.1000,  0.1403,  0.0351,  0.0605,  0.0677,  0.1042],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1429, 0.1817, 0.1635, 0.1677, 0.1690, 0.1752], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "190\n",
      "190\n",
      "tensor([-0.1023,  0.1189,  0.0590,  0.0286,  0.0850,  0.0824],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1434, 0.1790, 0.1685, 0.1635, 0.1730, 0.1725], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "191\n",
      "191\n",
      "tensor([-0.1123,  0.1388,  0.0449, -0.0036,  0.0448,  0.0996],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1433, 0.1843, 0.1677, 0.1598, 0.1677, 0.1772], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "192\n",
      "192\n",
      "tensor([-0.0918,  0.1218,  0.0662,  0.0323,  0.0586,  0.0980],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1447, 0.1791, 0.1694, 0.1638, 0.1681, 0.1749], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "193\n",
      "193\n",
      "tensor([-0.1159,  0.1391,  0.0536, -0.0052,  0.0890,  0.1176],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1412, 0.1822, 0.1673, 0.1577, 0.1733, 0.1783], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "194\n",
      "194\n",
      "tensor([-0.0674,  0.1381,  0.0560,  0.0523,  0.0735,  0.0877],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1469, 0.1804, 0.1662, 0.1656, 0.1692, 0.1716], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "195\n",
      "195\n",
      "tensor([-0.0988,  0.1445,  0.0713,  0.0125,  0.0781,  0.1245],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1424, 0.1816, 0.1688, 0.1592, 0.1700, 0.1780], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "196\n",
      "196\n",
      "tensor([-0.0715,  0.1328,  0.0500,  0.0645,  0.0725,  0.0723],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1468, 0.1801, 0.1658, 0.1682, 0.1696, 0.1695], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "197\n",
      "197\n",
      "tensor([-0.0804,  0.1509,  0.0699,  0.0401,  0.0401,  0.0901],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1457, 0.1836, 0.1693, 0.1643, 0.1643, 0.1728], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "198\n",
      "198\n",
      "tensor([-0.1329,  0.1174,  0.0698,  0.0129,  0.0969,  0.0558],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1402, 0.1801, 0.1717, 0.1622, 0.1764, 0.1693], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "199\n",
      "199\n",
      "tensor([-0.0818,  0.1605,  0.0481,  0.0278,  0.0659,  0.1046],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1451, 0.1849, 0.1652, 0.1619, 0.1682, 0.1748], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "200\n",
      "200\n",
      "tensor([-0.0809,  0.1314,  0.0745,  0.0012,  0.0737,  0.0799],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1464, 0.1810, 0.1710, 0.1589, 0.1708, 0.1719], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "201\n",
      "201\n",
      "Episode 0 of 100 episodes                \r",
      "tensor([-0.1000,  0.1345,  0.0799,  0.0395,  0.0555,  0.0819],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1433, 0.1812, 0.1715, 0.1647, 0.1674, 0.1719], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "202\n",
      "202\n",
      "tensor([-0.0887,  0.1064,  0.0474,  0.0155,  0.0779,  0.0742],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1464, 0.1780, 0.1678, 0.1625, 0.1730, 0.1723], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "203\n",
      "203\n",
      "tensor([-0.1032,  0.1665,  0.0430,  0.0377,  0.0619,  0.1009],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1424, 0.1864, 0.1648, 0.1639, 0.1679, 0.1746], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "204\n",
      "204\n",
      "tensor([-0.1050,  0.1312,  0.0603,  0.0343,  0.0775,  0.0750],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1430, 0.1811, 0.1687, 0.1644, 0.1716, 0.1712], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "205\n",
      "205\n",
      "tensor([-0.0993,  0.1387,  0.0381,  0.0236,  0.0623,  0.1095],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1438, 0.1824, 0.1650, 0.1626, 0.1690, 0.1772], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "206\n",
      "206\n",
      "tensor([-0.0957,  0.1270,  0.0500,  0.0261,  0.0304,  0.0858],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1456, 0.1819, 0.1684, 0.1644, 0.1651, 0.1745], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "207\n",
      "207\n",
      "tensor([-0.1021,  0.1525,  0.0460,  0.0570,  0.0770,  0.0788],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1425, 0.1838, 0.1653, 0.1671, 0.1705, 0.1708], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208\n",
      "208\n",
      "tensor([-0.1025,  0.1421,  0.0748,  0.0231,  0.0926,  0.0712],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1427, 0.1822, 0.1703, 0.1617, 0.1734, 0.1697], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "209\n",
      "209\n",
      "tensor([-0.0907,  0.1106,  0.0384,  0.0236,  0.0520,  0.0886],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1464, 0.1790, 0.1666, 0.1641, 0.1688, 0.1751], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "210\n",
      "210\n",
      "tensor([-0.1092,  0.1395,  0.0683,  0.0156,  0.0418,  0.0775],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1433, 0.1838, 0.1711, 0.1624, 0.1667, 0.1727], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "211\n",
      "211\n",
      "tensor([-0.0697,  0.1008,  0.0492,  0.0215,  0.0718,  0.1065],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1481, 0.1756, 0.1668, 0.1622, 0.1706, 0.1766], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "212\n",
      "212\n",
      "tensor([-0.0999,  0.1347,  0.0455,  0.0346,  0.0740,  0.0893],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1436, 0.1816, 0.1661, 0.1643, 0.1709, 0.1735], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "213\n",
      "213\n",
      "tensor([-0.1018,  0.1240,  0.0812,  0.0277,  0.0794,  0.0868],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1429, 0.1791, 0.1716, 0.1626, 0.1713, 0.1725], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "214\n",
      "214\n",
      "tensor([-0.0686,  0.1421,  0.0343,  0.0540,  0.0648,  0.1002],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1471, 0.1816, 0.1630, 0.1662, 0.1681, 0.1741], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "215\n",
      "215\n",
      "tensor([-0.1001,  0.1191,  0.0556,  0.0161,  0.0421,  0.1260],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1440, 0.1793, 0.1683, 0.1618, 0.1660, 0.1806], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "216\n",
      "216\n",
      "tensor([-0.0920,  0.1499,  0.0516,  0.0299,  0.0789,  0.1010],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1437, 0.1831, 0.1659, 0.1624, 0.1705, 0.1743], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "217\n",
      "217\n",
      "tensor([-0.1247,  0.1562,  0.0762,  0.0170,  0.0398,  0.0882],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1405, 0.1861, 0.1718, 0.1619, 0.1657, 0.1739], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "218\n",
      "218\n",
      "tensor([-0.1014,  0.0873,  0.0388,  0.0418,  0.0802,  0.1143],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1438, 0.1737, 0.1655, 0.1660, 0.1725, 0.1785], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "219\n",
      "219\n",
      "tensor([-0.0899,  0.1462,  0.0675,  0.0013,  0.0581,  0.0952],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1450, 0.1837, 0.1698, 0.1589, 0.1682, 0.1745], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "220\n",
      "220\n",
      "tensor([-0.1178,  0.1424,  0.0633,  0.0503,  0.0347,  0.0653],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1420, 0.1841, 0.1701, 0.1679, 0.1653, 0.1705], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "221\n",
      "221\n",
      "tensor([-0.0645,  0.1319,  0.0535,  0.0442,  0.0608,  0.1215],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1472, 0.1791, 0.1656, 0.1641, 0.1668, 0.1772], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "222\n",
      "222\n",
      "tensor([-0.1027,  0.1353,  0.0357,  0.0082,  0.0511,  0.0769],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1450, 0.1839, 0.1665, 0.1620, 0.1691, 0.1735], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "223\n",
      "223\n",
      "tensor([-0.0664,  0.1139,  0.0988,  0.0267,  0.0671,  0.0854],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1475, 0.1766, 0.1739, 0.1618, 0.1685, 0.1716], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "224\n",
      "224\n",
      "tensor([-0.1087,  0.1445,  0.0487,  0.0085,  0.0391,  0.0820],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1438, 0.1853, 0.1684, 0.1617, 0.1668, 0.1741], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "225\n",
      "225\n",
      "tensor([-0.1268,  0.1101,  0.0499,  0.0350,  0.1005,  0.0930],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1401, 0.1776, 0.1672, 0.1647, 0.1759, 0.1745], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "226\n",
      "226\n",
      "tensor([-0.1005,  0.1381,  0.0459,  0.0069,  0.0490,  0.0958],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1445, 0.1835, 0.1673, 0.1609, 0.1678, 0.1759], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "227\n",
      "227\n",
      "tensor([-0.0802,  0.1440,  0.0785,  0.0277,  0.0499,  0.0751],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1461, 0.1828, 0.1712, 0.1628, 0.1664, 0.1707], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "228\n",
      "228\n",
      "tensor([-0.0673,  0.1061,  0.0949,  0.0431,  0.0720,  0.1103],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1465, 0.1742, 0.1723, 0.1636, 0.1684, 0.1750], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "229\n",
      "229\n",
      "tensor([-0.1051,  0.1415,  0.0430,  0.0386,  0.0662,  0.0974],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1428, 0.1827, 0.1655, 0.1648, 0.1694, 0.1748], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "230\n",
      "230\n",
      "tensor([-0.0827,  0.1119,  0.0557,  0.0026,  0.0501,  0.0754],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1478, 0.1796, 0.1697, 0.1610, 0.1688, 0.1731], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "231\n",
      "231\n",
      "tensor([-0.1026,  0.1190,  0.0710,  0.0185,  0.0777,  0.0790],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1436, 0.1792, 0.1708, 0.1621, 0.1720, 0.1722], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "232\n",
      "232\n",
      "tensor([-0.0997,  0.1679,  0.0581,  0.0494,  0.0497,  0.1201],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1419, 0.1855, 0.1662, 0.1648, 0.1648, 0.1768], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "233\n",
      "233\n",
      "tensor([-0.0870,  0.1177,  0.0554,  0.0399,  0.0903,  0.0840],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1450, 0.1779, 0.1672, 0.1646, 0.1731, 0.1721], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "234\n",
      "234\n",
      "tensor([-0.0799,  0.1190,  0.0843,  0.0456,  0.0354,  0.0924],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1461, 0.1783, 0.1722, 0.1657, 0.1640, 0.1736], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "235\n",
      "235\n",
      "tensor([-0.0958,  0.1338,  0.0394,  0.0190,  0.0653,  0.1096],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1444, 0.1816, 0.1653, 0.1619, 0.1696, 0.1773], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "236\n",
      "236\n",
      "tensor([-0.0993,  0.1375,  0.0910,  0.0385,  0.0891,  0.1145],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1414, 0.1792, 0.1711, 0.1623, 0.1708, 0.1752], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "237\n",
      "237\n",
      "tensor([-0.1184,  0.1177,  0.0200,  0.0144,  0.0607,  0.1040],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1428, 0.1809, 0.1640, 0.1631, 0.1708, 0.1784], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "238\n",
      "238\n",
      "tensor([-0.1000,  0.1437,  0.0892,  0.0540,  0.0692,  0.0880],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1420, 0.1812, 0.1716, 0.1656, 0.1682, 0.1714], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "239\n",
      "239\n",
      "tensor([-0.1109,  0.1266,  0.0408,  0.0259,  0.0786,  0.0790],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1429, 0.1812, 0.1663, 0.1639, 0.1728, 0.1728], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "240\n",
      "240\n",
      "tensor([-0.0871,  0.1482,  0.0728,  0.0033,  0.0714,  0.0746],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1453, 0.1839, 0.1705, 0.1591, 0.1703, 0.1709], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "241\n",
      "241\n",
      "tensor([-0.1022,  0.1373,  0.0706,  0.0664,  0.0681,  0.1295],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1411, 0.1792, 0.1677, 0.1670, 0.1672, 0.1778], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "242\n",
      "242\n",
      "tensor([-0.0783,  0.1590,  0.0829,  0.0462,  0.0748,  0.0926],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1444, 0.1830, 0.1696, 0.1635, 0.1682, 0.1713], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "243\n",
      "243\n",
      "tensor([-0.1056,  0.1576,  0.0362,  0.0239,  0.0623,  0.0944],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1429, 0.1860, 0.1647, 0.1627, 0.1691, 0.1746], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "244\n",
      "244\n",
      "tensor([-0.0903,  0.1211,  0.0735,  0.0139,  0.0640,  0.0958],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1450, 0.1792, 0.1709, 0.1610, 0.1692, 0.1747], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "245\n",
      "245\n",
      "tensor([-0.0895,  0.1399,  0.0752,  0.0252,  0.0559,  0.0891],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1447, 0.1820, 0.1706, 0.1623, 0.1674, 0.1730], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "246\n",
      "246\n",
      "tensor([-0.1065,  0.1137,  0.0474,  0.0291,  0.0621,  0.1069],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1433, 0.1786, 0.1671, 0.1641, 0.1696, 0.1774], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "247\n",
      "247\n",
      "tensor([-0.0886,  0.1384,  0.0918,  0.0342,  0.0786,  0.0914],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1436, 0.1802, 0.1720, 0.1624, 0.1698, 0.1720], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "248\n",
      "248\n",
      "tensor([-0.1083,  0.1451,  0.0619,  0.0548,  0.0407,  0.0572],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1430, 0.1843, 0.1696, 0.1684, 0.1660, 0.1688], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "249\n",
      "249\n",
      "tensor([-0.1272,  0.1394,  0.0593,  0.0158,  0.0570,  0.1113],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1401, 0.1830, 0.1689, 0.1617, 0.1685, 0.1779], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "250\n",
      "250\n",
      "tensor([-0.0861,  0.1193,  0.0556,  0.0243,  0.0708,  0.0848],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1459, 0.1792, 0.1681, 0.1629, 0.1707, 0.1731], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "251\n",
      "251\n",
      "tensor([-0.0859,  0.1168,  0.0554,  0.0255,  0.0853,  0.1302],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1445, 0.1769, 0.1664, 0.1615, 0.1714, 0.1793], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "252\n",
      "252\n",
      "tensor([-0.1274,  0.1453,  0.0176,  0.0198,  0.0474,  0.0672],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1422, 0.1867, 0.1644, 0.1647, 0.1693, 0.1727], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "253\n",
      "253\n",
      "tensor([-0.1023,  0.1199,  0.0714,  0.0499,  0.0668,  0.1061],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1425, 0.1779, 0.1695, 0.1659, 0.1687, 0.1755], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "254\n",
      "254\n",
      "tensor([-0.0969,  0.1244,  0.0626,  0.0341,  0.0553,  0.0810],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1445, 0.1803, 0.1695, 0.1647, 0.1683, 0.1726], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "255\n",
      "255\n",
      "tensor([-0.1037,  0.1520,  0.0286,  0.0251,  0.0605,  0.1033],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1433, 0.1850, 0.1636, 0.1630, 0.1689, 0.1762], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "256\n",
      "256\n",
      "tensor([-0.0714,  0.1373,  0.0948,  0.0200,  0.0806,  0.0873],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1461, 0.1800, 0.1725, 0.1601, 0.1701, 0.1712], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "257\n",
      "257\n",
      "tensor([-0.0873,  0.1309,  0.0850,  0.0189,  0.0418,  0.0861],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1455, 0.1810, 0.1729, 0.1618, 0.1656, 0.1731], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "258\n",
      "258\n",
      "tensor([-0.1181,  0.1261,  0.0216,  0.0127,  0.0634,  0.1050],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1426, 0.1820, 0.1639, 0.1625, 0.1709, 0.1782], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "259\n",
      "259\n",
      "tensor([-0.0790,  0.1267,  0.0494,  0.0304,  0.0582,  0.0931],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1467, 0.1802, 0.1668, 0.1637, 0.1683, 0.1743], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "260\n",
      "260\n",
      "tensor([-0.0640,  0.1272,  0.1051,  0.0327,  0.0620,  0.0833],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1473, 0.1783, 0.1744, 0.1622, 0.1671, 0.1707], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "261\n",
      "261\n",
      "tensor([-0.1116,  0.1467,  0.0261,  0.0242,  0.0520,  0.1133],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1425, 0.1845, 0.1635, 0.1632, 0.1678, 0.1784], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "262\n",
      "262\n",
      "tensor([-0.0969,  0.1426,  0.0838,  0.0657,  0.0576,  0.0939],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1424, 0.1809, 0.1706, 0.1675, 0.1662, 0.1723], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "263\n",
      "263\n",
      "tensor([-0.1064,  0.1459,  0.0611,  0.0337,  0.0661,  0.1000],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1421, 0.1829, 0.1680, 0.1635, 0.1689, 0.1747], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "264\n",
      "264\n",
      "tensor([-0.0909,  0.1233,  0.0816,  0.0127,  0.0837,  0.0913],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1444, 0.1789, 0.1715, 0.1601, 0.1719, 0.1732], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "265\n",
      "265\n",
      "tensor([-0.1010,  0.1568,  0.0673,  0.0384,  0.0403,  0.0837],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1432, 0.1854, 0.1695, 0.1647, 0.1650, 0.1723], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "266\n",
      "266\n",
      "tensor([-0.0880,  0.1223,  0.0389,  0.0293,  0.0556,  0.0999],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1459, 0.1800, 0.1656, 0.1640, 0.1684, 0.1760], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "267\n",
      "267\n",
      "tensor([-0.0993,  0.1604,  0.0780,  0.0395,  0.0547,  0.0696],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1431, 0.1855, 0.1708, 0.1644, 0.1669, 0.1694], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "268\n",
      "268\n",
      "tensor([-0.0784,  0.1262,  0.0816,  0.0349,  0.0436,  0.1118],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1458, 0.1789, 0.1711, 0.1633, 0.1647, 0.1763], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "269\n",
      "269\n",
      "tensor([-0.1177,  0.1288,  0.0288,  0.0111,  0.0513,  0.0995],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1428, 0.1828, 0.1654, 0.1625, 0.1691, 0.1775], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "270\n",
      "270\n",
      "tensor([-0.0912,  0.1187,  0.0609,  0.0155,  0.0744,  0.0884],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1452, 0.1791, 0.1690, 0.1615, 0.1713, 0.1738], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "271\n",
      "271\n",
      "tensor([-0.0948,  0.1456,  0.0574,  0.0365,  0.0630,  0.0999],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1436, 0.1827, 0.1672, 0.1638, 0.1682, 0.1745], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "272\n",
      "272\n",
      "tensor([-0.0803,  0.1305,  0.0513,  0.0036,  0.0602,  0.0783],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1474, 0.1820, 0.1681, 0.1603, 0.1696, 0.1727], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "273\n",
      "273\n",
      "tensor([-0.0901,  0.1401,  0.0519,  0.0368,  0.0432,  0.1005],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1449, 0.1825, 0.1671, 0.1646, 0.1656, 0.1754], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "274\n",
      "274\n",
      "tensor([-0.1061,  0.1302,  0.0556,  0.0359,  0.0745,  0.0910],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1426, 0.1807, 0.1677, 0.1644, 0.1709, 0.1737], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "275\n",
      "275\n",
      "tensor([-0.0777,  0.1038,  0.0560,  0.0266,  0.0482,  0.0809],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1480, 0.1774, 0.1691, 0.1642, 0.1678, 0.1734], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "276\n",
      "276\n",
      "tensor([-0.1014,  0.1263,  0.0597,  0.0248,  0.0554,  0.0846],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1441, 0.1810, 0.1693, 0.1635, 0.1686, 0.1736], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "277\n",
      "277\n",
      "tensor([-0.0920,  0.1359,  0.0594,  0.0282,  0.0734,  0.0934],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1443, 0.1812, 0.1679, 0.1627, 0.1702, 0.1737], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "278\n",
      "278\n",
      "tensor([-0.1010,  0.1343,  0.0655,  0.0211,  0.0536,  0.1112],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1433, 0.1813, 0.1692, 0.1619, 0.1672, 0.1771], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "279\n",
      "279\n",
      "tensor([-0.0901,  0.1266,  0.0696,  0.0155,  0.0983,  0.1024],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1440, 0.1788, 0.1689, 0.1600, 0.1738, 0.1745], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "280\n",
      "280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0962,  0.1290,  0.0837,  0.0417,  0.0404,  0.1001],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1437, 0.1799, 0.1720, 0.1649, 0.1647, 0.1748], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "281\n",
      "281\n",
      "tensor([-0.1050,  0.1346,  0.0651,  0.0058,  0.0716,  0.0942],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1431, 0.1819, 0.1697, 0.1599, 0.1708, 0.1747], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "282\n",
      "282\n",
      "tensor([-0.1028,  0.1097,  0.0485,  0.0284,  0.0362,  0.0706],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1454, 0.1798, 0.1691, 0.1658, 0.1670, 0.1729], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "283\n",
      "283\n",
      "tensor([-0.1043,  0.1285,  0.0559,  0.0349,  0.0763,  0.0837],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1431, 0.1806, 0.1679, 0.1644, 0.1714, 0.1727], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "284\n",
      "284\n",
      "tensor([-0.1080,  0.1344,  0.0533,  0.0177,  0.0494,  0.0876],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1435, 0.1828, 0.1686, 0.1627, 0.1679, 0.1745], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "285\n",
      "285\n",
      "tensor([-0.0915,  0.1502,  0.0697,  0.0430,  0.0474,  0.1108],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1436, 0.1828, 0.1687, 0.1642, 0.1650, 0.1757], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "286\n",
      "286\n",
      "tensor([-0.0843,  0.1134,  0.0554,  0.0451,  0.0582,  0.0999],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1457, 0.1776, 0.1676, 0.1659, 0.1680, 0.1752], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "287\n",
      "287\n",
      "tensor([-0.0900,  0.1463,  0.0526,  0.0235,  0.0685,  0.0836],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1449, 0.1835, 0.1671, 0.1623, 0.1698, 0.1724], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "288\n",
      "288\n",
      "tensor([-0.1117,  0.1369,  0.0447,  0.0034,  0.0667,  0.0820],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1432, 0.1836, 0.1675, 0.1607, 0.1712, 0.1738], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "289\n",
      "289\n",
      "tensor([-0.0914,  0.1362,  0.0672,  0.0239,  0.0572,  0.1032],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1444, 0.1813, 0.1692, 0.1621, 0.1675, 0.1754], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "290\n",
      "290\n",
      "tensor([-0.0821,  0.1192,  0.0601,  0.0446,  0.0605,  0.0835],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1461, 0.1787, 0.1684, 0.1658, 0.1685, 0.1724], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "291\n",
      "291\n",
      "tensor([-0.1110,  0.1456,  0.0532,  0.0269,  0.0631,  0.0865],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1423, 0.1839, 0.1677, 0.1633, 0.1694, 0.1734], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "292\n",
      "292\n",
      "tensor([-0.1070,  0.1292,  0.0506,  0.0323,  0.0564,  0.0915],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1432, 0.1813, 0.1676, 0.1646, 0.1686, 0.1746], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "293\n",
      "293\n",
      "tensor([-0.1020,  0.1393,  0.0546,  0.0286,  0.0633,  0.0845],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1435, 0.1827, 0.1679, 0.1636, 0.1693, 0.1730], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "294\n",
      "294\n",
      "tensor([-0.0753,  0.1296,  0.0341,  0.0453,  0.0604,  0.1051],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1468, 0.1801, 0.1637, 0.1656, 0.1681, 0.1758], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "295\n",
      "295\n",
      "tensor([-0.0846,  0.1206,  0.0589,  0.0046,  0.0615,  0.1098],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1460, 0.1793, 0.1686, 0.1597, 0.1690, 0.1774], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "296\n",
      "296\n",
      "tensor([-0.0988,  0.1447,  0.0544,  0.0177,  0.0551,  0.0873],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1442, 0.1839, 0.1680, 0.1620, 0.1682, 0.1737], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "297\n",
      "297\n",
      "tensor([-0.1040,  0.1367,  0.0606,  0.0418,  0.0868,  0.0937],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1421, 0.1808, 0.1675, 0.1644, 0.1720, 0.1732], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "298\n",
      "298\n",
      "tensor([-0.1047,  0.1485,  0.0566,  0.0170,  0.0533,  0.1037],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1430, 0.1841, 0.1680, 0.1614, 0.1674, 0.1761], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "299\n",
      "299\n",
      "tensor([-0.0868,  0.1317,  0.0802,  0.0542,  0.0363,  0.0821],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1451, 0.1805, 0.1714, 0.1671, 0.1641, 0.1718], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "300\n",
      "300\n",
      "tensor([-0.0907,  0.1213,  0.0539,  0.0292,  0.0700,  0.1046],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1447, 0.1789, 0.1673, 0.1632, 0.1700, 0.1759], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "301\n",
      "301\n",
      "Episode 0 of 100 episodes                \r",
      "tensor([-0.1167,  0.1534,  0.0453,  0.0164,  0.0513,  0.0734],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1424, 0.1866, 0.1675, 0.1627, 0.1685, 0.1723], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "302\n",
      "302\n",
      "tensor([-0.0862,  0.1300,  0.0724,  0.0447,  0.0766,  0.0771],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1448, 0.1797, 0.1697, 0.1650, 0.1704, 0.1705], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "303\n",
      "303\n",
      "tensor([-0.1140,  0.1312,  0.0478,  0.0038,  0.0584,  0.1054],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1426, 0.1822, 0.1677, 0.1604, 0.1695, 0.1776], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "304\n",
      "304\n",
      "tensor([-0.1056,  0.1201,  0.0485,  0.0289,  0.0787,  0.0988],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1430, 0.1792, 0.1668, 0.1636, 0.1719, 0.1754], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "305\n",
      "305\n",
      "tensor([-0.0755,  0.1299,  0.0503,  0.0322,  0.0422,  0.0924],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1474, 0.1810, 0.1672, 0.1642, 0.1658, 0.1744], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "306\n",
      "306\n",
      "tensor([-0.0778,  0.1553,  0.0818,  0.0052,  0.0479,  0.0836],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1464, 0.1848, 0.1717, 0.1591, 0.1660, 0.1720], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "307\n",
      "307\n",
      "tensor([-0.1060,  0.1260,  0.0640,  0.0365,  0.0624,  0.1087],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1424, 0.1796, 0.1688, 0.1642, 0.1685, 0.1765], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "308\n",
      "308\n",
      "tensor([-0.0874,  0.1339,  0.0602,  0.0385,  0.0562,  0.0943],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1450, 0.1810, 0.1681, 0.1645, 0.1674, 0.1739], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "309\n",
      "309\n",
      "tensor([-0.0875,  0.1522,  0.0603,  0.0222,  0.0604,  0.0967],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1448, 0.1840, 0.1678, 0.1616, 0.1678, 0.1741], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "310\n",
      "310\n",
      "tensor([-0.0897,  0.1327,  0.0503,  0.0317,  0.0542,  0.0957],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1452, 0.1814, 0.1670, 0.1639, 0.1677, 0.1748], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "311\n",
      "311\n",
      "tensor([-0.1013,  0.1232,  0.0664,  0.0208,  0.0471,  0.0975],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1440, 0.1802, 0.1703, 0.1627, 0.1671, 0.1757], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "312\n",
      "312\n",
      "tensor([-0.1234,  0.1431,  0.0353,  0.0476,  0.0600,  0.0717],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1412, 0.1844, 0.1655, 0.1676, 0.1697, 0.1717], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "313\n",
      "313\n",
      "tensor([-0.1075,  0.1239,  0.0661,  0.0245,  0.0860,  0.1127],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1418, 0.1787, 0.1687, 0.1618, 0.1721, 0.1768], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "314\n",
      "314\n",
      "tensor([-0.1054,  0.1313,  0.0559,  0.0273,  0.0479,  0.0715],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1440, 0.1825, 0.1692, 0.1645, 0.1679, 0.1719], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "315\n",
      "315\n",
      "tensor([-0.1051,  0.1340,  0.0622,  0.0145,  0.0580,  0.0839],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1436, 0.1824, 0.1697, 0.1618, 0.1690, 0.1735], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "316\n",
      "316\n",
      "tensor([-0.0890,  0.1482,  0.0507,  0.0020,  0.0669,  0.0985],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1452, 0.1841, 0.1669, 0.1590, 0.1697, 0.1751], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "317\n",
      "317\n",
      "tensor([-0.0879,  0.1118,  0.0573,  0.0381,  0.0703,  0.0924],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1453, 0.1775, 0.1680, 0.1649, 0.1703, 0.1740], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "318\n",
      "318\n",
      "tensor([-0.1101,  0.1440,  0.0676,  0.0101,  0.0285,  0.0974],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1431, 0.1844, 0.1709, 0.1613, 0.1643, 0.1760], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "319\n",
      "319\n",
      "tensor([-0.0672,  0.1281,  0.0766,  0.0171,  0.0809,  0.0991],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1471, 0.1788, 0.1698, 0.1600, 0.1706, 0.1737], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "320\n",
      "320\n",
      "tensor([-0.1010,  0.1257,  0.0665,  0.0327,  0.0488,  0.0826],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1440, 0.1807, 0.1703, 0.1646, 0.1673, 0.1731], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "321\n",
      "321\n",
      "tensor([-0.0902,  0.1203,  0.0372,  0.0221,  0.0855,  0.1053],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1450, 0.1790, 0.1647, 0.1622, 0.1728, 0.1763], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "322\n",
      "322\n",
      "tensor([-0.1030,  0.1624,  0.0524,  0.0318,  0.0624,  0.1110],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1421, 0.1854, 0.1660, 0.1627, 0.1677, 0.1761], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "323\n",
      "323\n",
      "tensor([-0.0989,  0.1175,  0.0683,  0.0299,  0.0559,  0.1062],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1438, 0.1785, 0.1699, 0.1635, 0.1678, 0.1765], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "324\n",
      "324\n",
      "tensor([-0.1026,  0.1140,  0.0540,  0.0076,  0.0529,  0.0776],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1451, 0.1801, 0.1697, 0.1620, 0.1695, 0.1737], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "325\n",
      "325\n",
      "tensor([-0.0717,  0.1493,  0.0416,  0.0219,  0.0676,  0.0755],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1476, 0.1841, 0.1653, 0.1621, 0.1697, 0.1710], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "326\n",
      "326\n",
      "tensor([-0.0806,  0.1294,  0.0482,  0.0253,  0.0601,  0.1014],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1463, 0.1805, 0.1665, 0.1627, 0.1684, 0.1755], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "327\n",
      "327\n",
      "tensor([-0.1138,  0.1454,  0.0747,  0.0438,  0.0660,  0.1151],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1403, 0.1818, 0.1694, 0.1642, 0.1679, 0.1764], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "328\n",
      "328\n",
      "tensor([-0.1242,  0.1451,  0.0623,  0.0167,  0.0667,  0.0943],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1405, 0.1839, 0.1692, 0.1617, 0.1700, 0.1748], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "329\n",
      "329\n",
      "tensor([-0.0887,  0.1293,  0.0418,  0.0085,  0.0468,  0.1042],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1461, 0.1817, 0.1665, 0.1611, 0.1673, 0.1772], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "330\n",
      "330\n",
      "tensor([-0.0924,  0.1349,  0.0442,  0.0461,  0.0655,  0.0935],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1444, 0.1812, 0.1655, 0.1658, 0.1691, 0.1739], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "331\n",
      "331\n",
      "tensor([-0.0937,  0.1483,  0.0435,  0.0419,  0.0539,  0.1288],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1434, 0.1826, 0.1645, 0.1642, 0.1662, 0.1791], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "332\n",
      "332\n",
      "tensor([-0.0977,  0.1330,  0.0580,  0.0386,  0.0552,  0.0761],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1443, 0.1818, 0.1686, 0.1654, 0.1682, 0.1717], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "333\n",
      "333\n",
      "tensor([-0.1002,  0.1194,  0.0514,  0.0173,  0.0723,  0.0843],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1444, 0.1799, 0.1680, 0.1624, 0.1716, 0.1737], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "334\n",
      "334\n",
      "tensor([-0.0771,  0.1365,  0.0508,  0.0103,  0.0497,  0.0901],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1474, 0.1825, 0.1675, 0.1609, 0.1674, 0.1743], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "335\n",
      "335\n",
      "tensor([-0.0872,  0.1443,  0.0668,  0.0366,  0.0501,  0.1066],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1445, 0.1822, 0.1686, 0.1636, 0.1658, 0.1754], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "336\n",
      "336\n",
      "tensor([-0.1062,  0.1364,  0.0597,  0.0189,  0.0448,  0.0931],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1434, 0.1828, 0.1693, 0.1625, 0.1668, 0.1751], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "337\n",
      "337\n",
      "tensor([-0.0757,  0.1144,  0.0412,  0.0376,  0.0611,  0.0759],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1478, 0.1788, 0.1662, 0.1656, 0.1695, 0.1721], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "338\n",
      "338\n",
      "tensor([-0.1087,  0.1301,  0.0724, -0.0100,  0.0713,  0.1068],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1427, 0.1811, 0.1710, 0.1575, 0.1708, 0.1770], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "339\n",
      "339\n",
      "tensor([-0.0814,  0.1560,  0.0416,  0.0606,  0.0383,  0.0996],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1454, 0.1844, 0.1645, 0.1676, 0.1639, 0.1743], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "340\n",
      "340\n",
      "tensor([-0.0971,  0.1364,  0.0666,  0.0316,  0.0624,  0.0927],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1437, 0.1815, 0.1692, 0.1634, 0.1685, 0.1737], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "341\n",
      "341\n",
      "tensor([-0.1026,  0.1254,  0.0691,  0.0059,  0.0916,  0.0840],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1433, 0.1800, 0.1702, 0.1597, 0.1740, 0.1727], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "342\n",
      "342\n",
      "tensor([-0.0917,  0.1305,  0.0534,  0.0267,  0.0589,  0.1161],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1444, 0.1804, 0.1670, 0.1626, 0.1679, 0.1778], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "343\n",
      "343\n",
      "tensor([-0.1074,  0.1399,  0.0604,  0.0206,  0.0807,  0.0785],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1426, 0.1826, 0.1687, 0.1621, 0.1721, 0.1718], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "344\n",
      "344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0781,  0.1405,  0.0629,  0.0171,  0.0743,  0.1146],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1455, 0.1811, 0.1675, 0.1600, 0.1695, 0.1764], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "345\n",
      "345\n",
      "tensor([-0.1089,  0.1223,  0.0619,  0.0173,  0.0667,  0.0695],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1435, 0.1808, 0.1702, 0.1628, 0.1711, 0.1715], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "346\n",
      "346\n",
      "tensor([-0.1191,  0.1304,  0.0527,  0.0226,  0.0582,  0.1042],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1415, 0.1816, 0.1680, 0.1630, 0.1689, 0.1769], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "347\n",
      "347\n",
      "tensor([-0.0943,  0.1456,  0.0437,  0.0351,  0.0691,  0.0938],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1440, 0.1831, 0.1654, 0.1640, 0.1696, 0.1739], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "348\n",
      "348\n",
      "tensor([-0.0881,  0.1389,  0.0781,  0.0156,  0.0698,  0.0824],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1449, 0.1818, 0.1711, 0.1607, 0.1697, 0.1718], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "349\n",
      "349\n",
      "tensor([-0.1195,  0.1358,  0.0421,  0.0411,  0.0650,  0.1132],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1407, 0.1817, 0.1654, 0.1653, 0.1693, 0.1776], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "350\n",
      "350\n",
      "tensor([-0.0944,  0.1250,  0.0492,  0.0432,  0.0833,  0.0864],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1441, 0.1794, 0.1663, 0.1654, 0.1721, 0.1727], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "351\n",
      "351\n",
      "tensor([-0.0929,  0.1682,  0.0451,  0.0589,  0.0630,  0.0941],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1432, 0.1859, 0.1644, 0.1666, 0.1673, 0.1726], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "352\n",
      "352\n",
      "tensor([-0.0664,  0.1334,  0.0357,  0.0353,  0.0887,  0.0863],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1477, 0.1804, 0.1636, 0.1636, 0.1725, 0.1721], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "353\n",
      "353\n",
      "tensor([-0.0985,  0.1643,  0.0481,  0.0617,  0.0368,  0.1109],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1426, 0.1855, 0.1652, 0.1674, 0.1633, 0.1759], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "354\n",
      "354\n",
      "tensor([-0.1012,  0.1128,  0.0526,  0.0443,  0.0699,  0.0893],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1437, 0.1780, 0.1676, 0.1662, 0.1705, 0.1739], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "355\n",
      "355\n",
      "tensor([-0.0910,  0.1223,  0.0594,  0.0435,  0.0919,  0.0926],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1440, 0.1782, 0.1673, 0.1647, 0.1729, 0.1730], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "356\n",
      "356\n",
      "tensor([-0.0756,  0.1392,  0.0509,  0.0214,  0.0489,  0.0919],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1473, 0.1825, 0.1671, 0.1623, 0.1668, 0.1741], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "357\n",
      "357\n",
      "tensor([-0.0961,  0.1303,  0.0751,  0.0465,  0.0615,  0.0814],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1437, 0.1802, 0.1705, 0.1657, 0.1682, 0.1716], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "358\n",
      "358\n",
      "tensor([-0.1059,  0.1456,  0.0573,  0.0213,  0.0417,  0.0984],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1432, 0.1841, 0.1686, 0.1626, 0.1659, 0.1756], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "359\n",
      "359\n",
      "tensor([-0.1190,  0.1314,  0.0588,  0.0301,  0.0739,  0.0739],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1415, 0.1818, 0.1691, 0.1643, 0.1717, 0.1716], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "360\n",
      "360\n",
      "tensor([-0.0799,  0.1424,  0.0522,  0.0453,  0.0796,  0.1221],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1445, 0.1805, 0.1649, 0.1638, 0.1695, 0.1768], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "361\n",
      "361\n",
      "tensor([-0.1026,  0.1190,  0.0448, -0.0069,  0.0416,  0.0802],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1457, 0.1818, 0.1689, 0.1603, 0.1683, 0.1749], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "362\n",
      "362\n",
      "tensor([-0.1149,  0.1434,  0.0821,  0.0623,  0.0751,  0.0862],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1401, 0.1814, 0.1706, 0.1673, 0.1694, 0.1713], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "363\n",
      "363\n",
      "tensor([-0.1053,  0.1204,  0.0444,  0.0120,  0.0663,  0.1072],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1436, 0.1800, 0.1668, 0.1615, 0.1705, 0.1776], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "364\n",
      "364\n",
      "tensor([-0.0823,  0.1398,  0.0596,  0.0559,  0.0654,  0.0996],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1448, 0.1808, 0.1668, 0.1662, 0.1678, 0.1736], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "365\n",
      "365\n",
      "tensor([-0.0806,  0.1228,  0.0604,  0.0312,  0.0671,  0.0759],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1466, 0.1796, 0.1687, 0.1639, 0.1699, 0.1714], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "366\n",
      "366\n",
      "tensor([-0.0778,  0.1392,  0.0477,  0.0293,  0.0469,  0.1085],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1465, 0.1820, 0.1661, 0.1630, 0.1659, 0.1765], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "367\n",
      "367\n",
      "tensor([-0.1275,  0.1272,  0.0490,  0.0546,  0.0717,  0.0920],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1399, 0.1805, 0.1669, 0.1678, 0.1707, 0.1742], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "368\n",
      "368\n",
      "tensor([-0.0840,  0.1087,  0.0568,  0.0322,  0.0609,  0.0936],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1463, 0.1773, 0.1684, 0.1643, 0.1691, 0.1747], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "369\n",
      "369\n",
      "tensor([-0.0823,  0.1383,  0.0379,  0.0252,  0.0397,  0.0789],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1472, 0.1836, 0.1660, 0.1639, 0.1663, 0.1730], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "370\n",
      "370\n",
      "tensor([-0.0954,  0.1492,  0.0364,  0.0491,  0.0636,  0.0939],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1438, 0.1836, 0.1641, 0.1662, 0.1686, 0.1738], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "371\n",
      "371\n",
      "tensor([-0.1055,  0.1306,  0.0813,  0.0325,  0.0592,  0.0937],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1425, 0.1804, 0.1717, 0.1636, 0.1680, 0.1739], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "372\n",
      "372\n",
      "tensor([-0.1010,  0.1169,  0.0708,  0.0037,  0.0679,  0.0981],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1440, 0.1790, 0.1710, 0.1599, 0.1705, 0.1757], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "373\n",
      "373\n",
      "tensor([-0.0866,  0.1432,  0.0611,  0.0443,  0.0607,  0.0932],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1447, 0.1820, 0.1677, 0.1649, 0.1676, 0.1732], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "374\n",
      "374\n",
      "tensor([-0.1089,  0.1502,  0.0538,  0.0346,  0.0567,  0.0927],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1422, 0.1843, 0.1674, 0.1642, 0.1679, 0.1740], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "375\n",
      "375\n",
      "tensor([-0.0959,  0.1190,  0.0512,  0.0525,  0.0863,  0.1100],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1431, 0.1774, 0.1658, 0.1660, 0.1717, 0.1759], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "376\n",
      "376\n",
      "tensor([-0.1182,  0.1306,  0.0413,  0.0215,  0.0593,  0.0967],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1421, 0.1822, 0.1666, 0.1634, 0.1697, 0.1761], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "377\n",
      "377\n",
      "tensor([-0.0786,  0.1298,  0.0626,  0.0312,  0.0606,  0.0973],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1462, 0.1800, 0.1683, 0.1631, 0.1680, 0.1743], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "378\n",
      "378\n",
      "tensor([-0.1027,  0.1174,  0.0643,  0.0276,  0.0611,  0.1060],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1433, 0.1786, 0.1694, 0.1633, 0.1688, 0.1766], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "379\n",
      "379\n",
      "tensor([-0.1230,  0.1307,  0.0417,  0.0351,  0.0930,  0.0947],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1404, 0.1809, 0.1655, 0.1644, 0.1742, 0.1745], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "380\n",
      "380\n",
      "tensor([-0.0702,  0.1306,  0.0717,  0.0541,  0.0580,  0.0941],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1466, 0.1792, 0.1689, 0.1660, 0.1666, 0.1728], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "381\n",
      "381\n",
      "tensor([-0.0943,  0.1340,  0.0590,  0.0405,  0.0678,  0.0815],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1442, 0.1812, 0.1681, 0.1650, 0.1696, 0.1719], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "382\n",
      "382\n",
      "tensor([-0.1074,  0.1280,  0.0608,  0.0075,  0.0590,  0.0970],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1433, 0.1813, 0.1696, 0.1608, 0.1693, 0.1758], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "383\n",
      "383\n",
      "tensor([-0.1028,  0.1484,  0.0577,  0.0468,  0.0745,  0.1105],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1418, 0.1823, 0.1665, 0.1647, 0.1693, 0.1755], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "384\n",
      "384\n",
      "tensor([-0.0696,  0.1231,  0.0504,  0.0144,  0.0675,  0.0938],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1481, 0.1796, 0.1670, 0.1611, 0.1699, 0.1744], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "385\n",
      "385\n",
      "tensor([-0.1052,  0.1290,  0.0505,  0.0146,  0.0782,  0.1009],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1431, 0.1808, 0.1672, 0.1613, 0.1719, 0.1758], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "386\n",
      "386\n",
      "tensor([-0.1009,  0.1302,  0.0353,  0.0170,  0.0746,  0.0834],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1444, 0.1819, 0.1655, 0.1625, 0.1721, 0.1736], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "387\n",
      "387\n",
      "tensor([-0.0984,  0.1284,  0.0802,  0.0471,  0.0542,  0.0999],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1430, 0.1795, 0.1710, 0.1654, 0.1666, 0.1744], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "388\n",
      "388\n",
      "tensor([-0.0949,  0.1328,  0.0557,  0.0252,  0.0543,  0.1017],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1444, 0.1814, 0.1679, 0.1629, 0.1677, 0.1758], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "389\n",
      "389\n",
      "tensor([-0.0947,  0.1432,  0.0584,  0.0149,  0.0472,  0.1016],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1445, 0.1833, 0.1684, 0.1613, 0.1666, 0.1759], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "390\n",
      "390\n",
      "tensor([-0.0931,  0.1390,  0.0423,  0.0249,  0.0691,  0.0793],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1450, 0.1829, 0.1660, 0.1632, 0.1706, 0.1723], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "391\n",
      "391\n",
      "tensor([-0.0931,  0.1085,  0.0755,  0.0117,  0.0713,  0.0979],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1448, 0.1771, 0.1714, 0.1608, 0.1707, 0.1753], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "392\n",
      "392\n",
      "tensor([-0.1003,  0.1340,  0.0388,  0.0266,  0.0637,  0.0979],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1440, 0.1820, 0.1655, 0.1634, 0.1696, 0.1755], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "393\n",
      "393\n",
      "tensor([-0.1241,  0.1173,  0.0819,  0.0513,  0.0975,  0.1070],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1389, 0.1768, 0.1706, 0.1655, 0.1733, 0.1750], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "394\n",
      "394\n",
      "tensor([-0.1060,  0.1210,  0.0329,  0.0021,  0.0519,  0.1003],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1445, 0.1814, 0.1661, 0.1610, 0.1693, 0.1777], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "395\n",
      "395\n",
      "tensor([-0.0864,  0.1187,  0.0720,  0.0138,  0.0492,  0.0987],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1459, 0.1791, 0.1710, 0.1613, 0.1671, 0.1756], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "396\n",
      "396\n",
      "tensor([-0.0854,  0.1343,  0.0335,  0.0369,  0.0737,  0.0987],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1454, 0.1812, 0.1638, 0.1643, 0.1705, 0.1748], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "397\n",
      "397\n",
      "tensor([-0.0842,  0.1423,  0.0780,  0.0094,  0.0622,  0.0858],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1455, 0.1825, 0.1712, 0.1598, 0.1685, 0.1725], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "398\n",
      "398\n",
      "tensor([-0.0913,  0.1613,  0.0639,  0.0265,  0.0702,  0.1093],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1433, 0.1845, 0.1674, 0.1612, 0.1684, 0.1751], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "399\n",
      "399\n",
      "tensor([-0.1014,  0.1184,  0.0536, -0.0105,  0.0590,  0.1035],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1447, 0.1803, 0.1690, 0.1585, 0.1699, 0.1776], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "400\n",
      "400\n",
      "tensor([-0.0761,  0.1420,  0.0732,  0.0311,  0.0788,  0.1076],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1452, 0.1806, 0.1686, 0.1616, 0.1695, 0.1745], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "401\n",
      "401\n",
      "Episode 0 of 100 episodes                \r",
      "tensor([-0.0859,  0.1255,  0.0480,  0.0201,  0.0477,  0.0695],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1470, 0.1816, 0.1681, 0.1635, 0.1680, 0.1717], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "402\n",
      "402\n",
      "tensor([-0.0769,  0.1423,  0.0645,  0.0479,  0.0911,  0.0955],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1449, 0.1804, 0.1669, 0.1642, 0.1714, 0.1722], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "403\n",
      "403\n",
      "tensor([-0.1096,  0.1155,  0.0583,  0.0351,  0.0719,  0.0972],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1425, 0.1784, 0.1685, 0.1646, 0.1708, 0.1752], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "404\n",
      "404\n",
      "tensor([-0.0783,  0.1293,  0.0696,  0.0251,  0.0490,  0.0909],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1466, 0.1805, 0.1700, 0.1626, 0.1666, 0.1737], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "405\n",
      "405\n",
      "tensor([-0.0875,  0.1323,  0.0302,  0.0317,  0.0667,  0.0931],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1457, 0.1816, 0.1639, 0.1642, 0.1700, 0.1746], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "406\n",
      "406\n",
      "tensor([-0.1264,  0.1295,  0.0495, -0.0059,  0.0406,  0.0772],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1425, 0.1840, 0.1699, 0.1607, 0.1684, 0.1746], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "407\n",
      "407\n",
      "tensor([-0.0756,  0.1325,  0.0658,  0.0322,  0.0538,  0.0855],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1468, 0.1808, 0.1692, 0.1636, 0.1671, 0.1725], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "408\n",
      "408\n",
      "tensor([-0.1030,  0.1335,  0.0742,  0.0383,  0.0683,  0.0993],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1424, 0.1804, 0.1700, 0.1640, 0.1690, 0.1743], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "409\n",
      "409\n",
      "tensor([-0.0994,  0.1375,  0.0606,  0.0185,  0.0516,  0.1156],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1435, 0.1819, 0.1684, 0.1614, 0.1669, 0.1779], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "410\n",
      "410\n",
      "tensor([-0.0794,  0.1239,  0.0746,  0.0245,  0.0570,  0.0788],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1466, 0.1797, 0.1711, 0.1627, 0.1681, 0.1718], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "411\n",
      "411\n",
      "tensor([-0.0844,  0.1593,  0.0271,  0.0351,  0.0485,  0.0818],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1461, 0.1864, 0.1634, 0.1647, 0.1669, 0.1725], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "412\n",
      "412\n",
      "tensor([-0.0730,  0.1371,  0.0763,  0.0251,  0.0643,  0.0731],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1470, 0.1814, 0.1707, 0.1622, 0.1686, 0.1701], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "413\n",
      "413\n",
      "tensor([-0.1120,  0.1442,  0.0456,  0.0359,  0.0587,  0.0973],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1420, 0.1835, 0.1663, 0.1647, 0.1685, 0.1751], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "414\n",
      "414\n",
      "tensor([-0.0866,  0.1288,  0.0606,  0.0103,  0.0790,  0.0885],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1455, 0.1805, 0.1686, 0.1603, 0.1717, 0.1734], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "415\n",
      "415\n",
      "tensor([-0.0933,  0.1163,  0.0460,  0.0216,  0.0652,  0.0822],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1456, 0.1796, 0.1674, 0.1633, 0.1706, 0.1735], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "416\n",
      "416\n",
      "tensor([-0.0875,  0.1351,  0.0496,  0.0270,  0.0748,  0.0832],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1453, 0.1816, 0.1667, 0.1630, 0.1710, 0.1724], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "417\n",
      "417\n",
      "tensor([-0.1122,  0.1272,  0.0514,  0.0135,  0.0608,  0.0841],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1431, 0.1818, 0.1685, 0.1623, 0.1701, 0.1741], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "418\n",
      "418\n",
      "tensor([-0.1038,  0.1283,  0.0702,  0.0294,  0.0477,  0.0899],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1434, 0.1809, 0.1707, 0.1639, 0.1669, 0.1741], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "419\n",
      "419\n",
      "tensor([-0.0881,  0.1440,  0.0646,  0.0334,  0.0690,  0.0791],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1448, 0.1826, 0.1687, 0.1635, 0.1694, 0.1711], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "420\n",
      "420\n",
      "tensor([-0.1203,  0.1125,  0.0558,  0.0119,  0.0817,  0.0896],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1418, 0.1789, 0.1691, 0.1618, 0.1735, 0.1749], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "421\n",
      "421\n",
      "tensor([-0.1007,  0.1496,  0.0424,  0.0467,  0.0458,  0.1016],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1433, 0.1840, 0.1653, 0.1660, 0.1659, 0.1754], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "422\n",
      "422\n",
      "tensor([-0.0993,  0.1296,  0.0523,  0.0050,  0.0655,  0.0876],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1446, 0.1818, 0.1683, 0.1605, 0.1705, 0.1743], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "423\n",
      "423\n",
      "tensor([-0.1154,  0.1291,  0.0539,  0.0311,  0.0740,  0.0908],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1417, 0.1810, 0.1678, 0.1641, 0.1713, 0.1742], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "424\n",
      "424\n",
      "tensor([-0.0790,  0.1186,  0.0543,  0.0258,  0.0439,  0.0904],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1473, 0.1795, 0.1684, 0.1636, 0.1666, 0.1745], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "425\n",
      "425\n",
      "tensor([-0.0996,  0.1332,  0.0604,  0.0393,  0.0571,  0.0985],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1434, 0.1810, 0.1683, 0.1648, 0.1677, 0.1748], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "426\n",
      "426\n",
      "tensor([-0.1237,  0.1303,  0.0485,  0.0134,  0.0502,  0.0978],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1416, 0.1826, 0.1682, 0.1624, 0.1685, 0.1767], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "427\n",
      "427\n",
      "tensor([-0.0872,  0.1330,  0.0566,  0.0327,  0.0733,  0.0709],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1455, 0.1813, 0.1680, 0.1640, 0.1708, 0.1704], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "428\n",
      "428\n",
      "tensor([-0.0923,  0.1238,  0.0592,  0.0408,  0.0658,  0.1135],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1440, 0.1787, 0.1675, 0.1644, 0.1686, 0.1768], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "429\n",
      "429\n",
      "tensor([-0.1217,  0.1405,  0.0443,  0.0120,  0.0438,  0.0902],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1421, 0.1846, 0.1677, 0.1624, 0.1676, 0.1756], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "430\n",
      "430\n",
      "tensor([-0.0992,  0.1170,  0.0731,  0.0035,  0.0650,  0.1206],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1436, 0.1783, 0.1706, 0.1592, 0.1693, 0.1790], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "431\n",
      "431\n",
      "tensor([-0.0731,  0.1194,  0.0746,  0.0245,  0.0496,  0.0763],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1478, 0.1792, 0.1713, 0.1630, 0.1671, 0.1716], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "432\n",
      "432\n",
      "tensor([-0.0846,  0.1415,  0.0520,  0.0577,  0.0644,  0.0907],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1448, 0.1815, 0.1660, 0.1670, 0.1681, 0.1726], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "433\n",
      "433\n",
      "tensor([-0.0993,  0.1234,  0.0565,  0.0243,  0.0612,  0.0816],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1445, 0.1805, 0.1688, 0.1635, 0.1696, 0.1731], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "434\n",
      "434\n",
      "tensor([-0.0861,  0.1214,  0.0612,  0.0383,  0.0808,  0.1001],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1448, 0.1781, 0.1677, 0.1639, 0.1710, 0.1744], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "435\n",
      "435\n",
      "tensor([-0.0973,  0.1435,  0.0490,  0.0113,  0.0454,  0.1158],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1442, 0.1834, 0.1669, 0.1607, 0.1663, 0.1784], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "436\n",
      "436\n",
      "tensor([-0.1007,  0.1470,  0.0635,  0.0161,  0.0893,  0.0884],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1428, 0.1830, 0.1683, 0.1605, 0.1727, 0.1726], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "437\n",
      "437\n",
      "tensor([-0.1086,  0.1296,  0.0592,  0.0353,  0.0454,  0.0935],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1429, 0.1814, 0.1690, 0.1650, 0.1667, 0.1749], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "438\n",
      "438\n",
      "tensor([-0.0923,  0.1312,  0.0640,  0.0206,  0.0676,  0.0667],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1452, 0.1816, 0.1698, 0.1626, 0.1704, 0.1703], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "439\n",
      "439\n",
      "tensor([-0.0949,  0.1377,  0.0523,  0.0406,  0.0533,  0.0949],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1442, 0.1820, 0.1671, 0.1651, 0.1672, 0.1744], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "440\n",
      "440\n",
      "tensor([-0.1228,  0.1137,  0.0640,  0.0103,  0.0838,  0.0838],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1414, 0.1791, 0.1704, 0.1615, 0.1738, 0.1738], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "441\n",
      "441\n",
      "tensor([-0.0959,  0.1225,  0.0442,  0.0362,  0.0649,  0.1067],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1442, 0.1794, 0.1659, 0.1646, 0.1694, 0.1766], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "442\n",
      "442\n",
      "tensor([-0.0845,  0.1297,  0.0677,  0.0401,  0.0748,  0.0836],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1451, 0.1798, 0.1690, 0.1644, 0.1702, 0.1717], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "443\n",
      "443\n",
      "tensor([-0.0925,  0.1285,  0.0368,  0.0356,  0.0809,  0.0910],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1447, 0.1804, 0.1646, 0.1644, 0.1721, 0.1738], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "444\n",
      "444\n",
      "tensor([-0.1022,  0.1452,  0.0559,  0.0318,  0.0534,  0.0957],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1432, 0.1834, 0.1678, 0.1637, 0.1673, 0.1746], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "445\n",
      "445\n",
      "tensor([-0.1030,  0.1321,  0.0561,  0.0243,  0.0527,  0.0777],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1441, 0.1823, 0.1689, 0.1637, 0.1684, 0.1726], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "446\n",
      "446\n",
      "tensor([-0.0730,  0.1321,  0.0647,  0.0483,  0.0542,  0.1026],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1464, 0.1797, 0.1680, 0.1653, 0.1662, 0.1745], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "447\n",
      "447\n",
      "tensor([-0.0974,  0.1260,  0.0502,  0.0459,  0.0712,  0.0828],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1440, 0.1800, 0.1669, 0.1662, 0.1704, 0.1724], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "448\n",
      "448\n",
      "tensor([-0.1004,  0.1347,  0.0494,  0.0080,  0.0556,  0.0730],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1449, 0.1834, 0.1684, 0.1615, 0.1694, 0.1724], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "449\n",
      "449\n",
      "tensor([-0.0897,  0.1208,  0.0840,  0.0459,  0.0622,  0.0895],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1443, 0.1781, 0.1717, 0.1653, 0.1680, 0.1726], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "450\n",
      "450\n",
      "tensor([-0.0996,  0.1398,  0.0248,  0.0299,  0.0920,  0.1303],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1426, 0.1812, 0.1615, 0.1624, 0.1728, 0.1795], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "451\n",
      "451\n",
      "tensor([-0.1098,  0.1520,  0.0689,  0.0349,  0.0735,  0.0886],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1414, 0.1837, 0.1691, 0.1634, 0.1699, 0.1724], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "452\n",
      "452\n",
      "tensor([-0.0770,  0.1174,  0.0475,  0.0216,  0.0542,  0.0811],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1479, 0.1796, 0.1675, 0.1632, 0.1686, 0.1732], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "453\n",
      "453\n",
      "tensor([-0.0987,  0.1553,  0.0801,  0.0374,  0.0534,  0.1212],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1420, 0.1831, 0.1698, 0.1627, 0.1654, 0.1770], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "454\n",
      "454\n",
      "tensor([-0.1029,  0.1175,  0.0615,  0.0271,  0.0644,  0.0834],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1439, 0.1793, 0.1696, 0.1638, 0.1701, 0.1733], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "455\n",
      "455\n",
      "tensor([-0.0954,  0.1398,  0.0463,  0.0479,  0.0581,  0.1186],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1433, 0.1814, 0.1652, 0.1654, 0.1671, 0.1776], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "456\n",
      "456\n",
      "tensor([-0.0853,  0.1213,  0.0425,  0.0249,  0.0670,  0.0935],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1461, 0.1797, 0.1661, 0.1632, 0.1702, 0.1747], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "457\n",
      "457\n",
      "tensor([-0.0661,  0.1717,  0.0838,  0.0120,  0.0696,  0.1042],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1461, 0.1854, 0.1698, 0.1580, 0.1674, 0.1733], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "458\n",
      "458\n",
      "tensor([-0.0851,  0.1411,  0.0568,  0.0290,  0.0731,  0.0728],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1456, 0.1825, 0.1678, 0.1632, 0.1705, 0.1705], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "459\n",
      "459\n",
      "tensor([-0.1133,  0.1445,  0.0274,  0.0224,  0.0448,  0.1094],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1426, 0.1846, 0.1642, 0.1634, 0.1670, 0.1782], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "460\n",
      "460\n",
      "tensor([-0.0847,  0.1241,  0.0687,  0.0385,  0.0730,  0.0737],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1455, 0.1793, 0.1696, 0.1646, 0.1704, 0.1705], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "461\n",
      "461\n",
      "tensor([-0.0922,  0.1267,  0.0731,  0.0329,  0.0417,  0.0633],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1456, 0.1812, 0.1717, 0.1650, 0.1664, 0.1701], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "462\n",
      "462\n",
      "tensor([-0.1118,  0.1371,  0.0300,  0.0227,  0.0556,  0.1089],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1427, 0.1830, 0.1644, 0.1632, 0.1687, 0.1779], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "463\n",
      "463\n",
      "tensor([-0.0900,  0.1382,  0.0548,  0.0256,  0.0660,  0.0993],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1447, 0.1818, 0.1672, 0.1624, 0.1691, 0.1748], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "464\n",
      "464\n",
      "tensor([-0.1227,  0.1152,  0.0266,  0.0317,  0.0647,  0.0898],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1421, 0.1802, 0.1649, 0.1658, 0.1713, 0.1757], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "465\n",
      "465\n",
      "tensor([-0.0404,  0.1303,  0.1159,  0.0358,  0.0442,  0.1096],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1496, 0.1774, 0.1749, 0.1614, 0.1628, 0.1738], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "466\n",
      "466\n",
      "tensor([-0.1151,  0.1356,  0.0514,  0.0464,  0.0417,  0.0794],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1423, 0.1829, 0.1681, 0.1673, 0.1665, 0.1729], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "467\n",
      "467\n",
      "tensor([-0.0853,  0.1456,  0.0643,  0.0135,  0.0603,  0.0954],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1453, 0.1831, 0.1688, 0.1604, 0.1681, 0.1742], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "468\n",
      "468\n",
      "tensor([-0.0989,  0.1336,  0.0437, -0.0138,  0.0600,  0.1124],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1447, 0.1826, 0.1669, 0.1575, 0.1696, 0.1787], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "469\n",
      "469\n",
      "tensor([-0.1009,  0.1308,  0.0574,  0.0492,  0.0664,  0.0959],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1430, 0.1803, 0.1675, 0.1661, 0.1690, 0.1741], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "470\n",
      "470\n",
      "tensor([-0.1148,  0.1419,  0.0520, -0.0015,  0.0625,  0.1227],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1417, 0.1832, 0.1674, 0.1587, 0.1692, 0.1797], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "471\n",
      "471\n",
      "tensor([-0.1172,  0.1220,  0.0502,  0.0312,  0.0608,  0.0987],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1419, 0.1802, 0.1677, 0.1646, 0.1695, 0.1761], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "472\n",
      "472\n",
      "tensor([-0.1039,  0.1254,  0.0563,  0.0154,  0.0652,  0.0946],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1436, 0.1806, 0.1686, 0.1618, 0.1701, 0.1752], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "473\n",
      "473\n",
      "tensor([-0.0858,  0.1408,  0.0523,  0.0416,  0.0457,  0.1092],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1450, 0.1819, 0.1665, 0.1648, 0.1654, 0.1763], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "474\n",
      "474\n",
      "tensor([-0.1111,  0.1347,  0.0721,  0.0130,  0.0637,  0.0994],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1421, 0.1817, 0.1707, 0.1609, 0.1693, 0.1754], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "475\n",
      "475\n",
      "tensor([-0.0808,  0.1281, -0.0009,  0.0360,  0.0597,  0.1019],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1473, 0.1815, 0.1595, 0.1655, 0.1695, 0.1768], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "476\n",
      "476\n",
      "tensor([-0.1135,  0.1372,  0.0637,  0.0295,  0.0605,  0.0892],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1419, 0.1823, 0.1694, 0.1637, 0.1689, 0.1738], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "477\n",
      "477\n",
      "tensor([-0.1059,  0.1312,  0.0690,  0.0052,  0.0707,  0.0644],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1438, 0.1823, 0.1713, 0.1607, 0.1716, 0.1705], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "478\n",
      "478\n",
      "tensor([-0.0700,  0.1563,  0.0689,  0.0344,  0.0537,  0.0986],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1464, 0.1836, 0.1683, 0.1626, 0.1657, 0.1733], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "479\n",
      "479\n",
      "tensor([-0.0737,  0.1089,  0.0738,  0.0420,  0.0527,  0.0927],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1471, 0.1766, 0.1705, 0.1652, 0.1669, 0.1737], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "480\n",
      "480\n",
      "tensor([-0.1025,  0.1512,  0.0454,  0.0179,  0.0570,  0.0760],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1440, 0.1856, 0.1669, 0.1624, 0.1689, 0.1721], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "481\n",
      "481\n",
      "tensor([-0.0882,  0.1309,  0.0676,  0.0303,  0.0554,  0.0848],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1453, 0.1809, 0.1698, 0.1636, 0.1677, 0.1727], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "482\n",
      "482\n",
      "tensor([-0.0808,  0.1216,  0.0796,  0.0422,  0.0661,  0.0893],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1455, 0.1781, 0.1708, 0.1645, 0.1685, 0.1725], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "483\n",
      "483\n",
      "tensor([-0.1047,  0.1360,  0.0476,  0.0273,  0.0566,  0.0769],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1438, 0.1830, 0.1675, 0.1641, 0.1690, 0.1725], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "484\n",
      "484\n",
      "tensor([-0.0899,  0.1425,  0.0845,  0.0312,  0.0413,  0.0967],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1444, 0.1822, 0.1719, 0.1630, 0.1646, 0.1740], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "485\n",
      "485\n",
      "tensor([-0.1102,  0.1239,  0.0362,  0.0271,  0.0611,  0.0693],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1438, 0.1818, 0.1665, 0.1650, 0.1707, 0.1721], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "486\n",
      "486\n",
      "tensor([-0.0861,  0.1378,  0.0629,  0.0252,  0.0600,  0.0899],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1454, 0.1818, 0.1687, 0.1625, 0.1682, 0.1733], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "487\n",
      "487\n",
      "tensor([-0.0758,  0.1532,  0.0629,  0.0207,  0.0564,  0.1080],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1460, 0.1835, 0.1677, 0.1608, 0.1666, 0.1754], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "488\n",
      "488\n",
      "tensor([-0.0888,  0.1236,  0.0673,  0.0147,  0.0740,  0.0820],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1454, 0.1798, 0.1700, 0.1613, 0.1711, 0.1725], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "489\n",
      "489\n",
      "tensor([-0.1209,  0.1289,  0.0559,  0.0497,  0.0542,  0.0815],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1413, 0.1814, 0.1686, 0.1675, 0.1683, 0.1730], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "490\n",
      "490\n",
      "tensor([-0.1152,  0.1426,  0.0468,  0.0186,  0.0620,  0.1156],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1415, 0.1831, 0.1664, 0.1618, 0.1689, 0.1782], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "491\n",
      "491\n",
      "tensor([-0.1003,  0.1284,  0.0620,  0.0168,  0.0655,  0.0882],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1440, 0.1810, 0.1694, 0.1619, 0.1699, 0.1738], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "492\n",
      "492\n",
      "tensor([-0.0856,  0.1511,  0.0358,  0.0251,  0.0493,  0.1009],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1457, 0.1846, 0.1645, 0.1628, 0.1668, 0.1756], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "493\n",
      "493\n",
      "tensor([-0.0826,  0.1302,  0.0693,  0.0361,  0.0655,  0.0812],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1457, 0.1802, 0.1696, 0.1640, 0.1689, 0.1716], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "494\n",
      "494\n",
      "tensor([-0.1053,  0.1426,  0.0263,  0.0294,  0.0768,  0.0891],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1433, 0.1836, 0.1634, 0.1639, 0.1719, 0.1740], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "495\n",
      "495\n",
      "tensor([-0.0786,  0.1176,  0.0901,  0.0037,  0.0506,  0.0691],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1474, 0.1794, 0.1745, 0.1601, 0.1678, 0.1709], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "496\n",
      "496\n",
      "tensor([-0.1170,  0.1253,  0.0518,  0.0262,  0.0495,  0.1226],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1416, 0.1804, 0.1676, 0.1634, 0.1672, 0.1799], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "497\n",
      "497\n",
      "tensor([-0.0846,  0.1230,  0.0864,  0.0114,  0.0499,  0.0832],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1461, 0.1798, 0.1734, 0.1608, 0.1671, 0.1728], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "498\n",
      "498\n",
      "tensor([-0.1097,  0.1400,  0.0522,  0.0295,  0.0672,  0.0967],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1422, 0.1826, 0.1672, 0.1635, 0.1697, 0.1748], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "499\n",
      "499\n",
      "tensor([-0.1058,  0.1315,  0.0522,  0.0321,  0.0621,  0.0703],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1436, 0.1821, 0.1682, 0.1649, 0.1699, 0.1713], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "500\n",
      "500\n",
      "tensor([-0.0917,  0.1090,  0.0411,  0.0120,  0.0444,  0.1014],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1464, 0.1789, 0.1671, 0.1624, 0.1677, 0.1775], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "501\n",
      "501\n",
      "Episode 0 of 100 episodes                \r",
      "tensor([-0.0925,  0.1333,  0.0605,  0.0300,  0.0418,  0.0972],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1449, 0.1816, 0.1688, 0.1638, 0.1657, 0.1752], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "502\n",
      "502\n",
      "tensor([-0.0975,  0.1179,  0.0509,  0.0186,  0.0573,  0.0730],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1454, 0.1804, 0.1687, 0.1633, 0.1698, 0.1724], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "503\n",
      "503\n",
      "tensor([-0.0969,  0.1417,  0.0528,  0.0350,  0.0694,  0.0943],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1436, 0.1823, 0.1668, 0.1639, 0.1696, 0.1739], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "504\n",
      "504\n",
      "tensor([-0.0742,  0.1629,  0.0712,  0.0277,  0.0567,  0.1150],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1454, 0.1843, 0.1681, 0.1610, 0.1657, 0.1756], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "505\n",
      "505\n",
      "tensor([-0.1028,  0.1389,  0.0804,  0.0461,  0.0453,  0.0942],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1426, 0.1816, 0.1713, 0.1655, 0.1654, 0.1737], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "506\n",
      "506\n",
      "tensor([-0.0982,  0.1331,  0.0455,  0.0050,  0.0332,  0.0876],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1456, 0.1835, 0.1681, 0.1614, 0.1660, 0.1753], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "507\n",
      "507\n",
      "tensor([-0.1046,  0.1231,  0.0413,  0.0321,  0.0634,  0.0965],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1436, 0.1803, 0.1661, 0.1646, 0.1698, 0.1756], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "508\n",
      "508\n",
      "tensor([-0.1173,  0.1259,  0.0587,  0.0431,  0.0538,  0.0811],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1419, 0.1810, 0.1692, 0.1666, 0.1684, 0.1730], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "509\n",
      "509\n",
      "tensor([-0.0638,  0.1216,  0.0792,  0.0266,  0.0695,  0.0869],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1480, 0.1781, 0.1707, 0.1620, 0.1691, 0.1721], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "510\n",
      "510\n",
      "tensor([-0.1166,  0.1330,  0.0616,  0.0146,  0.0605,  0.0840],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1421, 0.1825, 0.1699, 0.1621, 0.1697, 0.1737], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "511\n",
      "511\n",
      "tensor([-0.1023,  0.1345,  0.0426,  0.0365,  0.0443,  0.1175],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1434, 0.1817, 0.1657, 0.1647, 0.1660, 0.1786], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "512\n",
      "512\n",
      "tensor([-0.0990,  0.1245,  0.0533,  0.0240,  0.0664,  0.0817],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1444, 0.1806, 0.1682, 0.1633, 0.1704, 0.1730], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "513\n",
      "513\n",
      "tensor([-0.0642,  0.1439,  0.1027,  0.0422,  0.0656,  0.0726],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1468, 0.1808, 0.1735, 0.1633, 0.1672, 0.1684], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "514\n",
      "514\n",
      "tensor([-0.0904,  0.1269,  0.0381,  0.0284,  0.0730,  0.0709],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1458, 0.1812, 0.1658, 0.1642, 0.1717, 0.1713], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "515\n",
      "515\n",
      "tensor([-0.1152,  0.1357,  0.0697,  0.0296,  0.0801,  0.1185],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1404, 0.1804, 0.1689, 0.1623, 0.1707, 0.1773], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "516\n",
      "516\n",
      "tensor([-0.0883,  0.1319,  0.0639,  0.0052,  0.0573,  0.0937],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1457, 0.1815, 0.1696, 0.1599, 0.1685, 0.1747], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "517\n",
      "517\n",
      "tensor([-0.0882,  0.1154,  0.0556,  0.0260,  0.0616,  0.0702],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1463, 0.1794, 0.1689, 0.1640, 0.1700, 0.1714], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "518\n",
      "518\n",
      "tensor([-0.0925,  0.1330,  0.0658,  0.0465,  0.0745,  0.0959],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1436, 0.1800, 0.1683, 0.1650, 0.1697, 0.1734], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "519\n",
      "519\n",
      "tensor([-0.0980,  0.1325,  0.0669,  0.0439,  0.0659,  0.1007],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1431, 0.1802, 0.1687, 0.1649, 0.1686, 0.1745], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "520\n",
      "520\n",
      "tensor([-0.1058,  0.1359,  0.0584,  0.0153,  0.0613,  0.0874],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1434, 0.1825, 0.1689, 0.1618, 0.1694, 0.1739], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "521\n",
      "521\n",
      "tensor([-0.1081,  0.1428,  0.0479,  0.0302,  0.0545,  0.0973],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1427, 0.1834, 0.1668, 0.1639, 0.1679, 0.1753], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "522\n",
      "522\n",
      "tensor([-0.0885,  0.1342,  0.0492,  0.0301,  0.0689,  0.0757],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1455, 0.1818, 0.1670, 0.1638, 0.1703, 0.1715], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "523\n",
      "523\n",
      "tensor([-0.1195,  0.1234,  0.0254,  0.0144,  0.0658,  0.1055],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1423, 0.1814, 0.1644, 0.1626, 0.1712, 0.1781], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "524\n",
      "524\n",
      "tensor([-0.0993,  0.1446,  0.0480,  0.0199,  0.0665,  0.0962],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1437, 0.1834, 0.1665, 0.1619, 0.1696, 0.1747], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "525\n",
      "525\n",
      "tensor([-0.0870,  0.1193,  0.0561,  0.0370,  0.0527,  0.0693],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1463, 0.1799, 0.1688, 0.1656, 0.1683, 0.1711], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "526\n",
      "526\n",
      "tensor([-0.0886,  0.1120,  0.0681,  0.0244,  0.0693,  0.1048],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1450, 0.1772, 0.1696, 0.1624, 0.1698, 0.1760], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "527\n",
      "527\n",
      "tensor([-0.1132,  0.1421,  0.0371,  0.0359,  0.0788,  0.0838],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1420, 0.1833, 0.1650, 0.1648, 0.1720, 0.1729], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "528\n",
      "528\n",
      "tensor([-0.0763,  0.1157,  0.0444,  0.0170,  0.0676,  0.0938],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1475, 0.1788, 0.1665, 0.1620, 0.1704, 0.1749], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "529\n",
      "529\n",
      "tensor([-0.0839,  0.1358,  0.0450,  0.0112,  0.0612,  0.0955],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1463, 0.1822, 0.1664, 0.1609, 0.1691, 0.1750], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "530\n",
      "530\n",
      "tensor([-0.1254,  0.1328,  0.0742,  0.0350,  0.0348,  0.0972],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1406, 0.1820, 0.1717, 0.1651, 0.1650, 0.1757], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "531\n",
      "531\n",
      "tensor([-0.0766,  0.1272,  0.0566,  0.0425,  0.0607,  0.0686],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1471, 0.1803, 0.1681, 0.1657, 0.1687, 0.1701], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "532\n",
      "532\n",
      "tensor([-0.0793,  0.1217,  0.0436,  0.0112,  0.0809,  0.0827],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1471, 0.1799, 0.1664, 0.1610, 0.1727, 0.1730], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "533\n",
      "533\n",
      "tensor([-0.1014,  0.1433,  0.0729,  0.0278,  0.0639,  0.0963],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1428, 0.1824, 0.1700, 0.1625, 0.1684, 0.1740], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "534\n",
      "534\n",
      "tensor([-0.1073,  0.1248,  0.0414,  0.0340,  0.0742,  0.1055],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1427, 0.1799, 0.1655, 0.1643, 0.1711, 0.1765], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "535\n",
      "535\n",
      "tensor([-0.1265,  0.1276,  0.0725,  0.0367,  0.0403,  0.0686],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1412, 0.1820, 0.1723, 0.1662, 0.1668, 0.1716], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "536\n",
      "536\n",
      "tensor([-0.1006,  0.1314,  0.0586,  0.0172,  0.0538,  0.1000],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1439, 0.1815, 0.1688, 0.1619, 0.1680, 0.1759], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "537\n",
      "537\n",
      "tensor([-0.0960,  0.1412,  0.0589,  0.0129,  0.0596,  0.0835],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1446, 0.1833, 0.1688, 0.1612, 0.1690, 0.1730], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "538\n",
      "538\n",
      "tensor([-0.0831,  0.1418,  0.0583,  0.0230,  0.0661,  0.1197],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1449, 0.1814, 0.1669, 0.1611, 0.1682, 0.1775], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "539\n",
      "539\n",
      "tensor([-0.1212,  0.1188,  0.0554,  0.0404,  0.0611,  0.0797],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1416, 0.1800, 0.1690, 0.1664, 0.1699, 0.1731], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "540\n",
      "540\n",
      "tensor([-0.0630,  0.1340,  0.0563,  0.0244,  0.0511,  0.0807],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1490, 0.1814, 0.1679, 0.1626, 0.1670, 0.1720], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "541\n",
      "541\n",
      "tensor([-0.0998,  0.1331,  0.0824,  0.0503,  0.0764,  0.0990],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1421, 0.1794, 0.1705, 0.1651, 0.1695, 0.1734], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "542\n",
      "542\n",
      "tensor([-0.1167,  0.1389,  0.0352,  0.0379,  0.0470,  0.1219],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1414, 0.1826, 0.1647, 0.1651, 0.1666, 0.1796], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "543\n",
      "543\n",
      "tensor([-0.1137,  0.1232,  0.0607,  0.0238,  0.0726,  0.0970],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1420, 0.1799, 0.1690, 0.1629, 0.1710, 0.1753], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "544\n",
      "544\n",
      "tensor([-0.1119,  0.1238,  0.0592,  0.0290,  0.0760,  0.1028],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1418, 0.1795, 0.1683, 0.1633, 0.1712, 0.1758], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "545\n",
      "545\n",
      "tensor([-0.0846,  0.1187,  0.0608,  0.0088,  0.0753,  0.0827],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1463, 0.1793, 0.1692, 0.1606, 0.1717, 0.1729], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "546\n",
      "546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0633,  0.1349,  0.0861,  0.0271,  0.0620,  0.0870],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1477, 0.1801, 0.1715, 0.1617, 0.1674, 0.1716], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "547\n",
      "547\n",
      "tensor([-0.0964,  0.1331,  0.0502,  0.0316,  0.0446,  0.0887],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1448, 0.1821, 0.1676, 0.1645, 0.1667, 0.1742], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "548\n",
      "548\n",
      "tensor([-0.1046,  0.1542,  0.0737,  0.0348,  0.0898,  0.1136],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1409, 0.1825, 0.1684, 0.1619, 0.1711, 0.1752], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "549\n",
      "549\n",
      "tensor([-0.1056,  0.1331,  0.0746,  0.0030,  0.0516,  0.0917],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1435, 0.1821, 0.1718, 0.1599, 0.1679, 0.1748], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "550\n",
      "550\n",
      "tensor([-0.0915,  0.1475,  0.0369,  0.0727,  0.0603,  0.0692],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1444, 0.1834, 0.1642, 0.1702, 0.1681, 0.1696], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "551\n",
      "551\n",
      "tensor([-0.0987,  0.1414,  0.0767,  0.0287,  0.0561,  0.0764],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1437, 0.1827, 0.1713, 0.1632, 0.1678, 0.1712], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "552\n",
      "552\n",
      "tensor([-0.0854,  0.1147,  0.0636,  0.0100,  0.0827,  0.0872],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1459, 0.1782, 0.1694, 0.1605, 0.1726, 0.1734], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "553\n",
      "553\n",
      "tensor([-0.1174,  0.1396,  0.0439,  0.0310,  0.0515,  0.0819],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1422, 0.1839, 0.1671, 0.1649, 0.1684, 0.1736], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "554\n",
      "554\n",
      "tensor([-0.1039,  0.1311,  0.0496,  0.0112,  0.0782,  0.1030],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1432, 0.1812, 0.1670, 0.1607, 0.1718, 0.1761], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "555\n",
      "555\n",
      "tensor([-0.0963,  0.1229,  0.0639,  0.0254,  0.0670,  0.1037],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1440, 0.1792, 0.1690, 0.1626, 0.1695, 0.1758], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "556\n",
      "556\n",
      "tensor([-0.1150,  0.1426,  0.0557,  0.0185,  0.0488,  0.0668],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1429, 0.1848, 0.1694, 0.1633, 0.1683, 0.1713], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "557\n",
      "557\n",
      "tensor([-0.0862,  0.1244,  0.0840,  0.0332,  0.0829,  0.1006],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1442, 0.1780, 0.1709, 0.1624, 0.1707, 0.1738], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "558\n",
      "558\n",
      "tensor([-0.1024,  0.1444,  0.0487,  0.0391,  0.0616,  0.0931],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1431, 0.1831, 0.1664, 0.1648, 0.1686, 0.1740], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "559\n",
      "559\n",
      "tensor([-0.1062,  0.1323,  0.0491,  0.0309,  0.0621,  0.0834],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1433, 0.1820, 0.1674, 0.1644, 0.1696, 0.1733], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "560\n",
      "560\n",
      "tensor([-0.0819,  0.1330,  0.0644,  0.0459,  0.0680,  0.0978],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1451, 0.1799, 0.1680, 0.1649, 0.1686, 0.1737], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "561\n",
      "561\n",
      "tensor([-0.1391,  0.1311,  0.0560, -0.0024,  0.0601,  0.0912],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1398, 0.1832, 0.1700, 0.1603, 0.1706, 0.1760], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "562\n",
      "562\n",
      "tensor([-0.1026,  0.1373,  0.0461,  0.0312,  0.0615,  0.0873],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1436, 0.1826, 0.1667, 0.1642, 0.1692, 0.1737], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "563\n",
      "563\n",
      "tensor([-0.1056,  0.1351,  0.0347,  0.0341,  0.0359,  0.1099],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1436, 0.1826, 0.1652, 0.1651, 0.1654, 0.1781], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "564\n",
      "564\n",
      "tensor([-0.0948,  0.1413,  0.0519,  0.0299,  0.0634,  0.0773],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1446, 0.1831, 0.1674, 0.1638, 0.1694, 0.1717], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "565\n",
      "565\n",
      "tensor([-0.1201,  0.1242,  0.0692, -0.0040,  0.0779,  0.1029],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1413, 0.1804, 0.1708, 0.1587, 0.1722, 0.1766], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "566\n",
      "566\n",
      "tensor([-0.1138,  0.1178,  0.0140,  0.0165,  0.0507,  0.0963],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1439, 0.1814, 0.1635, 0.1639, 0.1696, 0.1776], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "567\n",
      "567\n",
      "tensor([-0.0855,  0.1291,  0.0771,  0.0429,  0.0601,  0.0770],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1452, 0.1800, 0.1709, 0.1651, 0.1680, 0.1708], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "568\n",
      "568\n",
      "tensor([-0.0730,  0.1391,  0.0726,  0.0189,  0.0746,  0.1013],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1462, 0.1808, 0.1691, 0.1603, 0.1695, 0.1741], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "569\n",
      "569\n",
      "tensor([-0.1021,  0.1295,  0.0420,  0.0220,  0.0678,  0.0818],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1442, 0.1818, 0.1665, 0.1633, 0.1709, 0.1733], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "570\n",
      "570\n",
      "tensor([-0.0899,  0.1229,  0.0700,  0.0344,  0.0708,  0.0919],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1446, 0.1789, 0.1696, 0.1637, 0.1698, 0.1734], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "571\n",
      "571\n",
      "tensor([-0.1075,  0.1401,  0.0541,  0.0338,  0.0663,  0.0842],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1427, 0.1827, 0.1677, 0.1643, 0.1698, 0.1728], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "572\n",
      "572\n",
      "tensor([-0.1000,  0.1272,  0.0637,  0.0248,  0.0682,  0.0796],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1440, 0.1807, 0.1696, 0.1631, 0.1703, 0.1723], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "573\n",
      "573\n",
      "tensor([-0.1036,  0.1227,  0.0596,  0.0228,  0.0674,  0.0968],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1434, 0.1798, 0.1688, 0.1627, 0.1701, 0.1752], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "574\n",
      "574\n",
      "tensor([-0.0944,  0.1317,  0.0674,  0.0211,  0.0634,  0.0853],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1445, 0.1812, 0.1699, 0.1622, 0.1692, 0.1730], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "575\n",
      "575\n",
      "tensor([-0.1112,  0.1168,  0.0484,  0.0248,  0.0708,  0.0907],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1429, 0.1795, 0.1676, 0.1637, 0.1714, 0.1749], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "576\n",
      "576\n",
      "tensor([-0.1030,  0.1415,  0.0644,  0.0352,  0.0583,  0.1052],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1426, 0.1821, 0.1686, 0.1637, 0.1675, 0.1756], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "577\n",
      "577\n",
      "tensor([-0.0941,  0.1257,  0.0545,  0.0005,  0.0596,  0.0728],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1459, 0.1818, 0.1693, 0.1604, 0.1702, 0.1724], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "578\n",
      "578\n",
      "tensor([-0.0927,  0.1441,  0.0488,  0.0422,  0.0438,  0.1041],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1444, 0.1829, 0.1663, 0.1652, 0.1655, 0.1757], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "579\n",
      "579\n",
      "tensor([-0.0943,  0.1343,  0.0510,  0.0366,  0.0612,  0.0810],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1447, 0.1818, 0.1673, 0.1649, 0.1690, 0.1724], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "580\n",
      "580\n",
      "tensor([-0.0897,  0.1243,  0.0565,  0.0188,  0.0741,  0.0866],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1453, 0.1800, 0.1682, 0.1620, 0.1712, 0.1733], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "581\n",
      "581\n",
      "tensor([-0.1045,  0.1301,  0.0601,  0.0240,  0.0396,  0.0779],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1442, 0.1823, 0.1700, 0.1640, 0.1665, 0.1730], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "582\n",
      "582\n",
      "tensor([-0.0800,  0.1324,  0.0596,  0.0329,  0.0742,  0.0940],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1457, 0.1802, 0.1675, 0.1631, 0.1700, 0.1734], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "583\n",
      "583\n",
      "tensor([-0.1010,  0.1310,  0.0602,  0.0132,  0.0631,  0.0867],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1440, 0.1817, 0.1692, 0.1615, 0.1697, 0.1738], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "584\n",
      "584\n",
      "tensor([-0.0966,  0.1299,  0.0539,  0.0191,  0.0643,  0.0952],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1444, 0.1811, 0.1679, 0.1621, 0.1696, 0.1749], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "585\n",
      "585\n",
      "tensor([-0.0980,  0.1279,  0.0767,  0.0143,  0.0692,  0.0750],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1442, 0.1808, 0.1717, 0.1614, 0.1705, 0.1715], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "586\n",
      "586\n",
      "tensor([-0.1256,  0.1489,  0.0592,  0.0389,  0.0472,  0.0962],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1402, 0.1844, 0.1686, 0.1652, 0.1666, 0.1750], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "587\n",
      "587\n",
      "tensor([-0.0873,  0.1332,  0.0333,  0.0204,  0.0621,  0.0936],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1460, 0.1820, 0.1647, 0.1626, 0.1696, 0.1750], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "588\n",
      "588\n",
      "tensor([-0.0960,  0.1368,  0.0737,  0.0523,  0.0413,  0.1215],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1429, 0.1804, 0.1693, 0.1658, 0.1639, 0.1776], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "589\n",
      "589\n",
      "tensor([-0.0771,  0.1340,  0.0625,  0.0500,  0.0555,  0.0944],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1460, 0.1803, 0.1679, 0.1658, 0.1667, 0.1733], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "590\n",
      "590\n",
      "tensor([-0.1127,  0.1602,  0.0636,  0.0231,  0.0457,  0.0917],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1418, 0.1863, 0.1692, 0.1625, 0.1662, 0.1740], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "591\n",
      "591\n",
      "tensor([-0.1234,  0.1129,  0.0420,  0.0190,  0.0704,  0.0694],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1423, 0.1803, 0.1679, 0.1641, 0.1728, 0.1726], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "592\n",
      "592\n",
      "tensor([-0.0805,  0.1097,  0.0607,  0.0109,  0.0559,  0.0945],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1472, 0.1780, 0.1695, 0.1613, 0.1687, 0.1753], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "593\n",
      "593\n",
      "tensor([-0.0982,  0.1355,  0.0581,  0.0520,  0.0764,  0.0956],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1429, 0.1805, 0.1670, 0.1660, 0.1701, 0.1734], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "594\n",
      "594\n",
      "tensor([-0.1201,  0.1073,  0.0453,  0.0120,  0.0542,  0.1020],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1425, 0.1789, 0.1682, 0.1627, 0.1697, 0.1780], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "595\n",
      "595\n",
      "tensor([-0.0836,  0.1338,  0.0430,  0.0503,  0.0960,  0.0799],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1450, 0.1802, 0.1646, 0.1658, 0.1736, 0.1708], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "596\n",
      "596\n",
      "tensor([-0.1086,  0.1224,  0.0478,  0.0290,  0.0673,  0.0973],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1429, 0.1800, 0.1671, 0.1640, 0.1704, 0.1756], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "597\n",
      "597\n",
      "tensor([-0.0949,  0.1423,  0.0551,  0.0182,  0.0447,  0.1037],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1445, 0.1832, 0.1679, 0.1618, 0.1662, 0.1763], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "598\n",
      "598\n",
      "tensor([-0.1185,  0.1407,  0.0626,  0.0441,  0.0445,  0.0956],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1411, 0.1829, 0.1691, 0.1660, 0.1661, 0.1748], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "599\n",
      "599\n",
      "tensor([-0.0795,  0.1325,  0.0639,  0.0139,  0.0313,  0.0737],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1477, 0.1826, 0.1705, 0.1622, 0.1650, 0.1721], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "600\n",
      "600\n",
      "tensor([-0.1077,  0.1341,  0.0449,  0.0341,  0.0819,  0.0990],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1423, 0.1812, 0.1657, 0.1639, 0.1720, 0.1749], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "601\n",
      "601\n",
      "Episode 0 of 100 episodes                \r",
      "tensor([-0.0868,  0.1372,  0.0624,  0.0083,  0.0796,  0.1068],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1448, 0.1811, 0.1681, 0.1592, 0.1710, 0.1757], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "602\n",
      "602\n",
      "tensor([-0.0717,  0.1257,  0.0061,  0.0267,  0.0620,  0.1069],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1483, 0.1807, 0.1603, 0.1637, 0.1696, 0.1773], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "603\n",
      "603\n",
      "tensor([-0.1222,  0.1379,  0.0918,  0.0105,  0.0733,  0.1066],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1399, 0.1814, 0.1732, 0.1597, 0.1700, 0.1758], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "604\n",
      "604\n",
      "tensor([-0.0959,  0.1428,  0.0584,  0.0252,  0.0671,  0.0758],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1443, 0.1832, 0.1684, 0.1629, 0.1699, 0.1713], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "605\n",
      "605\n",
      "tensor([-0.1192,  0.1044,  0.0157,  0.0666,  0.0485,  0.0874],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1426, 0.1784, 0.1632, 0.1718, 0.1687, 0.1754], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "606\n",
      "606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0936,  0.1279,  0.0709,  0.0240,  0.0628,  0.1050],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1441, 0.1798, 0.1698, 0.1621, 0.1685, 0.1757], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "607\n",
      "607\n",
      "tensor([-0.1344,  0.1499,  0.0533,  0.0252,  0.0482,  0.0924],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1396, 0.1855, 0.1684, 0.1638, 0.1676, 0.1751], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "608\n",
      "608\n",
      "tensor([-0.0821,  0.1423,  0.0684,  0.0388,  0.0690,  0.0841],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1452, 0.1817, 0.1688, 0.1639, 0.1689, 0.1715], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "609\n",
      "609\n",
      "tensor([-0.0706,  0.1504,  0.0485,  0.0141,  0.0719,  0.1178],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1466, 0.1828, 0.1651, 0.1595, 0.1690, 0.1769], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "610\n",
      "610\n",
      "tensor([-0.0947,  0.1173,  0.0635,  0.0371,  0.0813,  0.0718],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1445, 0.1786, 0.1692, 0.1648, 0.1723, 0.1706], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "611\n",
      "611\n",
      "tensor([-0.1030,  0.1439,  0.0479,  0.0439,  0.0489,  0.1246],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1424, 0.1823, 0.1656, 0.1650, 0.1658, 0.1788], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "612\n",
      "612\n",
      "tensor([-0.0838,  0.1545,  0.0766,  0.0265,  0.0937,  0.0849],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1441, 0.1829, 0.1692, 0.1609, 0.1721, 0.1706], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "613\n",
      "613\n",
      "tensor([-0.0965,  0.1322,  0.0924,  0.0071,  0.0753,  0.0813],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1438, 0.1807, 0.1736, 0.1595, 0.1707, 0.1717], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "614\n",
      "614\n",
      "tensor([-0.0979,  0.1312,  0.0662,  0.0158,  0.0497,  0.1038],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1441, 0.1812, 0.1698, 0.1615, 0.1670, 0.1763], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "615\n",
      "615\n",
      "tensor([-0.0956,  0.1207,  0.0425, -0.0112,  0.0619,  0.0912],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1459, 0.1811, 0.1675, 0.1588, 0.1708, 0.1759], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "616\n",
      "616\n",
      "tensor([-0.1315,  0.1266,  0.0673,  0.0292,  0.0412,  0.0906],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1403, 0.1817, 0.1712, 0.1648, 0.1668, 0.1752], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "617\n",
      "617\n",
      "tensor([-0.0595,  0.1351,  0.0895,  0.0011,  0.0703,  0.0969],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1482, 0.1801, 0.1721, 0.1575, 0.1688, 0.1733], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "618\n",
      "618\n",
      "tensor([-0.0870,  0.1469,  0.0207,  0.0650,  0.0660,  0.1145],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1443, 0.1823, 0.1607, 0.1680, 0.1682, 0.1765], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "619\n",
      "619\n",
      "tensor([-0.1110,  0.1369,  0.0363,  0.0373,  0.0225,  0.0650],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1442, 0.1848, 0.1671, 0.1672, 0.1648, 0.1719], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "620\n",
      "620\n",
      "tensor([-0.1087,  0.1306,  0.0297, -0.0084,  0.1005,  0.0842],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1435, 0.1823, 0.1648, 0.1586, 0.1769, 0.1740], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "621\n",
      "621\n",
      "tensor([-0.1086,  0.1340,  0.0615,  0.0324,  0.0686,  0.1171],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1417, 0.1806, 0.1679, 0.1631, 0.1691, 0.1775], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "622\n",
      "622\n",
      "tensor([-0.0755,  0.1278,  0.0579,  0.0624,  0.0742,  0.1119],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1453, 0.1780, 0.1660, 0.1668, 0.1687, 0.1752], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "623\n",
      "623\n",
      "tensor([-0.0741,  0.1450,  0.0561,  0.0395,  0.0722,  0.1071],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1458, 0.1815, 0.1660, 0.1633, 0.1687, 0.1747], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "624\n",
      "624\n",
      "tensor([-0.1146,  0.1251,  0.0690,  0.0388,  0.0481,  0.0755],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1424, 0.1809, 0.1711, 0.1660, 0.1675, 0.1722], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "625\n",
      "625\n",
      "tensor([-0.1131,  0.1274,  0.0832,  0.0149,  0.0902,  0.1165],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1407, 0.1789, 0.1712, 0.1599, 0.1724, 0.1770], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "626\n",
      "626\n",
      "tensor([-0.0654,  0.1530,  0.0720,  0.0368,  0.0249,  0.1073],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1475, 0.1834, 0.1692, 0.1633, 0.1614, 0.1752], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "627\n",
      "627\n",
      "tensor([-0.0753,  0.1594,  0.0645,  0.0481,  0.0564,  0.0737],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1460, 0.1847, 0.1680, 0.1652, 0.1666, 0.1695], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "628\n",
      "628\n",
      "tensor([-0.0836,  0.1277,  0.0969,  0.0383,  0.0554,  0.0922],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1449, 0.1789, 0.1735, 0.1636, 0.1664, 0.1727], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "629\n",
      "629\n",
      "tensor([-0.1099,  0.1449, -0.0120,  0.0124,  0.0810,  0.0774],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1441, 0.1859, 0.1589, 0.1628, 0.1744, 0.1738], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "630\n",
      "630\n",
      "tensor([-0.1578,  0.1270,  0.0615,  0.0278,  0.0578,  0.1158],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1363, 0.1813, 0.1698, 0.1642, 0.1692, 0.1793], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "631\n",
      "631\n",
      "tensor([-0.0885,  0.1475,  0.0720,  0.0378,  0.0516,  0.1127],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1439, 0.1822, 0.1690, 0.1633, 0.1656, 0.1760], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "632\n",
      "632\n",
      "tensor([-0.0677,  0.0964,  0.0431, -0.0025,  0.0262,  0.0857],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1509, 0.1778, 0.1686, 0.1611, 0.1658, 0.1759], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "633\n",
      "633\n",
      "tensor([-0.1107,  0.1426,  0.0643,  0.0274,  0.0668,  0.0869],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1420, 0.1830, 0.1692, 0.1631, 0.1696, 0.1731], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "634\n",
      "634\n",
      "tensor([-0.0648,  0.1409,  0.0538,  0.0411,  0.0707,  0.1013],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1472, 0.1809, 0.1658, 0.1637, 0.1686, 0.1738], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "635\n",
      "635\n",
      "tensor([-0.1188,  0.1433,  0.0819,  0.0489,  0.0633,  0.0774],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1404, 0.1825, 0.1716, 0.1661, 0.1685, 0.1709], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "636\n",
      "636\n",
      "tensor([-0.1015,  0.1223,  0.0723,  0.0416,  0.0282,  0.1104],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1435, 0.1795, 0.1707, 0.1656, 0.1634, 0.1774], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "637\n",
      "637\n",
      "tensor([-0.0980,  0.1901,  0.0371,  0.0410,  0.0382,  0.1201],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1425, 0.1901, 0.1631, 0.1638, 0.1633, 0.1772], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "638\n",
      "638\n",
      "tensor([-0.0885,  0.1408,  0.0764,  0.0607,  0.0589,  0.0933],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1438, 0.1808, 0.1695, 0.1669, 0.1666, 0.1724], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "639\n",
      "639\n",
      "tensor([-0.0818,  0.1263,  0.0614,  0.0221,  0.0743,  0.0926],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1459, 0.1796, 0.1683, 0.1619, 0.1705, 0.1737], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "640\n",
      "640\n",
      "tensor([-0.0634,  0.1411,  0.0512, -0.0044,  0.0390,  0.0981],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1494, 0.1833, 0.1676, 0.1585, 0.1655, 0.1756], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "641\n",
      "641\n",
      "tensor([-0.1176,  0.1410,  0.0411,  0.0231,  0.0982,  0.0833],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1412, 0.1829, 0.1655, 0.1625, 0.1752, 0.1726], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "642\n",
      "642\n",
      "tensor([-0.0956,  0.1702,  0.0607,  0.0379,  0.0236,  0.0968],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1438, 0.1876, 0.1681, 0.1643, 0.1620, 0.1743], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "643\n",
      "643\n",
      "tensor([-0.0772,  0.1307,  0.0580,  0.0400,  0.0638,  0.0936],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1462, 0.1800, 0.1674, 0.1644, 0.1684, 0.1735], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "644\n",
      "644\n",
      "tensor([-0.1160,  0.1448,  0.0753,  0.0383,  0.0483,  0.0896],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1412, 0.1833, 0.1710, 0.1648, 0.1664, 0.1734], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "645\n",
      "645\n",
      "tensor([-0.0653,  0.1440,  0.0743,  0.0666,  0.0578,  0.1149],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1459, 0.1799, 0.1678, 0.1665, 0.1650, 0.1748], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "646\n",
      "646\n",
      "tensor([-0.0696,  0.1254,  0.0312,  0.0129,  0.0586,  0.0786],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1492, 0.1813, 0.1650, 0.1620, 0.1696, 0.1730], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "647\n",
      "647\n",
      "tensor([-0.0847,  0.1209,  0.0606,  0.0641,  0.0404,  0.0974],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1454, 0.1786, 0.1681, 0.1687, 0.1648, 0.1744], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "648\n",
      "648\n",
      "tensor([-0.1034,  0.1512,  0.0857, -0.0025,  0.0533,  0.0732],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1435, 0.1851, 0.1734, 0.1588, 0.1679, 0.1713], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "649\n",
      "649\n",
      "tensor([-0.1127,  0.0856,  0.0103,  0.0306,  0.0527,  0.0736],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1452, 0.1770, 0.1642, 0.1675, 0.1713, 0.1749], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "650\n",
      "650\n",
      "tensor([-0.1073,  0.1489,  0.0409,  0.0621,  0.0362,  0.0876],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1427, 0.1844, 0.1655, 0.1691, 0.1648, 0.1735], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "651\n",
      "651\n",
      "tensor([-0.0844,  0.1487,  0.0639,  0.0544,  0.0796,  0.0758],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1444, 0.1824, 0.1675, 0.1659, 0.1702, 0.1695], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "652\n",
      "652\n",
      "tensor([-0.1065,  0.1243,  0.0408,  0.0384,  0.0518,  0.1226],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1428, 0.1799, 0.1654, 0.1651, 0.1673, 0.1796], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "653\n",
      "653\n",
      "tensor([-0.0905,  0.1431,  0.0518,  0.0552,  0.0276,  0.0718],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1455, 0.1838, 0.1677, 0.1683, 0.1637, 0.1711], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "654\n",
      "654\n",
      "tensor([-0.1039,  0.1358,  0.0548,  0.0258,  0.0979,  0.1036],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1421, 0.1806, 0.1666, 0.1618, 0.1739, 0.1749], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "655\n",
      "655\n",
      "tensor([-0.0595,  0.1374,  0.0430,  0.0351,  0.0290,  0.1055],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1493, 0.1818, 0.1654, 0.1641, 0.1631, 0.1761], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "656\n",
      "656\n",
      "tensor([-0.0863,  0.1503,  0.0453,  0.0167,  0.0718,  0.1197],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1446, 0.1832, 0.1649, 0.1603, 0.1694, 0.1777], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "657\n",
      "657\n",
      "tensor([-0.1187,  0.1119,  0.0625,  0.0228,  0.0679,  0.0742],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1423, 0.1792, 0.1706, 0.1639, 0.1715, 0.1726], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "658\n",
      "658\n",
      "tensor([-0.0995,  0.1595,  0.0663,  0.0240,  0.0360,  0.0823],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1438, 0.1864, 0.1698, 0.1628, 0.1647, 0.1725], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "659\n",
      "659\n",
      "tensor([-0.0670,  0.1402,  0.0481,  0.0632,  0.0627,  0.0932],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1470, 0.1808, 0.1649, 0.1674, 0.1673, 0.1725], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "660\n",
      "660\n",
      "tensor([-0.1086,  0.1297,  0.0432,  0.0254,  0.0555,  0.1063],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1430, 0.1814, 0.1664, 0.1635, 0.1685, 0.1772], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "661\n",
      "661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0886,  0.1564,  0.0797,  0.0394,  0.0630,  0.1152],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1431, 0.1829, 0.1694, 0.1627, 0.1665, 0.1755], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "662\n",
      "662\n",
      "tensor([-0.1265,  0.1363,  0.0383,  0.0266,  0.0373,  0.0866],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1416, 0.1842, 0.1670, 0.1651, 0.1668, 0.1753], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "663\n",
      "663\n",
      "tensor([-0.0873,  0.1390,  0.0704,  0.0721,  0.0770,  0.0906],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1434, 0.1799, 0.1680, 0.1682, 0.1691, 0.1714], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "664\n",
      "664\n",
      "tensor([-0.1128,  0.1387,  0.0406,  0.0391,  0.0421,  0.0786],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1430, 0.1839, 0.1667, 0.1664, 0.1669, 0.1731], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "665\n",
      "665\n",
      "tensor([-0.1037,  0.1566,  0.0400,  0.0384,  0.0611,  0.1148],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1423, 0.1846, 0.1643, 0.1640, 0.1678, 0.1770], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "666\n",
      "666\n",
      "tensor([-0.0861,  0.1279,  0.0645,  0.0447,  0.0797,  0.1105],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1441, 0.1785, 0.1675, 0.1643, 0.1701, 0.1754], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "667\n",
      "667\n",
      "tensor([-0.0938,  0.1146,  0.0359,  0.0197,  0.0611,  0.0832],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1459, 0.1798, 0.1662, 0.1635, 0.1704, 0.1742], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "668\n",
      "668\n",
      "tensor([-0.0825,  0.1331,  0.0782,  0.0209,  0.0510,  0.0792],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1461, 0.1813, 0.1716, 0.1621, 0.1670, 0.1718], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "669\n",
      "669\n",
      "tensor([-0.0899,  0.1378,  0.0460,  0.0272,  0.0712,  0.0844],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1451, 0.1822, 0.1662, 0.1631, 0.1705, 0.1728], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "670\n",
      "670\n",
      "tensor([-0.1033,  0.1624,  0.1023,  0.0464,  0.0254,  0.0921],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1419, 0.1851, 0.1743, 0.1648, 0.1614, 0.1725], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "671\n",
      "671\n",
      "tensor([-0.0919,  0.1198,  0.0552,  0.0269,  0.0676,  0.0624],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1458, 0.1801, 0.1689, 0.1642, 0.1710, 0.1701], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "672\n",
      "672\n",
      "tensor([-0.0834,  0.1221,  0.0445,  0.0334,  0.0690,  0.1058],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1457, 0.1790, 0.1656, 0.1638, 0.1697, 0.1761], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "673\n",
      "673\n",
      "tensor([-0.0969,  0.1132,  0.0719,  0.0104,  0.0521,  0.0630],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1457, 0.1797, 0.1725, 0.1622, 0.1691, 0.1709], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "674\n",
      "674\n",
      "tensor([-0.0613,  0.1460,  0.0340,  0.0675,  0.0719,  0.1162],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1470, 0.1808, 0.1617, 0.1672, 0.1679, 0.1755], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "675\n",
      "675\n",
      "tensor([-0.1043,  0.1172,  0.0399, -0.0357,  0.0565,  0.0951],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1456, 0.1817, 0.1682, 0.1559, 0.1710, 0.1777], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "676\n",
      "676\n",
      "tensor([-0.1046,  0.1468,  0.0643,  0.0696,  0.0554,  0.0838],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1420, 0.1826, 0.1682, 0.1691, 0.1667, 0.1715], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "677\n",
      "677\n",
      "tensor([-0.0960,  0.1095,  0.0618,  0.0125,  0.0724,  0.0862],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1450, 0.1781, 0.1698, 0.1616, 0.1716, 0.1740], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "678\n",
      "678\n",
      "tensor([-0.0822,  0.1438,  0.0500,  0.0413,  0.0568,  0.1052],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1453, 0.1822, 0.1658, 0.1644, 0.1670, 0.1753], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "679\n",
      "679\n",
      "tensor([-0.1144,  0.1432,  0.0727,  0.0280,  0.0573,  0.0990],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1413, 0.1828, 0.1704, 0.1629, 0.1678, 0.1749], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "680\n",
      "680\n",
      "tensor([-0.0959,  0.3118, -0.0247,  0.1773,  0.2074,  0.3516],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1280, 0.1925, 0.1375, 0.1683, 0.1734, 0.2003], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "681\n",
      "681\n",
      "tensor([-0.1014,  0.1251,  0.0595,  0.0210,  0.0686,  0.0887],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1438, 0.1804, 0.1689, 0.1625, 0.1705, 0.1739], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "682\n",
      "682\n",
      "tensor([-0.1014,  0.1251,  0.0595,  0.0210,  0.0686,  0.0887],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1438, 0.1804, 0.1689, 0.1625, 0.1705, 0.1739], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "683\n",
      "683\n",
      "tensor([ 0.0606,  0.0844, -0.0495,  0.3201, -0.0654, -0.0678],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1673, 0.1713, 0.1499, 0.2169, 0.1475, 0.1471], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "684\n",
      "684\n",
      "tensor([-0.0924,  0.1165,  0.0470,  0.0099,  0.0742,  0.0956],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1454, 0.1792, 0.1671, 0.1611, 0.1718, 0.1755], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "685\n",
      "685\n",
      "tensor([-0.0889,  0.1133,  0.0594,  0.0461,  0.0520,  0.0724],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1459, 0.1786, 0.1692, 0.1670, 0.1680, 0.1714], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "686\n",
      "686\n",
      "tensor([-0.1030,  0.1451,  0.0467,  0.0147,  0.0649,  0.0919],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1436, 0.1840, 0.1667, 0.1615, 0.1698, 0.1744], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "687\n",
      "687\n",
      "tensor([-0.1058,  0.1210,  0.0529,  0.0353,  0.0588,  0.0789],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1437, 0.1803, 0.1684, 0.1655, 0.1694, 0.1728], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "688\n",
      "688\n",
      "tensor([-0.0975,  0.1419,  0.0354,  0.0241,  0.0649,  0.0925],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1444, 0.1834, 0.1649, 0.1630, 0.1698, 0.1746], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "689\n",
      "689\n",
      "tensor([-0.1082,  0.1366,  0.0540,  0.0477,  0.0206,  0.0880],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1433, 0.1831, 0.1686, 0.1675, 0.1631, 0.1744], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "690\n",
      "690\n",
      "tensor([-0.0696,  0.0997,  0.0606,  0.0013,  0.0800,  0.0819],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1488, 0.1762, 0.1695, 0.1597, 0.1728, 0.1731], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "691\n",
      "691\n",
      "tensor([-0.0911,  0.1244,  0.0639,  0.0325,  0.0399,  0.1156],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1447, 0.1795, 0.1690, 0.1638, 0.1650, 0.1780], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "692\n",
      "692\n",
      "tensor([-0.0986,  0.1349,  0.0787,  0.0281,  0.0795,  0.1074],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1425, 0.1800, 0.1702, 0.1618, 0.1703, 0.1751], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "693\n",
      "693\n",
      "tensor([-0.1064,  0.1221,  0.0620,  0.0102,  0.0807,  0.0673],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1437, 0.1806, 0.1700, 0.1615, 0.1733, 0.1710], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "694\n",
      "694\n",
      "tensor([-0.1006,  0.1434,  0.0731,  0.0498,  0.0283,  0.0777],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1437, 0.1834, 0.1709, 0.1670, 0.1634, 0.1717], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "695\n",
      "695\n",
      "tensor([-0.1077,  0.1624,  0.0467,  0.0293,  0.0414,  0.0968],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1426, 0.1868, 0.1664, 0.1636, 0.1656, 0.1750], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "696\n",
      "696\n",
      "tensor([-0.0725,  0.1318,  0.0574,  0.0338,  0.0707,  0.0931],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1468, 0.1801, 0.1672, 0.1633, 0.1694, 0.1733], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "697\n",
      "697\n",
      "tensor([-0.0972,  0.1415,  0.0426,  0.0424,  0.0659,  0.1029],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1435, 0.1822, 0.1650, 0.1650, 0.1689, 0.1753], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "698\n",
      "698\n",
      "tensor([-0.0941,  0.1174,  0.0642,  0.0293,  0.0752,  0.0967],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1442, 0.1782, 0.1690, 0.1632, 0.1708, 0.1746], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "699\n",
      "699\n",
      "tensor([-0.1071,  0.1217,  0.0568,  0.0202,  0.0347,  0.0921],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1440, 0.1810, 0.1697, 0.1636, 0.1660, 0.1758], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "700\n",
      "700\n",
      "tensor([-0.0273,  0.1242,  0.0325,  0.0254,  0.0642,  0.0758],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1542, 0.1795, 0.1637, 0.1626, 0.1690, 0.1710], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "701\n",
      "701\n",
      "Episode 0 of 100 episodes                \r",
      "tensor([-0.1099,  0.1430,  0.0450,  0.0346,  0.0753,  0.0984],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1419, 0.1828, 0.1657, 0.1640, 0.1708, 0.1748], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "702\n",
      "702\n",
      "tensor([-0.1403,  0.1520,  0.0802,  0.0704,  0.0487,  0.1158],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1366, 0.1830, 0.1703, 0.1686, 0.1650, 0.1765], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "703\n",
      "703\n",
      "tensor([-0.0761,  0.1333,  0.0299,  0.0382,  0.0415,  0.0845],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1478, 0.1823, 0.1643, 0.1657, 0.1663, 0.1736], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "704\n",
      "704\n",
      "tensor([-0.0475,  0.1201,  0.0769,  0.0164,  0.0690,  0.1104],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1498, 0.1771, 0.1696, 0.1597, 0.1683, 0.1754], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "705\n",
      "705\n",
      "tensor([-0.0900,  0.1256,  0.0900,  0.0532,  0.0702,  0.0744],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1440, 0.1786, 0.1724, 0.1662, 0.1690, 0.1697], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "706\n",
      "706\n",
      "tensor([-0.1243,  0.1699,  0.0701,  0.0755,  0.0172,  0.0864],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1396, 0.1873, 0.1695, 0.1704, 0.1608, 0.1723], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "707\n",
      "707\n",
      "tensor([-0.0716,  0.1069,  0.0518, -0.0012,  0.0569,  0.1372],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1477, 0.1766, 0.1671, 0.1585, 0.1680, 0.1820], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "708\n",
      "708\n",
      "tensor([-0.1171,  0.1297,  0.0207,  0.0315,  0.0603,  0.0860],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1427, 0.1827, 0.1638, 0.1656, 0.1704, 0.1748], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "709\n",
      "709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0923,  0.1473,  0.1050,  0.0157,  0.0472,  0.1157],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1432, 0.1820, 0.1744, 0.1595, 0.1646, 0.1763], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "710\n",
      "710\n",
      "tensor([-0.0737,  0.1180,  0.0371,  0.0546,  0.0362,  0.0753],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1483, 0.1797, 0.1657, 0.1686, 0.1655, 0.1722], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "711\n",
      "711\n",
      "tensor([-0.0967,  0.1455,  0.0407,  0.0535,  0.0851,  0.0946],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1430, 0.1822, 0.1640, 0.1662, 0.1715, 0.1731], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "712\n",
      "712\n",
      "tensor([-0.1145,  0.1087,  0.0353,  0.0051,  0.0650,  0.0829],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1438, 0.1798, 0.1670, 0.1621, 0.1721, 0.1752], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "713\n",
      "713\n",
      "tensor([-0.0716,  0.1540,  0.0621,  0.0474,  0.0761,  0.1190],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1451, 0.1818, 0.1659, 0.1634, 0.1682, 0.1756], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "714\n",
      "714\n",
      "tensor([-0.0983,  0.1485,  0.0484,  0.0311,  0.0752,  0.0699],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1439, 0.1842, 0.1667, 0.1638, 0.1712, 0.1703], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "715\n",
      "715\n",
      "tensor([-0.1111,  0.1492,  0.0627,  0.0246,  0.0488,  0.0904],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1423, 0.1846, 0.1693, 0.1629, 0.1669, 0.1740], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "716\n",
      "716\n",
      "tensor([-0.1073,  0.1290,  0.0276,  0.0274,  0.0437,  0.0710],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1446, 0.1832, 0.1655, 0.1655, 0.1682, 0.1729], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "717\n",
      "717\n",
      "tensor([-0.0699,  0.1438,  0.0594,  0.0187,  0.0433,  0.1261],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1469, 0.1820, 0.1672, 0.1606, 0.1646, 0.1788], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "718\n",
      "718\n",
      "tensor([-0.1092,  0.1420,  0.0476,  0.0237,  0.0447,  0.0903],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1432, 0.1840, 0.1675, 0.1635, 0.1670, 0.1748], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "719\n",
      "719\n",
      "tensor([-0.0723,  0.1277,  0.0564,  0.0238,  0.1016,  0.1135],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1459, 0.1782, 0.1659, 0.1606, 0.1736, 0.1757], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "720\n",
      "720\n",
      "tensor([-0.0954,  0.1176,  0.0561,  0.0394,  0.0683,  0.0729],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1448, 0.1792, 0.1685, 0.1657, 0.1705, 0.1713], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "721\n",
      "721\n",
      "tensor([-0.0935,  0.1588,  0.0398,  0.0371,  0.0490,  0.1011],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1441, 0.1855, 0.1647, 0.1643, 0.1662, 0.1751], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "722\n",
      "722\n",
      "tensor([-0.0749,  0.1297,  0.0905,  0.0474,  0.0498,  0.0908],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1460, 0.1791, 0.1722, 0.1650, 0.1654, 0.1723], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "723\n",
      "723\n",
      "tensor([-0.1297,  0.1237,  0.0249,  0.0339,  0.0509,  0.1087],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1408, 0.1815, 0.1644, 0.1659, 0.1687, 0.1787], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "724\n",
      "724\n",
      "tensor([-0.0584,  0.1292,  0.0944,  0.0469,  0.0810,  0.0581],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1480, 0.1786, 0.1725, 0.1645, 0.1702, 0.1663], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "725\n",
      "725\n",
      "tensor([-0.0922,  0.1281,  0.0466,  0.0504,  0.0820,  0.1049],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1437, 0.1792, 0.1651, 0.1658, 0.1711, 0.1751], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "726\n",
      "726\n",
      "tensor([-0.1142,  0.1140,  0.0876,  0.0200,  0.0499,  0.1034],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1420, 0.1783, 0.1737, 0.1623, 0.1673, 0.1765], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "727\n",
      "727\n",
      "tensor([-0.0747,  0.1447,  0.0219,  0.0002,  0.0538,  0.0968],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1482, 0.1845, 0.1632, 0.1597, 0.1685, 0.1759], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "728\n",
      "728\n",
      "tensor([-0.1169,  0.0935,  0.0298,  0.0190,  0.0683,  0.0756],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1438, 0.1775, 0.1665, 0.1647, 0.1731, 0.1743], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "729\n",
      "729\n",
      "tensor([-0.0671,  0.1591,  0.0640,  0.0088,  0.0722,  0.0901],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1472, 0.1846, 0.1679, 0.1588, 0.1692, 0.1723], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "730\n",
      "730\n",
      "tensor([-0.1221,  0.3361,  0.0024,  0.1780,  0.1763,  0.3594],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1245, 0.1969, 0.1410, 0.1681, 0.1678, 0.2016], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "731\n",
      "731\n",
      "tensor([-0.1014,  0.1251,  0.0595,  0.0210,  0.0686,  0.0887],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1438, 0.1804, 0.1689, 0.1625, 0.1705, 0.1739], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "732\n",
      "732\n",
      "tensor([-0.1014,  0.1251,  0.0595,  0.0210,  0.0686,  0.0887],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1438, 0.1804, 0.1689, 0.1625, 0.1705, 0.1739], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "733\n",
      "733\n",
      "tensor([-0.1014,  0.1251,  0.0595,  0.0210,  0.0686,  0.0887],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1438, 0.1804, 0.1689, 0.1625, 0.1705, 0.1739], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "734\n",
      "734\n",
      "tensor([ 0.0603,  0.0842, -0.0534,  0.3123, -0.0521, -0.0417],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1667, 0.1707, 0.1488, 0.2144, 0.1489, 0.1505], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "735\n",
      "735\n",
      "tensor([-0.0928,  0.1219,  0.0315,  0.0208,  0.0821,  0.1073],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1448, 0.1795, 0.1640, 0.1623, 0.1725, 0.1769], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "736\n",
      "736\n",
      "tensor([-0.0622,  0.1393,  0.1040,  0.0678,  0.0623,  0.0971],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1460, 0.1786, 0.1724, 0.1663, 0.1654, 0.1712], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "737\n",
      "737\n",
      "tensor([-0.1126,  0.1329,  0.0416,  0.0234,  0.0694,  0.0739],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1430, 0.1827, 0.1668, 0.1638, 0.1715, 0.1723], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "738\n",
      "738\n",
      "tensor([-0.1052,  0.1423,  0.0686,  0.0431,  0.0675,  0.1005],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1419, 0.1817, 0.1688, 0.1646, 0.1686, 0.1743], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "739\n",
      "739\n",
      "tensor([-0.0806,  0.1519,  0.0305,  0.0274,  0.0691,  0.0734],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1466, 0.1850, 0.1638, 0.1633, 0.1703, 0.1710], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "740\n",
      "740\n",
      "tensor([-0.1040,  0.1352,  0.0395,  0.0107,  0.0420,  0.1270],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1436, 0.1824, 0.1658, 0.1611, 0.1662, 0.1809], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "741\n",
      "741\n",
      "tensor([-0.0887,  0.1194,  0.0578,  0.0410,  0.0850,  0.0778],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1450, 0.1785, 0.1678, 0.1650, 0.1725, 0.1712], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "742\n",
      "742\n",
      "tensor([-0.1126,  0.1406,  0.0479,  0.0257,  0.0615,  0.1013],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1421, 0.1830, 0.1668, 0.1631, 0.1691, 0.1759], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "743\n",
      "743\n",
      "tensor([-0.1186,  0.1349,  0.0585,  0.0559,  0.0540,  0.1117],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1404, 0.1810, 0.1677, 0.1672, 0.1669, 0.1768], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "744\n",
      "744\n",
      "tensor([-0.0888,  0.1308,  0.0815,  0.0072,  0.0451,  0.1152],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1449, 0.1805, 0.1718, 0.1595, 0.1657, 0.1777], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "745\n",
      "745\n",
      "tensor([-0.0982,  0.1340,  0.0451,  0.0166,  0.0520,  0.0821],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1450, 0.1829, 0.1673, 0.1626, 0.1685, 0.1736], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "746\n",
      "746\n",
      "tensor([-0.1021,  0.1270,  0.0483,  0.0225,  0.0931,  0.0994],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1430, 0.1799, 0.1663, 0.1620, 0.1739, 0.1750], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "747\n",
      "747\n",
      "tensor([-0.0904,  0.1359,  0.0663,  0.0073,  0.0467,  0.0969],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1454, 0.1823, 0.1700, 0.1603, 0.1667, 0.1753], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "748\n",
      "748\n",
      "tensor([-0.0985,  0.1375,  0.0600,  0.0347,  0.0748,  0.0961],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1432, 0.1813, 0.1678, 0.1636, 0.1703, 0.1739], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "749\n",
      "749\n",
      "tensor([-0.1149,  0.1409,  0.0715,  0.0681,  0.0593,  0.0879],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1406, 0.1816, 0.1694, 0.1688, 0.1674, 0.1722], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "750\n",
      "750\n",
      "tensor([-0.0869,  0.1454,  0.0455,  0.0212,  0.0465,  0.1240],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1450, 0.1830, 0.1656, 0.1616, 0.1657, 0.1791], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "751\n",
      "751\n",
      "tensor([-0.1022,  0.0997,  0.0472,  0.0550,  0.0587,  0.0731],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1445, 0.1768, 0.1678, 0.1691, 0.1697, 0.1722], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "752\n",
      "752\n",
      "tensor([-0.0660,  0.1646,  0.0854,  0.0657,  0.0892,  0.1103],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1444, 0.1819, 0.1680, 0.1647, 0.1687, 0.1723], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "753\n",
      "753\n",
      "tensor([-0.1055,  0.1378,  0.0609,  0.0177,  0.0409,  0.0769],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1440, 0.1836, 0.1700, 0.1629, 0.1667, 0.1728], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "754\n",
      "754\n",
      "tensor([-0.1216,  0.1270,  0.0394,  0.0188,  0.0587,  0.0894],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1420, 0.1821, 0.1669, 0.1635, 0.1701, 0.1754], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "755\n",
      "755\n",
      "tensor([-0.0702,  0.1595,  0.0565,  0.0249,  0.0625,  0.0952],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1467, 0.1846, 0.1666, 0.1614, 0.1676, 0.1731], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "756\n",
      "756\n",
      "tensor([-0.1034,  0.1055,  0.0800,  0.0072,  0.0769,  0.1314],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1426, 0.1757, 0.1713, 0.1593, 0.1708, 0.1803], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "757\n",
      "757\n",
      "tensor([-0.0795,  0.1682,  0.0516,  0.0096,  0.0392,  0.1002],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1463, 0.1874, 0.1667, 0.1599, 0.1647, 0.1751], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "758\n",
      "758\n",
      "tensor([-0.1120,  0.1030,  0.0410,  0.0261,  0.0566,  0.0931],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1436, 0.1780, 0.1673, 0.1648, 0.1700, 0.1763], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "759\n",
      "759\n",
      "tensor([-0.0677,  0.1468,  0.0454,  0.1090,  0.0329,  0.0618],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1471, 0.1823, 0.1648, 0.1756, 0.1627, 0.1675], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "760\n",
      "760\n",
      "tensor([-0.1416,  0.1191,  0.0664,  0.0306,  0.0674,  0.1067],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1383, 0.1795, 0.1703, 0.1643, 0.1704, 0.1773], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "761\n",
      "761\n",
      "tensor([-0.0855,  0.1231,  0.0340,  0.0203,  0.0554,  0.1075],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1463, 0.1802, 0.1649, 0.1626, 0.1685, 0.1775], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "762\n",
      "762\n",
      "tensor([-0.0404,  0.1647,  0.0460,  0.0573,  0.0234,  0.0787],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1512, 0.1856, 0.1649, 0.1668, 0.1612, 0.1703], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "763\n",
      "763\n",
      "tensor([-0.0777,  0.1148,  0.0735,  0.0135,  0.0611,  0.0775],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1473, 0.1786, 0.1714, 0.1614, 0.1693, 0.1720], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "764\n",
      "764\n",
      "tensor([-0.0814,  0.1442,  0.0347,  0.0330,  0.0614,  0.1124],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1457, 0.1825, 0.1636, 0.1633, 0.1680, 0.1768], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "765\n",
      "765\n",
      "tensor([-0.1152,  0.1556,  0.0592,  0.0294,  0.0475,  0.0866],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1417, 0.1858, 0.1687, 0.1637, 0.1667, 0.1734], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "766\n",
      "766\n",
      "tensor([-0.0799,  0.1318,  0.0593,  0.0330,  0.0360,  0.1275],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1458, 0.1802, 0.1676, 0.1632, 0.1637, 0.1794], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "767\n",
      "767\n",
      "tensor([-0.1051,  0.1463,  0.0664,  0.0071,  0.0521,  0.0366],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1446, 0.1860, 0.1717, 0.1618, 0.1692, 0.1667], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "768\n",
      "768\n",
      "tensor([-0.0917,  0.1548,  0.0574,  0.0768,  0.0634,  0.0947],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1429, 0.1829, 0.1659, 0.1692, 0.1669, 0.1722], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "769\n",
      "769\n",
      "tensor([-0.0876,  0.0919,  0.0460,  0.0167,  0.0279,  0.1105],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1472, 0.1762, 0.1683, 0.1634, 0.1653, 0.1795], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "770\n",
      "770\n",
      "tensor([-0.0907,  0.1447,  0.0818,  0.0282,  0.0697,  0.0832],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1440, 0.1822, 0.1711, 0.1622, 0.1691, 0.1714], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "771\n",
      "771\n",
      "tensor([-0.0969,  0.1430,  0.0262,  0.0120,  0.0375,  0.0869],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1457, 0.1852, 0.1648, 0.1625, 0.1667, 0.1751], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "772\n",
      "772\n",
      "tensor([-0.0837,  0.1206,  0.0955,  0.0589,  0.1037,  0.1021],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1431, 0.1756, 0.1712, 0.1651, 0.1726, 0.1724], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "773\n",
      "773\n",
      "tensor([-0.0798,  0.1413,  0.0489,  0.0517,  0.0169,  0.0837],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1470, 0.1833, 0.1671, 0.1676, 0.1619, 0.1731], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "774\n",
      "774\n",
      "tensor([-0.0939,  0.1148,  0.0439,  0.0227,  0.0493,  0.0625],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1465, 0.1805, 0.1681, 0.1646, 0.1690, 0.1713], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "775\n",
      "775\n",
      "tensor([-0.0816,  0.1154,  0.0481,  0.0398,  0.0696,  0.1241],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1454, 0.1771, 0.1656, 0.1642, 0.1691, 0.1786], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "776\n",
      "776\n",
      "tensor([-0.1056,  0.1564,  0.0588,  0.0166,  0.0636,  0.0600],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1434, 0.1864, 0.1690, 0.1621, 0.1699, 0.1693], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "777\n",
      "777\n",
      "tensor([-0.0963,  0.1200,  0.0766,  0.0032,  0.0492,  0.1004],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1447, 0.1797, 0.1721, 0.1599, 0.1674, 0.1762], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "778\n",
      "778\n",
      "tensor([-0.0850,  0.1371,  0.0856,  0.0400,  0.0946,  0.1267],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1429, 0.1784, 0.1694, 0.1619, 0.1710, 0.1765], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "779\n",
      "779\n",
      "tensor([-0.1076,  0.1096,  0.0399,  0.0641,  0.0734,  0.0975],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1426, 0.1771, 0.1652, 0.1693, 0.1708, 0.1750], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "780\n",
      "780\n",
      "tensor([-0.1192,  0.1274,  0.0413,  0.0187,  0.0502,  0.1207],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1417, 0.1813, 0.1664, 0.1626, 0.1679, 0.1801], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "781\n",
      "781\n",
      "tensor([-0.0790,  0.1324,  0.0473,  0.0048,  0.0569,  0.0308],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1488, 0.1839, 0.1689, 0.1618, 0.1705, 0.1661], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "782\n",
      "782\n",
      "tensor([-0.1236,  0.1354,  0.0603,  0.0156,  0.0592,  0.1386],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1399, 0.1813, 0.1682, 0.1608, 0.1680, 0.1819], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "783\n",
      "783\n",
      "tensor([-0.0883,  0.1313,  0.0457,  0.0780,  0.0734,  0.0743],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1445, 0.1799, 0.1652, 0.1706, 0.1698, 0.1700], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "784\n",
      "784\n",
      "tensor([-0.1072,  0.1571,  0.0553,  0.0048,  0.0286,  0.0967],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1435, 0.1869, 0.1688, 0.1605, 0.1644, 0.1759], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "785\n",
      "785\n",
      "tensor([-0.0653,  0.1225,  0.0462,  0.0552,  0.0973,  0.0561],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1480, 0.1785, 0.1654, 0.1669, 0.1741, 0.1671], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "786\n",
      "786\n",
      "tensor([-0.1249,  0.1152,  0.0334,  0.0473,  0.0600,  0.1346],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1402, 0.1783, 0.1643, 0.1666, 0.1687, 0.1818], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "787\n",
      "787\n",
      "tensor([-0.0920,  0.1259,  0.0506,  0.0173,  0.0653,  0.0833],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1455, 0.1809, 0.1678, 0.1623, 0.1702, 0.1733], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "788\n",
      "788\n",
      "tensor([-0.1126,  0.1201,  0.0720,  0.0629,  0.0792,  0.1560],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1394, 0.1759, 0.1676, 0.1661, 0.1688, 0.1823], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "789\n",
      "789\n",
      "tensor([-0.0882,  0.1209,  0.0685,  0.0348,  0.0780,  0.0783],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1450, 0.1788, 0.1696, 0.1640, 0.1713, 0.1713], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "790\n",
      "790\n",
      "tensor([-0.0877,  0.1280,  0.0415,  0.0307,  0.0547,  0.0836],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1461, 0.1813, 0.1663, 0.1645, 0.1685, 0.1734], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "791\n",
      "791\n",
      "tensor([-0.0959,  0.1448,  0.0934,  0.0024,  0.0615,  0.1048],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1433, 0.1823, 0.1732, 0.1581, 0.1678, 0.1752], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "792\n",
      "792\n",
      "tensor([-0.1094,  0.1126,  0.0404,  0.0008,  0.0308,  0.1100],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1445, 0.1804, 0.1678, 0.1613, 0.1662, 0.1799], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "793\n",
      "793\n",
      "tensor([-0.0898,  0.1185,  0.0408,  0.0375,  0.0623,  0.1018],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1453, 0.1790, 0.1656, 0.1650, 0.1692, 0.1760], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "794\n",
      "794\n",
      "tensor([-0.1204,  0.1441,  0.0682,  0.0236,  0.0573,  0.0923],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1409, 0.1836, 0.1702, 0.1627, 0.1683, 0.1743], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "795\n",
      "795\n",
      "tensor([-0.0534,  0.0936,  0.0793,  0.0364,  0.0303,  0.0761],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1511, 0.1750, 0.1725, 0.1652, 0.1643, 0.1719], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "796\n",
      "796\n",
      "tensor([-0.0898,  0.1157,  0.0412,  0.0503,  0.1059,  0.1154],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1436, 0.1764, 0.1637, 0.1652, 0.1747, 0.1763], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "797\n",
      "797\n",
      "tensor([-0.1085,  0.1695,  0.0447,  0.0466,  0.0134,  0.0884],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1428, 0.1886, 0.1665, 0.1668, 0.1614, 0.1739], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "798\n",
      "798\n",
      "tensor([-0.1045,  0.1300,  0.0685,  0.0300,  0.0521,  0.0749],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1436, 0.1816, 0.1707, 0.1643, 0.1680, 0.1718], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "799\n",
      "799\n",
      "tensor([-0.1031,  0.1446,  0.0690,  0.0345,  0.0416,  0.1243],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1423, 0.1823, 0.1690, 0.1633, 0.1645, 0.1786], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "800\n",
      "800\n",
      "tensor([-0.0836,  0.1336,  0.0634,  0.0254,  0.0755,  0.1156],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1447, 0.1799, 0.1677, 0.1614, 0.1697, 0.1766], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "801\n",
      "801\n",
      "Episode 0 of 100 episodes                \r",
      "tensor([-0.0811,  0.1408,  0.0756,  0.0464,  0.0391,  0.0700],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1461, 0.1824, 0.1709, 0.1660, 0.1648, 0.1699], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "802\n",
      "802\n",
      "tensor([-0.0940,  0.1309,  0.0432,  0.0461,  0.0917,  0.1058],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1434, 0.1795, 0.1644, 0.1649, 0.1726, 0.1751], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "803\n",
      "803\n",
      "tensor([-0.1038,  0.1256,  0.0727,  0.0396,  0.0617,  0.0929],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1428, 0.1796, 0.1704, 0.1648, 0.1685, 0.1738], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "804\n",
      "804\n",
      "tensor([-0.0832,  0.1508,  0.0605,  0.0302,  0.0574,  0.0854],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1455, 0.1839, 0.1680, 0.1630, 0.1675, 0.1722], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "805\n",
      "805\n",
      "tensor([-0.0685,  0.1500,  0.0581, -0.0217,  0.0568,  0.0877],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1486, 0.1849, 0.1686, 0.1557, 0.1684, 0.1737], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "806\n",
      "806\n",
      "tensor([-0.1127,  0.1352,  0.0449,  0.0401,  0.0702,  0.0837],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1421, 0.1821, 0.1664, 0.1656, 0.1707, 0.1730], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "807\n",
      "807\n",
      "tensor([-0.0575,  0.1133,  0.0657,  0.0406,  0.0821,  0.1046],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1482, 0.1758, 0.1677, 0.1635, 0.1704, 0.1743], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "808\n",
      "808\n",
      "tensor([-0.0977,  0.1686,  0.0498,  0.0281,  0.0260,  0.0734],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1446, 0.1887, 0.1676, 0.1640, 0.1636, 0.1716], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "809\n",
      "809\n",
      "tensor([-0.1230,  0.1329,  0.0560,  0.0581,  0.0603,  0.1014],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1401, 0.1809, 0.1675, 0.1679, 0.1683, 0.1753], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "810\n",
      "810\n",
      "tensor([-0.0689,  0.1517,  0.0754,  0.0261,  0.0368,  0.0884],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1474, 0.1838, 0.1703, 0.1621, 0.1638, 0.1725], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "811\n",
      "811\n",
      "tensor([-0.0779,  0.1258,  0.0594,  0.0287,  0.0723,  0.0907],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1464, 0.1795, 0.1679, 0.1628, 0.1701, 0.1733], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "812\n",
      "812\n",
      "tensor([-0.1311,  0.1704,  0.0398,  0.0196,  0.0268,  0.1160],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1398, 0.1890, 0.1659, 0.1626, 0.1637, 0.1790], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "813\n",
      "813\n",
      "tensor([-0.0761,  0.1096,  0.0583,  0.0036,  0.0637,  0.0927],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1478, 0.1780, 0.1691, 0.1601, 0.1700, 0.1750], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "814\n",
      "814\n",
      "tensor([-0.1094,  0.1483,  0.0416,  0.0253,  0.0464,  0.0935],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1430, 0.1850, 0.1663, 0.1636, 0.1671, 0.1751], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "815\n",
      "815\n",
      "tensor([-0.0963,  0.1294,  0.0581,  0.0779,  0.0774,  0.0895],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1428, 0.1789, 0.1666, 0.1699, 0.1698, 0.1719], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "816\n",
      "816\n",
      "tensor([-0.0726,  0.1208,  0.1029,  0.0041,  0.0722,  0.1268],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1457, 0.1768, 0.1737, 0.1574, 0.1684, 0.1779], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "817\n",
      "817\n",
      "tensor([-0.0842,  0.1515,  0.0711,  0.0423,  0.0302,  0.0865],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1454, 0.1841, 0.1699, 0.1650, 0.1631, 0.1725], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "818\n",
      "818\n",
      "tensor([-0.0727,  0.1250,  0.1004,  0.0167,  0.0639,  0.0801],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1468, 0.1789, 0.1745, 0.1605, 0.1683, 0.1710], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "819\n",
      "819\n",
      "tensor([-0.1124,  0.1357,  0.0414,  0.0204,  0.0596,  0.0951],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1427, 0.1829, 0.1664, 0.1630, 0.1695, 0.1756], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "820\n",
      "820\n",
      "tensor([-0.1240,  0.1437,  0.0296,  0.0175,  0.0832,  0.1197],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1402, 0.1833, 0.1635, 0.1615, 0.1725, 0.1789], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "821\n",
      "821\n",
      "tensor([-0.0720,  0.1277,  0.0828,  0.0524,  0.0009,  0.0982],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1474, 0.1800, 0.1721, 0.1670, 0.1586, 0.1748], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "822\n",
      "822\n",
      "tensor([-0.0572,  0.1688,  0.0478,  0.0223,  0.0650,  0.0741],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1489, 0.1866, 0.1653, 0.1612, 0.1682, 0.1698], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "823\n",
      "823\n",
      "tensor([-0.1426,  0.1561,  0.0598,  0.0325,  0.0581,  0.0939],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1379, 0.1859, 0.1688, 0.1643, 0.1685, 0.1747], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "824\n",
      "824\n",
      "tensor([-0.1223,  0.1760,  0.0501,  0.0125,  0.0679,  0.1141],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1397, 0.1883, 0.1660, 0.1599, 0.1690, 0.1770], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "825\n",
      "825\n",
      "tensor([-0.0848,  0.1099,  0.0398,  0.0717,  0.0778,  0.0739],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1457, 0.1770, 0.1650, 0.1703, 0.1714, 0.1707], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "826\n",
      "826\n",
      "tensor([-0.0812,  0.1319,  0.0532,  0.0258,  0.0744,  0.1130],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1454, 0.1799, 0.1663, 0.1618, 0.1699, 0.1766], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "827\n",
      "827\n",
      "tensor([-0.0830,  0.1260,  0.1126, -0.0008,  0.0636,  0.1208],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1445, 0.1781, 0.1758, 0.1569, 0.1674, 0.1772], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "828\n",
      "828\n",
      "tensor([-0.0911,  0.1112,  0.0470,  0.0355,  0.0723,  0.0591],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1461, 0.1788, 0.1677, 0.1658, 0.1720, 0.1697], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "829\n",
      "829\n",
      "tensor([-0.0964,  0.1399,  0.0504,  0.0049,  0.0374,  0.1038],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1450, 0.1837, 0.1679, 0.1605, 0.1658, 0.1771], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "830\n",
      "830\n",
      "tensor([-0.0665,  0.1421,  0.0412,  0.0232,  0.0779,  0.0571],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1487, 0.1831, 0.1656, 0.1626, 0.1718, 0.1682], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "831\n",
      "831\n",
      "tensor([-0.1375,  0.1141,  0.0635,  0.0236,  0.0917,  0.1313],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1379, 0.1774, 0.1687, 0.1621, 0.1735, 0.1805], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "832\n",
      "832\n",
      "tensor([-0.0711,  0.1450,  0.0802,  0.0121,  0.0397,  0.0990],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1472, 0.1827, 0.1712, 0.1600, 0.1644, 0.1745], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "833\n",
      "833\n",
      "tensor([-0.1115,  0.1413,  0.0507,  0.0696,  0.0689,  0.1122],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1406, 0.1811, 0.1654, 0.1686, 0.1684, 0.1759], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "834\n",
      "834\n",
      "tensor([-0.0926,  0.1262,  0.0853,  0.0289,  0.0508,  0.0591],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1452, 0.1807, 0.1735, 0.1640, 0.1676, 0.1690], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "835\n",
      "835\n",
      "tensor([-0.0641,  0.1575,  0.0468,  0.0864,  0.0335,  0.1055],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1467, 0.1831, 0.1639, 0.1706, 0.1618, 0.1739], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "836\n",
      "836\n",
      "tensor([-0.0902,  0.1381,  0.0839,  0.0107,  0.0622,  0.1190],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1439, 0.1808, 0.1712, 0.1592, 0.1676, 0.1774], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "837\n",
      "837\n",
      "tensor([-0.0774,  0.1225,  0.0336,  0.0162,  0.1061,  0.0400],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1479, 0.1806, 0.1652, 0.1624, 0.1777, 0.1663], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "838\n",
      "838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0787,  0.1132,  0.0776,  0.0327,  0.0429,  0.1217],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1460, 0.1769, 0.1707, 0.1632, 0.1649, 0.1784], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "839\n",
      "839\n",
      "tensor([-0.1086,  0.1458,  0.0513,  0.0516,  0.0319,  0.0730],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1431, 0.1846, 0.1679, 0.1680, 0.1647, 0.1716], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "840\n",
      "840\n",
      "tensor([-0.0903,  0.1279,  0.0327,  0.0115,  0.0848,  0.0739],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1459, 0.1815, 0.1650, 0.1616, 0.1739, 0.1720], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "841\n",
      "841\n",
      "tensor([-0.0996,  0.1412,  0.0562,  0.0237,  0.0073,  0.1117],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1445, 0.1839, 0.1689, 0.1635, 0.1608, 0.1785], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "842\n",
      "842\n",
      "tensor([-0.1007,  0.1368,  0.0505,  0.0458,  0.1104,  0.1178],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1415, 0.1794, 0.1646, 0.1638, 0.1747, 0.1760], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "843\n",
      "843\n",
      "tensor([-0.0886,  0.1474,  0.0423,  0.0370,  0.0366,  0.1210],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1448, 0.1833, 0.1650, 0.1642, 0.1641, 0.1786], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "844\n",
      "844\n",
      "tensor([-0.0650,  0.1137,  0.0738,  0.0301,  0.0604,  0.0972],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1481, 0.1770, 0.1701, 0.1628, 0.1678, 0.1741], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "845\n",
      "845\n",
      "tensor([-0.0996,  0.1309,  0.0608,  0.0246,  0.0624,  0.1175],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1432, 0.1803, 0.1681, 0.1621, 0.1684, 0.1779], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "846\n",
      "846\n",
      "tensor([-0.1234,  0.1100,  0.0373,  0.0080,  0.0729,  0.0883],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1422, 0.1796, 0.1670, 0.1622, 0.1731, 0.1758], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "847\n",
      "847\n",
      "tensor([-0.0524,  0.1295,  0.0555,  0.0428,  0.0839,  0.1242],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1481, 0.1776, 0.1650, 0.1629, 0.1697, 0.1767], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "848\n",
      "848\n",
      "tensor([-0.0899,  0.1586,  0.0365,  0.0693,  0.0295,  0.1091],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1442, 0.1848, 0.1636, 0.1690, 0.1624, 0.1759], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "849\n",
      "849\n",
      "tensor([-0.0874,  0.1000,  0.0357,  0.0427,  0.0885,  0.0611],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1464, 0.1766, 0.1656, 0.1668, 0.1746, 0.1699], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "850\n",
      "850\n",
      "tensor([-0.1008,  0.1516,  0.0375,  0.0080,  0.0559,  0.0830],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1445, 0.1860, 0.1659, 0.1611, 0.1690, 0.1736], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "851\n",
      "851\n",
      "tensor([-0.1364,  0.1070,  0.0603,  0.0464,  0.0946,  0.1139],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1382, 0.1762, 0.1682, 0.1659, 0.1741, 0.1775], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "852\n",
      "852\n",
      "tensor([-0.1079,  0.1512,  0.0395,  0.0406,  0.0517,  0.1021],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1424, 0.1846, 0.1650, 0.1652, 0.1671, 0.1757], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "853\n",
      "853\n",
      "tensor([-0.0923,  0.1411,  0.0217,  0.0095,  0.0566,  0.1063],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1455, 0.1838, 0.1631, 0.1611, 0.1689, 0.1775], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "854\n",
      "854\n",
      "tensor([-0.0917,  0.1341,  0.0696,  0.0203,  0.0564,  0.0886],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1448, 0.1815, 0.1702, 0.1620, 0.1680, 0.1735], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "855\n",
      "855\n",
      "tensor([-0.0917,  0.1388,  0.0704,  0.0118,  0.0508,  0.0971],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1448, 0.1824, 0.1703, 0.1606, 0.1670, 0.1749], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "856\n",
      "856\n",
      "tensor([-0.1241,  0.1253,  0.0463,  0.0465,  0.0784,  0.0996],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1402, 0.1800, 0.1663, 0.1663, 0.1717, 0.1754], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "857\n",
      "857\n",
      "tensor([-0.0195,  0.1422,  0.0614,  0.0548,  0.0493,  0.0728],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1537, 0.1807, 0.1667, 0.1656, 0.1647, 0.1686], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "858\n",
      "858\n",
      "tensor([-0.1034,  0.1137,  0.0367,  0.0159,  0.0790,  0.0867],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1443, 0.1793, 0.1660, 0.1626, 0.1732, 0.1745], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "859\n",
      "859\n",
      "tensor([-0.1074,  0.1561,  0.0529,  0.0205,  0.0090,  0.1158],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1432, 0.1863, 0.1680, 0.1627, 0.1608, 0.1790], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "860\n",
      "860\n",
      "tensor([-0.0989,  0.1593,  0.0452,  0.0541,  0.0916,  0.0778],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1425, 0.1845, 0.1646, 0.1661, 0.1724, 0.1700], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "861\n",
      "861\n",
      "tensor([-0.0650,  0.1360,  0.0737,  0.0287,  0.0797,  0.0860],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1473, 0.1801, 0.1692, 0.1618, 0.1702, 0.1713], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "862\n",
      "862\n",
      "tensor([-0.1356,  0.1172,  0.0169,  0.0184,  0.0517,  0.0914],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1413, 0.1819, 0.1645, 0.1648, 0.1703, 0.1772], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "863\n",
      "863\n",
      "tensor([-0.0833,  0.1340,  0.0739,  0.0290,  0.0622,  0.1024],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1451, 0.1803, 0.1698, 0.1623, 0.1678, 0.1747], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "864\n",
      "864\n",
      "tensor([-0.0703,  0.1323,  0.0557,  0.0447,  0.0718,  0.1075],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1465, 0.1793, 0.1661, 0.1643, 0.1688, 0.1750], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "865\n",
      "865\n",
      "tensor([-0.0956,  0.1429,  0.0411,  0.0278,  0.0769,  0.1103],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1436, 0.1823, 0.1646, 0.1625, 0.1706, 0.1764], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "866\n",
      "866\n",
      "tensor([-0.0845,  0.1408,  0.0605,  0.0171,  0.0273,  0.0742],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1469, 0.1841, 0.1699, 0.1626, 0.1643, 0.1722], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "867\n",
      "867\n",
      "tensor([-0.1004,  0.1041,  0.0661,  0.0280,  0.0848,  0.1199],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1430, 0.1754, 0.1689, 0.1625, 0.1720, 0.1782], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "868\n",
      "868\n",
      "tensor([-0.1041,  0.1252,  0.0319,  0.0065,  0.0421,  0.1039],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1447, 0.1820, 0.1658, 0.1617, 0.1675, 0.1782], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "869\n",
      "869\n",
      "tensor([-0.0540,  0.1452,  0.0327,  0.0161,  0.0781,  0.0844],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1499, 0.1829, 0.1634, 0.1607, 0.1710, 0.1721], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "870\n",
      "870\n",
      "tensor([-0.1075,  0.1471,  0.0800,  0.0200,  0.0623,  0.0746],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1425, 0.1838, 0.1719, 0.1619, 0.1689, 0.1710], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "871\n",
      "871\n",
      "tensor([-0.1060,  0.1079,  0.0506,  0.0435,  0.0630,  0.0990],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1432, 0.1774, 0.1675, 0.1664, 0.1696, 0.1758], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "872\n",
      "872\n",
      "tensor([-0.0707,  0.1450,  0.0417,  0.0594,  0.0071,  0.0982],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1478, 0.1835, 0.1654, 0.1684, 0.1598, 0.1750], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "873\n",
      "873\n",
      "tensor([-0.1010,  0.1344,  0.0331, -0.0171,  0.0892,  0.1344],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1434, 0.1815, 0.1640, 0.1560, 0.1735, 0.1815], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "874\n",
      "874\n",
      "tensor([-0.0897,  0.1373,  0.0693,  0.0475,  0.0599,  0.0946],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1441, 0.1809, 0.1690, 0.1653, 0.1674, 0.1733], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "875\n",
      "875\n",
      "tensor([-0.0885,  0.1258,  0.0539,  0.0339,  0.0552,  0.1033],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1452, 0.1799, 0.1674, 0.1641, 0.1676, 0.1759], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "876\n",
      "876\n",
      "tensor([-0.0728,  0.1375,  0.0638,  0.0255,  0.0656,  0.1121],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1463, 0.1805, 0.1677, 0.1614, 0.1680, 0.1760], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "877\n",
      "877\n",
      "tensor([-0.1273,  0.1347,  0.0595,  0.0695,  0.0866,  0.0656],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1394, 0.1812, 0.1680, 0.1697, 0.1727, 0.1691], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "878\n",
      "878\n",
      "tensor([-0.0853,  0.1141,  0.0325, -0.0194,  0.0583,  0.0666],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1485, 0.1813, 0.1671, 0.1587, 0.1715, 0.1729], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "879\n",
      "879\n",
      "tensor([-0.0821,  0.1372,  0.0365,  0.0457,  0.0517,  0.0791],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1465, 0.1824, 0.1650, 0.1665, 0.1675, 0.1721], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "880\n",
      "880\n",
      "tensor([-0.0960,  0.1454,  0.1081,  0.0611,  0.0416,  0.0858],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1425, 0.1814, 0.1748, 0.1668, 0.1635, 0.1709], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "881\n",
      "881\n",
      "tensor([-0.1196,  0.1263,  0.0289,  0.0429,  0.0516,  0.1279],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1412, 0.1805, 0.1638, 0.1661, 0.1676, 0.1808], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "882\n",
      "882\n",
      "tensor([-0.0713,  0.1283,  0.0540,  0.0273,  0.0789,  0.1072],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1467, 0.1791, 0.1663, 0.1619, 0.1705, 0.1754], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "883\n",
      "883\n",
      "tensor([-0.1142,  0.1439,  0.0846,  0.0105,  0.0594,  0.0836],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1417, 0.1835, 0.1729, 0.1606, 0.1686, 0.1727], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "884\n",
      "884\n",
      "tensor([-0.0927,  0.1552,  0.0315,  0.0519,  0.0381,  0.1075],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1443, 0.1849, 0.1634, 0.1667, 0.1644, 0.1763], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "885\n",
      "885\n",
      "tensor([-0.1142,  0.3360,  0.0124,  0.1255,  0.2081,  0.3388],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1261, 0.1979, 0.1432, 0.1603, 0.1741, 0.1984], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "886\n",
      "886\n",
      "tensor([-0.1014,  0.1251,  0.0595,  0.0210,  0.0686,  0.0887],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1438, 0.1804, 0.1689, 0.1625, 0.1705, 0.1739], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "887\n",
      "887\n",
      "tensor([-0.1014,  0.1251,  0.0595,  0.0210,  0.0686,  0.0887],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1438, 0.1804, 0.1689, 0.1625, 0.1705, 0.1739], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "888\n",
      "888\n",
      "tensor([ 0.0542,  0.1067, -0.0759,  0.3207, -0.0635, -0.0884],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1669, 0.1758, 0.1465, 0.2178, 0.1483, 0.1447], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "889\n",
      "889\n",
      "tensor([-0.1090,  0.1332,  0.0589,  0.0309,  0.0706,  0.0813],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1426, 0.1817, 0.1686, 0.1640, 0.1706, 0.1725], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "890\n",
      "890\n",
      "tensor([-0.0847,  0.1265,  0.0567,  0.0255,  0.0640,  0.1355],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1447, 0.1787, 0.1667, 0.1616, 0.1679, 0.1804], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "891\n",
      "891\n",
      "tensor([-0.0882,  0.1424,  0.0542,  0.0319,  0.0491,  0.0832],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1455, 0.1832, 0.1677, 0.1640, 0.1669, 0.1727], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "892\n",
      "892\n",
      "tensor([-0.0838,  0.1366,  0.0741,  0.0652,  0.0363,  0.1304],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1440, 0.1795, 0.1686, 0.1671, 0.1624, 0.1784], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "893\n",
      "893\n",
      "tensor([-0.1027,  0.1344,  0.0690,  0.0027,  0.0603,  0.0726],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1442, 0.1828, 0.1712, 0.1602, 0.1697, 0.1718], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "894\n",
      "894\n",
      "tensor([-0.1217,  0.1392,  0.0420,  0.0721,  0.0778,  0.0895],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1399, 0.1817, 0.1648, 0.1699, 0.1708, 0.1728], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "895\n",
      "895\n",
      "tensor([-0.0788,  0.1357,  0.0503,  0.0163,  0.0498,  0.1222],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1463, 0.1813, 0.1664, 0.1609, 0.1663, 0.1788], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "896\n",
      "896\n",
      "tensor([-0.1059,  0.1481,  0.0598,  0.0346,  0.0608,  0.0670],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1430, 0.1844, 0.1688, 0.1646, 0.1690, 0.1701], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "897\n",
      "897\n",
      "tensor([-0.0711,  0.1513,  0.0740,  0.0561,  0.0797,  0.1114],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1449, 0.1809, 0.1675, 0.1645, 0.1684, 0.1738], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "898\n",
      "898\n",
      "tensor([-0.0861,  0.1255,  0.0489,  0.0636,  0.0516,  0.0634],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1460, 0.1804, 0.1671, 0.1695, 0.1675, 0.1695], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "899\n",
      "899\n",
      "tensor([-0.1174,  0.1456,  0.0621,  0.0264,  0.0435,  0.1371],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1405, 0.1828, 0.1681, 0.1623, 0.1651, 0.1812], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "900\n",
      "900\n",
      "tensor([-0.0808,  0.1461,  0.0667,  0.0141,  0.0872,  0.1009],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1450, 0.1820, 0.1681, 0.1595, 0.1716, 0.1739], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "901\n",
      "901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 of 100 episodes                \r",
      "tensor([-0.1088,  0.1356,  0.0697, -0.0020,  0.0472,  0.0895],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1434, 0.1831, 0.1714, 0.1596, 0.1676, 0.1749], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "902\n",
      "902\n",
      "tensor([-0.1355,  0.1299,  0.0307,  0.0586,  0.0509,  0.1192],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1390, 0.1812, 0.1641, 0.1688, 0.1675, 0.1793], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "903\n",
      "903\n",
      "tensor([-0.0305,  0.1576,  0.0304,  0.0804,  0.0872,  0.0922],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1505, 0.1817, 0.1600, 0.1682, 0.1694, 0.1702], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "904\n",
      "904\n",
      "tensor([-0.1330,  0.1497,  0.0439,  0.0199,  0.0558,  0.1087],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1395, 0.1851, 0.1665, 0.1626, 0.1685, 0.1777], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "905\n",
      "905\n",
      "tensor([-0.1103,  0.1352,  0.0917,  0.0087,  0.0658,  0.0768],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1423, 0.1819, 0.1742, 0.1603, 0.1697, 0.1716], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "906\n",
      "906\n",
      "tensor([-0.0733,  0.1092,  0.0502,  0.0522,  0.0842,  0.0839],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1469, 0.1763, 0.1662, 0.1666, 0.1720, 0.1719], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "907\n",
      "907\n",
      "tensor([-0.1071,  0.1488,  0.0492,  0.0296,  0.0549,  0.0921],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1428, 0.1844, 0.1669, 0.1637, 0.1679, 0.1743], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "908\n",
      "908\n",
      "tensor([-0.0809,  0.1602,  0.0655,  0.0470,  0.0661,  0.1344],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1436, 0.1827, 0.1662, 0.1632, 0.1663, 0.1781], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "909\n",
      "909\n",
      "tensor([-0.0970,  0.1314,  0.0379,  0.0305,  0.0754,  0.0722],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1447, 0.1819, 0.1656, 0.1644, 0.1720, 0.1714], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "910\n",
      "910\n",
      "tensor([-0.0763,  0.1363,  0.0508,  0.0328,  0.0592,  0.0855],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1469, 0.1817, 0.1668, 0.1638, 0.1682, 0.1727], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "911\n",
      "911\n",
      "tensor([-0.1121,  0.1446,  0.0159,  0.0230,  0.0454,  0.0708],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1440, 0.1861, 0.1636, 0.1648, 0.1685, 0.1729], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "912\n",
      "912\n",
      "tensor([-0.0700,  0.1345,  0.1108,  0.0089,  0.0354,  0.0952],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1471, 0.1805, 0.1762, 0.1592, 0.1635, 0.1735], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "913\n",
      "913\n",
      "tensor([-0.1019,  0.1362,  0.0537,  0.0130,  0.0654,  0.0941],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1437, 0.1824, 0.1679, 0.1612, 0.1699, 0.1749], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "914\n",
      "914\n",
      "tensor([-0.0592,  0.3432,  0.0160,  0.1470,  0.1791,  0.3392],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1323, 0.1978, 0.1426, 0.1625, 0.1678, 0.1970], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "915\n",
      "915\n",
      "tensor([-0.1014,  0.1251,  0.0595,  0.0210,  0.0686,  0.0887],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1438, 0.1804, 0.1689, 0.1625, 0.1705, 0.1739], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "916\n",
      "916\n",
      "tensor([-0.1014,  0.1251,  0.0595,  0.0210,  0.0686,  0.0887],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1438, 0.1804, 0.1689, 0.1625, 0.1705, 0.1739], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "917\n",
      "917\n",
      "tensor([-0.1014,  0.1251,  0.0595,  0.0210,  0.0686,  0.0887],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1438, 0.1804, 0.1689, 0.1625, 0.1705, 0.1739], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "918\n",
      "918\n",
      "tensor([ 0.0728,  0.1091, -0.0733,  0.3390, -0.0717, -0.1067],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1693, 0.1755, 0.1463, 0.2209, 0.1465, 0.1415], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "919\n",
      "919\n",
      "tensor([-0.1079,  0.1072,  0.0704,  0.0165,  0.0779,  0.1399],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1418, 0.1758, 0.1695, 0.1606, 0.1707, 0.1817], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "920\n",
      "920\n",
      "tensor([-0.0949,  0.1263,  0.0684,  0.0545,  0.0712,  0.0859],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1436, 0.1791, 0.1691, 0.1667, 0.1695, 0.1720], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "921\n",
      "921\n",
      "tensor([-0.0951,  0.1141,  0.0552,  0.0380,  0.0568,  0.0786],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1451, 0.1789, 0.1686, 0.1658, 0.1689, 0.1726], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "922\n",
      "922\n",
      "tensor([-0.0984,  0.1562,  0.0517,  0.0326,  0.0695,  0.1070],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1428, 0.1842, 0.1659, 0.1628, 0.1689, 0.1754], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "923\n",
      "923\n",
      "tensor([-0.1253,  0.1181,  0.0567,  0.0051,  0.0482,  0.0886],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1420, 0.1811, 0.1703, 0.1618, 0.1689, 0.1759], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "924\n",
      "924\n",
      "tensor([-0.0820,  0.1553,  0.0156,  0.0412,  0.0391,  0.0774],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1470, 0.1864, 0.1621, 0.1663, 0.1659, 0.1724], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "925\n",
      "925\n",
      "tensor([-0.1274,  0.1355,  0.0650,  0.0060,  0.0508,  0.1002],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1407, 0.1830, 0.1706, 0.1608, 0.1682, 0.1767], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "926\n",
      "926\n",
      "tensor([-0.0767,  0.1371,  0.0406,  0.0342,  0.0472,  0.0924],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1471, 0.1822, 0.1655, 0.1644, 0.1665, 0.1743], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "927\n",
      "927\n",
      "tensor([-0.0888,  0.1109,  0.0516,  0.0677,  0.0663,  0.0526],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1458, 0.1780, 0.1677, 0.1704, 0.1702, 0.1679], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "928\n",
      "928\n",
      "tensor([-0.1128,  0.1285,  0.0419,  0.0013,  0.0422,  0.1426],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1425, 0.1813, 0.1663, 0.1597, 0.1663, 0.1839], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "929\n",
      "929\n",
      "tensor([-0.0718,  0.1224,  0.0527,  0.0254,  0.0854,  0.0814],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1474, 0.1790, 0.1669, 0.1624, 0.1725, 0.1718], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "930\n",
      "930\n",
      "tensor([-0.1066,  0.1493,  0.1033,  0.0442,  0.0400,  0.0997],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1413, 0.1826, 0.1744, 0.1644, 0.1637, 0.1737], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "931\n",
      "931\n",
      "tensor([-0.0687,  0.1133,  0.0356,  0.0688,  0.0408,  0.1089],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1478, 0.1773, 0.1640, 0.1696, 0.1649, 0.1765], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "932\n",
      "932\n",
      "tensor([-0.0844,  0.1585,  0.0679,  0.0275,  0.0444,  0.1127],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1447, 0.1844, 0.1684, 0.1618, 0.1645, 0.1762], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "933\n",
      "933\n",
      "tensor([-0.0994,  0.1276,  0.0435,  0.0199,  0.0687,  0.0822],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1446, 0.1814, 0.1668, 0.1629, 0.1710, 0.1733], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "934\n",
      "934\n",
      "tensor([-0.0865,  0.1534,  0.0538,  0.0278,  0.0800,  0.0657],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1452, 0.1845, 0.1670, 0.1628, 0.1715, 0.1690], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "935\n",
      "935\n",
      "tensor([-0.1074,  0.0958,  0.0508,  0.0213,  0.0789,  0.1243],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1429, 0.1750, 0.1674, 0.1625, 0.1721, 0.1801], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "936\n",
      "936\n",
      "tensor([-0.0942,  0.1318,  0.0488,  0.0447,  0.0620,  0.0499],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1453, 0.1822, 0.1677, 0.1670, 0.1699, 0.1679], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "937\n",
      "937\n",
      "tensor([-0.1177,  0.1516,  0.0882,  0.0372,  0.0465,  0.1150],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1399, 0.1832, 0.1719, 0.1634, 0.1649, 0.1766], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "938\n",
      "938\n",
      "tensor([-0.0538,  0.1315,  0.0232,  0.0285,  0.0735,  0.0899],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1502, 0.1807, 0.1622, 0.1630, 0.1705, 0.1734], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "939\n",
      "939\n",
      "tensor([-0.0850,  0.1212,  0.0824,  0.0342,  0.0876,  0.0978],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1444, 0.1774, 0.1707, 0.1626, 0.1716, 0.1733], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "940\n",
      "940\n",
      "tensor([-0.1155,  0.1539,  0.0619,  0.0457,  0.0384,  0.1041],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1410, 0.1846, 0.1684, 0.1657, 0.1645, 0.1757], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "941\n",
      "941\n",
      "tensor([-0.0871,  0.1206,  0.0552,  0.0010,  0.0470,  0.1127],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1462, 0.1799, 0.1685, 0.1596, 0.1672, 0.1785], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "942\n",
      "942\n",
      "tensor([-0.1094,  0.1189,  0.0306,  0.0715,  0.0504,  0.0777],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1432, 0.1799, 0.1647, 0.1716, 0.1680, 0.1726], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "943\n",
      "943\n",
      "tensor([-0.1255,  0.1733,  0.0291,  0.0184,  0.0487,  0.0709],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1413, 0.1905, 0.1649, 0.1632, 0.1682, 0.1720], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "944\n",
      "944\n",
      "tensor([-0.0872,  0.0862,  0.0557, -0.0064,  0.0599,  0.1446],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1461, 0.1737, 0.1685, 0.1584, 0.1692, 0.1842], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "945\n",
      "945\n",
      "tensor([-0.0755,  0.1548,  0.0488,  0.0514,  0.0497,  0.0674],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1468, 0.1848, 0.1662, 0.1666, 0.1663, 0.1693], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "946\n",
      "946\n",
      "tensor([-0.1103,  0.1591,  0.0775,  0.0559,  0.0412,  0.0721],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1416, 0.1854, 0.1709, 0.1672, 0.1648, 0.1700], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "947\n",
      "947\n",
      "tensor([-0.0584,  0.1385,  0.0556,  0.0352,  0.0461,  0.0661],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1497, 0.1823, 0.1678, 0.1644, 0.1662, 0.1696], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "948\n",
      "948\n",
      "tensor([-0.1231,  0.1234,  0.0643,  0.0255,  0.0705,  0.0980],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1407, 0.1800, 0.1697, 0.1633, 0.1708, 0.1755], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "949\n",
      "949\n",
      "tensor([-0.0948,  0.1502,  0.0863,  0.0019,  0.0651,  0.0690],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1443, 0.1844, 0.1730, 0.1590, 0.1693, 0.1700], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "950\n",
      "950\n",
      "tensor([-0.0839,  0.1576,  0.0448,  0.0618,  0.0769,  0.1411],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1430, 0.1820, 0.1626, 0.1654, 0.1679, 0.1791], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "951\n",
      "951\n",
      "tensor([-0.1151,  0.1344,  0.0326,  0.0294,  0.0806,  0.0928],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1419, 0.1822, 0.1645, 0.1640, 0.1726, 0.1747], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "952\n",
      "952\n",
      "tensor([-0.0556,  0.1308,  0.0725,  0.0096,  0.0756,  0.0594],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1499, 0.1806, 0.1704, 0.1600, 0.1709, 0.1682], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "953\n",
      "953\n",
      "tensor([-0.0981,  0.1407,  0.0258,  0.0576,  0.0716,  0.1272],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1427, 0.1812, 0.1615, 0.1667, 0.1691, 0.1788], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "954\n",
      "954\n",
      "tensor([-0.1063,  0.1539,  0.0766,  0.0329,  0.0683,  0.0752],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1421, 0.1843, 0.1706, 0.1633, 0.1692, 0.1704], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "955\n",
      "955\n",
      "tensor([-0.0811,  0.1084,  0.0634,  0.0261,  0.0797,  0.0883],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1463, 0.1768, 0.1690, 0.1628, 0.1718, 0.1733], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "956\n",
      "956\n",
      "tensor([-0.1041,  0.1425,  0.0603,  0.0418,  0.0556,  0.0831],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1430, 0.1830, 0.1685, 0.1654, 0.1677, 0.1724], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "957\n",
      "957\n",
      "tensor([-0.1029,  0.1367,  0.0539,  0.0357,  0.0609,  0.1005],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1430, 0.1817, 0.1673, 0.1643, 0.1685, 0.1753], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "958\n",
      "958\n",
      "tensor([-0.1163,  0.1293,  0.0545,  0.0412,  0.0820,  0.1110],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1406, 0.1798, 0.1668, 0.1646, 0.1715, 0.1765], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "959\n",
      "959\n",
      "tensor([-0.0831,  0.1327,  0.0617, -0.0092,  0.0497,  0.0857],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1471, 0.1825, 0.1700, 0.1584, 0.1680, 0.1741], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "960\n",
      "960\n",
      "tensor([-0.0971,  0.1085,  0.0150,  0.0535,  0.0702,  0.1034],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1446, 0.1777, 0.1618, 0.1682, 0.1710, 0.1768], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "961\n",
      "961\n",
      "tensor([-0.1290,  0.1405,  0.0564,  0.0160,  0.0400,  0.1127],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1403, 0.1837, 0.1689, 0.1622, 0.1662, 0.1787], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "962\n",
      "962\n",
      "tensor([-0.0690,  0.1395,  0.0505,  0.0665,  0.0839,  0.0832],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1463, 0.1803, 0.1649, 0.1676, 0.1705, 0.1704], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "963\n",
      "963\n",
      "tensor([-0.1028,  0.1585,  0.0422,  0.0065,  0.0373,  0.0957],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1441, 0.1871, 0.1666, 0.1607, 0.1658, 0.1757], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "964\n",
      "964\n",
      "tensor([-0.0713,  0.1175,  0.0693,  0.0091,  0.0757,  0.0892],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1476, 0.1783, 0.1699, 0.1600, 0.1710, 0.1733], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "965\n",
      "965\n",
      "tensor([-0.1089,  0.1263,  0.0441,  0.0147,  0.0735,  0.0805],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1435, 0.1815, 0.1672, 0.1623, 0.1722, 0.1734], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "966\n",
      "966\n",
      "tensor([-0.1060,  0.1481,  0.0486,  0.0126,  0.0702,  0.1167],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1424, 0.1835, 0.1662, 0.1603, 0.1698, 0.1779], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "967\n",
      "967\n",
      "tensor([-0.1187,  0.1392,  0.0722,  0.0331,  0.0607,  0.0935],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1408, 0.1822, 0.1704, 0.1639, 0.1685, 0.1741], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "968\n",
      "968\n",
      "tensor([-0.1206,  0.1040,  0.0193,  0.0404,  0.0619,  0.1062],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1422, 0.1780, 0.1636, 0.1671, 0.1707, 0.1784], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "969\n",
      "969\n",
      "tensor([-0.0642,  0.1316,  0.0801,  0.0710,  0.0621,  0.1105],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1462, 0.1778, 0.1688, 0.1673, 0.1658, 0.1741], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "970\n",
      "970\n",
      "tensor([-0.0847,  0.1354,  0.0574,  0.0223,  0.0520,  0.0788],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1463, 0.1823, 0.1686, 0.1628, 0.1677, 0.1723], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "971\n",
      "971\n",
      "tensor([-0.0485,  0.1648,  0.0587,  0.0365,  0.0890,  0.0913],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1484, 0.1837, 0.1652, 0.1616, 0.1703, 0.1707], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "972\n",
      "972\n",
      "tensor([-0.1243,  0.1610,  0.0498,  0.0227,  0.0697,  0.1074],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1398, 0.1859, 0.1664, 0.1619, 0.1697, 0.1762], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "973\n",
      "973\n",
      "tensor([-0.1070,  0.1151,  0.0620,  0.0145,  0.0490,  0.0988],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1437, 0.1794, 0.1701, 0.1623, 0.1680, 0.1765], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "974\n",
      "974\n",
      "tensor([-0.1093,  0.1154,  0.0591,  0.0365,  0.1048,  0.0749],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1422, 0.1780, 0.1683, 0.1645, 0.1761, 0.1709], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "975\n",
      "975\n",
      "tensor([-0.0762,  0.1535,  0.0617,  0.0241,  0.0509,  0.0982],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1462, 0.1840, 0.1679, 0.1617, 0.1661, 0.1741], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "976\n",
      "976\n",
      "tensor([-0.0961,  0.1440,  0.0621,  0.0321,  0.0595,  0.1315],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1428, 0.1815, 0.1673, 0.1623, 0.1668, 0.1793], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "977\n",
      "977\n",
      "tensor([-0.0965,  0.1221,  0.0571,  0.0680,  0.0647,  0.0741],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1439, 0.1790, 0.1678, 0.1696, 0.1690, 0.1706], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "978\n",
      "978\n",
      "tensor([-0.1095,  0.1287,  0.0424,  0.0084,  0.0441,  0.0950],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1439, 0.1826, 0.1675, 0.1619, 0.1677, 0.1765], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "979\n",
      "979\n",
      "tensor([-0.1149,  0.1172,  0.0597,  0.0622,  0.0519,  0.0741],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1421, 0.1793, 0.1693, 0.1697, 0.1679, 0.1717], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "980\n",
      "980\n",
      "tensor([-0.0978,  0.1066,  0.0864,  0.0362,  0.0697,  0.0979],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1435, 0.1760, 0.1725, 0.1640, 0.1696, 0.1745], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "981\n",
      "981\n",
      "tensor([-0.0860,  0.1151,  0.0393, -0.0006,  0.0765,  0.0955],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1466, 0.1793, 0.1662, 0.1597, 0.1725, 0.1758], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "982\n",
      "982\n",
      "tensor([-0.0988,  0.1467,  0.0880,  0.0525,  0.0498,  0.0841],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1427, 0.1824, 0.1720, 0.1660, 0.1656, 0.1713], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "983\n",
      "983\n",
      "tensor([-0.0392,  0.1709,  0.0034,  0.0284,  0.0637,  0.1123],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1511, 0.1864, 0.1576, 0.1616, 0.1675, 0.1758], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "984\n",
      "984\n",
      "tensor([-0.1059,  0.1160,  0.0640, -0.0126,  0.0934,  0.1045],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1431, 0.1787, 0.1696, 0.1571, 0.1747, 0.1767], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "985\n",
      "985\n",
      "tensor([-0.0920,  0.1551,  0.0504,  0.0647,  0.0712,  0.0907],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1433, 0.1834, 0.1652, 0.1676, 0.1686, 0.1720], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "986\n",
      "986\n",
      "tensor([-0.0788,  0.1015,  0.0755,  0.0350,  0.0554,  0.0998],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1465, 0.1755, 0.1710, 0.1642, 0.1676, 0.1752], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "987\n",
      "987\n",
      "tensor([-0.1000,  0.1540,  0.0577,  0.0248,  0.0358,  0.0554],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1448, 0.1867, 0.1695, 0.1640, 0.1659, 0.1691], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "988\n",
      "988\n",
      "tensor([-0.1063,  0.1214,  0.0437,  0.0226,  0.0225,  0.1000],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1445, 0.1814, 0.1679, 0.1644, 0.1643, 0.1776], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "989\n",
      "989\n",
      "tensor([-0.0435,  0.1316,  0.0973,  0.0634,  0.0617,  0.0938],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1490, 0.1775, 0.1715, 0.1658, 0.1655, 0.1709], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "990\n",
      "990\n",
      "tensor([-0.1167,  0.1387,  0.0416,  0.0238,  0.0470,  0.1055],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1421, 0.1834, 0.1664, 0.1635, 0.1673, 0.1774], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "991\n",
      "991\n",
      "tensor([-0.0745,  0.1289,  0.0754,  0.0252,  0.0450,  0.0981],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1469, 0.1800, 0.1707, 0.1623, 0.1655, 0.1746], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "992\n",
      "992\n",
      "tensor([-0.1180,  0.1392,  0.0765,  0.0776,  0.0451,  0.1303],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1392, 0.1801, 0.1691, 0.1693, 0.1639, 0.1784], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "993\n",
      "993\n",
      "tensor([-0.0711,  0.1409,  0.0554,  0.0409,  0.0694,  0.1142],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1461, 0.1806, 0.1658, 0.1634, 0.1682, 0.1759], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "994\n",
      "994\n",
      "tensor([-0.1422,  0.1227,  0.0166,  0.0118,  0.0777,  0.0991],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1396, 0.1820, 0.1637, 0.1629, 0.1740, 0.1778], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "995\n",
      "995\n",
      "tensor([-0.0838,  0.1467,  0.0608,  0.0035,  0.0671,  0.0720],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1463, 0.1842, 0.1690, 0.1596, 0.1701, 0.1709], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "996\n",
      "996\n",
      "tensor([-0.0699,  0.1396,  0.0645,  0.0559,  0.0582,  0.1260],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1457, 0.1796, 0.1666, 0.1652, 0.1656, 0.1772], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "997\n",
      "997\n",
      "tensor([-0.1350,  0.1058,  0.0725,  0.0252,  0.0868,  0.0899],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1393, 0.1773, 0.1715, 0.1635, 0.1739, 0.1745], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "998\n",
      "998\n",
      "tensor([-0.0934,  0.1413,  0.0520,  0.0333,  0.0277,  0.0733],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1456, 0.1842, 0.1684, 0.1653, 0.1644, 0.1721], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "999\n",
      "999\n",
      "tensor([-0.0926,  0.1263,  0.0494,  0.0616,  0.0526,  0.1322],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1434, 0.1785, 0.1653, 0.1673, 0.1658, 0.1796], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1000\n",
      "1000\n",
      "tensor([-0.1232,  0.1401,  0.0865,  0.0225,  0.0695,  0.0790],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1403, 0.1826, 0.1730, 0.1623, 0.1701, 0.1717], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1001\n",
      "1001\n",
      "Episode 0 of 100 episodes                \r",
      "tensor([-0.1097,  0.1398,  0.0439,  0.0101,  0.0320,  0.1172],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1432, 0.1838, 0.1670, 0.1614, 0.1650, 0.1797], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1002\n",
      "1002\n",
      "tensor([-0.0891,  0.1292,  0.0687,  0.0508,  0.0746,  0.1244],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1432, 0.1782, 0.1677, 0.1648, 0.1687, 0.1773], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1003\n",
      "1003\n",
      "tensor([-0.1027,  0.1406,  0.0664,  0.0374,  0.0778,  0.0998],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1422, 0.1814, 0.1684, 0.1636, 0.1703, 0.1741], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1004\n",
      "1004\n",
      "tensor([-0.1034,  0.1299, -0.0052,  0.0420,  0.0230,  0.1182],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1448, 0.1829, 0.1598, 0.1675, 0.1643, 0.1807], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1005\n",
      "1005\n",
      "tensor([-0.1080,  0.1131,  0.0944,  0.0247,  0.0707,  0.0745],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1427, 0.1780, 0.1747, 0.1629, 0.1706, 0.1712], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1006\n",
      "1006\n",
      "tensor([-0.1032,  0.1449,  0.0738,  0.0416,  0.0639,  0.1051],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1420, 0.1819, 0.1694, 0.1641, 0.1678, 0.1748], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1007\n",
      "1007\n",
      "tensor([-0.0946,  0.1253,  0.0427,  0.0282,  0.0646,  0.1237],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1441, 0.1795, 0.1653, 0.1629, 0.1689, 0.1792], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1008\n",
      "1008\n",
      "tensor([-0.0787,  0.1396,  0.0782, -0.0013,  0.0576,  0.0957],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1464, 0.1821, 0.1713, 0.1582, 0.1678, 0.1743], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1009\n",
      "1009\n",
      "tensor([-0.0757,  0.1538,  0.0732,  0.0722,  0.0767,  0.0894],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1445, 0.1817, 0.1677, 0.1675, 0.1683, 0.1704], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1010\n",
      "1010\n",
      "tensor([-0.1094,  0.1414,  0.0449,  0.0616,  0.0625,  0.1086],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1415, 0.1818, 0.1651, 0.1678, 0.1680, 0.1759], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1011\n",
      "1011\n",
      "tensor([-0.0987,  0.1554,  0.0467,  0.0115,  0.0540,  0.0713],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1447, 0.1865, 0.1673, 0.1615, 0.1685, 0.1715], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1012\n",
      "1012\n",
      "tensor([-0.0996,  0.1199,  0.0852,  0.0251,  0.0738,  0.1167],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1426, 0.1776, 0.1716, 0.1616, 0.1696, 0.1770], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1013\n",
      "1013\n",
      "tensor([-0.0834,  0.1684,  0.0739,  0.0550,  0.0363,  0.0825],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1447, 0.1861, 0.1693, 0.1661, 0.1630, 0.1708], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1014\n",
      "1014\n",
      "tensor([-0.0873,  0.1359,  0.0422, -0.0056,  0.0363,  0.0898],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1471, 0.1839, 0.1674, 0.1596, 0.1664, 0.1756], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1015\n",
      "1015\n",
      "tensor([-0.1277,  0.1156,  0.0223,  0.0550,  0.1037,  0.1309],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1390, 0.1773, 0.1615, 0.1669, 0.1752, 0.1800], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1016\n",
      "1016\n",
      "tensor([-0.0726,  0.1261,  0.0729,  0.0516,  0.0445,  0.0773],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1472, 0.1795, 0.1702, 0.1666, 0.1655, 0.1710], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1017\n",
      "1017\n",
      "tensor([-0.0748,  0.1201,  0.1252,  0.0348,  0.0602,  0.0853],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1456, 0.1769, 0.1778, 0.1624, 0.1666, 0.1708], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1018\n",
      "1018\n",
      "tensor([-0.0859,  0.1610,  0.0331,  0.0426,  0.0740,  0.0933],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1447, 0.1852, 0.1629, 0.1645, 0.1697, 0.1730], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1019\n",
      "1019\n",
      "tensor([-0.0970,  0.1281,  0.0560,  0.0146,  0.0478,  0.1132],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1444, 0.1808, 0.1683, 0.1614, 0.1669, 0.1782], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1020\n",
      "1020\n",
      "tensor([-0.0901,  0.1389,  0.0566,  0.0796,  0.0648,  0.0613],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1443, 0.1814, 0.1671, 0.1709, 0.1685, 0.1678], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1021\n",
      "1021\n",
      "tensor([-0.1175,  0.1597,  0.0511,  0.0252,  0.0789,  0.1017],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1405, 0.1854, 0.1663, 0.1620, 0.1710, 0.1749], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1022\n",
      "1022\n",
      "tensor([-0.0914,  0.1422,  0.0452,  0.0609,  0.0665,  0.0906],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1440, 0.1819, 0.1651, 0.1677, 0.1686, 0.1727], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1023\n",
      "1023\n",
      "tensor([-0.0963,  0.1354,  0.0699,  0.0320,  0.0530,  0.1039],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1437, 0.1811, 0.1696, 0.1633, 0.1668, 0.1755], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1024\n",
      "1024\n",
      "tensor([-0.1193,  0.1487,  0.0478,  0.0160,  0.0384,  0.0770],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1424, 0.1862, 0.1683, 0.1630, 0.1667, 0.1733], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1025\n",
      "1025\n",
      "tensor([-0.1116,  0.1427,  0.0669,  0.0566,  0.0721,  0.1109],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1405, 0.1811, 0.1679, 0.1662, 0.1688, 0.1755], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1026\n",
      "1026\n",
      "tensor([-0.1098,  0.1487,  0.0490, -0.0078,  0.0215,  0.0921],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1441, 0.1866, 0.1689, 0.1596, 0.1643, 0.1764], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1027\n",
      "1027\n",
      "tensor([-0.0781,  0.1234,  0.0733,  0.0723,  0.0527,  0.0824],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1457, 0.1782, 0.1695, 0.1694, 0.1661, 0.1711], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1028\n",
      "1028\n",
      "tensor([-0.1037,  0.2014,  0.0401,  0.0102,  0.0805,  0.0979],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1417, 0.1922, 0.1636, 0.1588, 0.1703, 0.1733], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1029\n",
      "1029\n",
      "tensor([-0.0937,  0.1329,  0.0414,  0.0453,  0.0390,  0.0742],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1455, 0.1825, 0.1666, 0.1672, 0.1661, 0.1721], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1030\n",
      "1030\n",
      "tensor([-0.0819,  0.1333,  0.0242,  0.0594,  0.0733,  0.0885],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1458, 0.1808, 0.1621, 0.1680, 0.1703, 0.1729], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1031\n",
      "1031\n",
      "tensor([-0.1109,  0.1504,  0.0498,  0.0085,  0.0529,  0.0670],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1434, 0.1863, 0.1684, 0.1616, 0.1689, 0.1713], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1032\n",
      "1032\n",
      "tensor([-0.1322,  0.1379,  0.0851,  0.0312,  0.0558,  0.1078],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1387, 0.1817, 0.1724, 0.1633, 0.1674, 0.1764], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1033\n",
      "1033\n",
      "tensor([-0.0577,  0.1215,  0.0327, -0.0081,  0.0584,  0.1000],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1507, 0.1803, 0.1650, 0.1584, 0.1692, 0.1764], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1034\n",
      "1034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0491,  0.1242,  0.0701,  0.0407,  0.0563,  0.0577],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1507, 0.1793, 0.1698, 0.1649, 0.1675, 0.1677], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1035\n",
      "1035\n",
      "tensor([-0.1230,  0.1678,  0.0520,  0.0316,  0.0693,  0.1022],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1397, 0.1868, 0.1664, 0.1630, 0.1693, 0.1749], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1036\n",
      "1036\n",
      "tensor([-0.0842,  0.1268,  0.0740,  0.0131,  0.0370,  0.1034],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1461, 0.1804, 0.1712, 0.1611, 0.1649, 0.1763], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1037\n",
      "1037\n",
      "tensor([-0.1010,  0.1234,  0.0440,  0.0281,  0.0583,  0.0940],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1442, 0.1805, 0.1667, 0.1641, 0.1691, 0.1753], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1038\n",
      "1038\n",
      "tensor([-0.0618,  0.1484,  0.0477,  0.0342,  0.0696,  0.0996],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1478, 0.1824, 0.1649, 0.1627, 0.1685, 0.1737], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1039\n",
      "1039\n",
      "tensor([-0.0981,  0.1262,  0.0624,  0.0261,  0.0659,  0.0832],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1442, 0.1805, 0.1693, 0.1633, 0.1699, 0.1729], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1040\n",
      "1040\n",
      "tensor([-0.1197,  0.1336,  0.0655,  0.0116,  0.0701,  0.0996],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1411, 0.1818, 0.1698, 0.1609, 0.1706, 0.1757], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1041\n",
      "1041\n",
      "tensor([-0.0846,  0.1401,  0.0497,  0.0004,  0.0615,  0.0979],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1462, 0.1830, 0.1672, 0.1591, 0.1691, 0.1754], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1042\n",
      "1042\n",
      "tensor([-0.0903,  0.1306,  0.0600,  0.0408,  0.0458,  0.0964],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1449, 0.1807, 0.1684, 0.1652, 0.1660, 0.1747], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1043\n",
      "1043\n",
      "tensor([-0.1310,  0.1289,  0.0531,  0.0177,  0.0756,  0.1078],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1397, 0.1812, 0.1679, 0.1621, 0.1717, 0.1774], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1044\n",
      "1044\n",
      "tensor([-0.1171,  0.1477,  0.0608,  0.0336,  0.0364,  0.1094],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1412, 0.1840, 0.1687, 0.1642, 0.1647, 0.1771], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1045\n",
      "1045\n",
      "tensor([-0.1164,  0.1268,  0.0493,  0.0474,  0.0754,  0.0934],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1413, 0.1802, 0.1667, 0.1664, 0.1711, 0.1742], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1046\n",
      "1046\n",
      "tensor([-0.0842,  0.1563,  0.0330,  0.0354,  0.0472,  0.1147],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1453, 0.1848, 0.1633, 0.1637, 0.1657, 0.1772], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1047\n",
      "1047\n",
      "tensor([-0.0854,  0.1246,  0.0574,  0.0357,  0.0792,  0.0841],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1454, 0.1793, 0.1677, 0.1641, 0.1714, 0.1722], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1048\n",
      "1048\n",
      "tensor([-0.0996,  0.1390,  0.0545, -0.0160,  0.0513,  0.1160],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1444, 0.1833, 0.1684, 0.1570, 0.1679, 0.1791], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1049\n",
      "1049\n",
      "tensor([-0.0852,  0.1314,  0.0478,  0.0107,  0.0436,  0.0735],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1472, 0.1828, 0.1681, 0.1620, 0.1674, 0.1725], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1050\n",
      "1050\n",
      "tensor([-0.0896,  0.1141,  0.0628,  0.0372,  0.0665,  0.0768],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1454, 0.1783, 0.1694, 0.1651, 0.1700, 0.1718], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1051\n",
      "1051\n",
      "tensor([-0.1164,  0.1502,  0.0632,  0.0490,  0.0372,  0.1103],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1408, 0.1838, 0.1685, 0.1661, 0.1642, 0.1766], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1052\n",
      "1052\n",
      "tensor([-0.0989,  0.1324,  0.0624,  0.0039,  0.0711,  0.1048],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1438, 0.1812, 0.1689, 0.1594, 0.1704, 0.1763], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1053\n",
      "1053\n",
      "tensor([-0.1044,  0.1397,  0.0810,  0.0345,  0.0670,  0.0679],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1428, 0.1822, 0.1719, 0.1640, 0.1695, 0.1696], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1054\n",
      "1054\n",
      "tensor([-0.0938,  0.1444,  0.0578,  0.0175,  0.0391,  0.1301],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1440, 0.1827, 0.1676, 0.1610, 0.1645, 0.1802], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1055\n",
      "1055\n",
      "tensor([-0.0850,  0.1256,  0.0535,  0.0181,  0.0734,  0.0621],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1466, 0.1810, 0.1684, 0.1625, 0.1718, 0.1698], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1056\n",
      "1056\n",
      "tensor([-0.0991,  0.1354,  0.0492,  0.0651,  0.0375,  0.1154],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1431, 0.1809, 0.1660, 0.1686, 0.1640, 0.1773], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1057\n",
      "1057\n",
      "tensor([-0.1117,  0.1627,  0.0574,  0.0141,  0.0709,  0.0935],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1416, 0.1863, 0.1677, 0.1606, 0.1700, 0.1738], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1058\n",
      "1058\n",
      "tensor([-0.0837,  0.1403,  0.0692,  0.0676,  0.0383,  0.0625],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1456, 0.1822, 0.1697, 0.1694, 0.1645, 0.1686], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1059\n",
      "1059\n",
      "tensor([-0.0842,  0.1191,  0.0407,  0.0278,  0.0647,  0.1095],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1460, 0.1789, 0.1654, 0.1633, 0.1694, 0.1772], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1060\n",
      "1060\n",
      "tensor([-0.0808,  0.1628,  0.0774, -0.0362,  0.0283,  0.1248],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1463, 0.1866, 0.1714, 0.1529, 0.1631, 0.1797], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1061\n",
      "1061\n",
      "tensor([-0.1168,  0.1383,  0.0772,  0.0732,  0.0582,  0.0765],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1405, 0.1813, 0.1706, 0.1699, 0.1673, 0.1704], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1062\n",
      "1062\n",
      "tensor([-0.0707,  0.1054,  0.0671,  0.0458,  0.0736,  0.1063],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1468, 0.1750, 0.1685, 0.1649, 0.1696, 0.1752], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1063\n",
      "1063\n",
      "tensor([-0.0871,  0.1384,  0.0542,  0.0399,  0.0592,  0.1074],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1447, 0.1813, 0.1666, 0.1643, 0.1675, 0.1757], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1064\n",
      "1064\n",
      "tensor([-0.0859,  0.1391,  0.0760,  0.0168,  0.0772,  0.0763],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1451, 0.1818, 0.1707, 0.1608, 0.1709, 0.1707], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1065\n",
      "1065\n",
      "tensor([-0.1428,  0.1261,  0.0109,  0.0230,  0.0500,  0.0969],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1401, 0.1833, 0.1634, 0.1653, 0.1699, 0.1780], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1066\n",
      "1066\n",
      "tensor([-0.0792,  0.1367,  0.0687,  0.0147,  0.0676,  0.1010],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1459, 0.1811, 0.1691, 0.1602, 0.1690, 0.1747], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1067\n",
      "1067\n",
      "tensor([-0.1085,  0.1407,  0.0516,  0.0256,  0.0799,  0.0612],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1430, 0.1835, 0.1679, 0.1635, 0.1727, 0.1695], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1068\n",
      "1068\n",
      "tensor([-0.1063,  0.1246,  0.0415,  0.0493,  0.0545,  0.1054],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1429, 0.1800, 0.1657, 0.1670, 0.1678, 0.1766], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1069\n",
      "1069\n",
      "tensor([-0.0973,  0.1567,  0.0635,  0.0188,  0.0481,  0.0746],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1443, 0.1860, 0.1694, 0.1620, 0.1669, 0.1713], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1070\n",
      "1070\n",
      "tensor([-0.0735,  0.1171,  0.0740,  0.0239,  0.0603,  0.0871],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1473, 0.1782, 0.1707, 0.1624, 0.1684, 0.1730], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1071\n",
      "1071\n",
      "tensor([-0.1402,  0.1399,  0.0696,  0.0151,  0.0376,  0.1274],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1384, 0.1831, 0.1707, 0.1616, 0.1653, 0.1808], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1072\n",
      "1072\n",
      "tensor([-0.0912,  0.1342,  0.0579,  0.0303,  0.0887,  0.0982],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1439, 0.1803, 0.1671, 0.1625, 0.1723, 0.1739], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1073\n",
      "1073\n",
      "tensor([-0.0654,  0.1331,  0.0793,  0.0179,  0.0593,  0.0920],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1478, 0.1803, 0.1708, 0.1607, 0.1674, 0.1730], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1074\n",
      "1074\n",
      "tensor([-0.1176,  0.1516,  0.0457,  0.0163,  0.0651,  0.1028],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1413, 0.1850, 0.1664, 0.1616, 0.1696, 0.1762], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1075\n",
      "1075\n",
      "tensor([-0.0976,  0.1312,  0.0520,  0.0218,  0.0577,  0.0947],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1444, 0.1815, 0.1677, 0.1627, 0.1687, 0.1750], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1076\n",
      "1076\n",
      "tensor([-0.1076,  0.1503,  0.0379,  0.0543,  0.0565,  0.1259],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1415, 0.1831, 0.1636, 0.1663, 0.1667, 0.1787], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1077\n",
      "1077\n",
      "tensor([-0.0988,  0.1325,  0.0647,  0.0234,  0.0655,  0.0923],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1437, 0.1811, 0.1693, 0.1624, 0.1694, 0.1740], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1078\n",
      "1078\n",
      "tensor([-0.0993,  0.1351,  0.0564,  0.0413,  0.0488,  0.0987],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1436, 0.1816, 0.1678, 0.1653, 0.1666, 0.1751], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1079\n",
      "1079\n",
      "tensor([-0.1030,  0.1334,  0.0676,  0.0406,  0.0553,  0.0817],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1432, 0.1814, 0.1699, 0.1653, 0.1678, 0.1723], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1080\n",
      "1080\n",
      "tensor([-0.0938,  0.1222,  0.0514,  0.0162,  0.0757,  0.0748],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1453, 0.1803, 0.1680, 0.1622, 0.1722, 0.1720], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1081\n",
      "1081\n",
      "tensor([-0.1039,  0.1442,  0.0713,  0.0209,  0.0426,  0.1103],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1428, 0.1830, 0.1702, 0.1618, 0.1653, 0.1769], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1082\n",
      "1082\n",
      "tensor([-0.1031,  0.1161,  0.0637,  0.0182,  0.0830,  0.0835],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1436, 0.1788, 0.1696, 0.1621, 0.1729, 0.1730], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1083\n",
      "1083\n",
      "tensor([-0.0869,  0.1184,  0.0526,  0.0615,  0.0683,  0.0581],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1457, 0.1790, 0.1676, 0.1691, 0.1702, 0.1685], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1084\n",
      "1084\n",
      "tensor([-0.1030,  0.1347,  0.0698,  0.0049,  0.0340,  0.1083],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1438, 0.1824, 0.1709, 0.1602, 0.1649, 0.1777], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1085\n",
      "1085\n",
      "tensor([-0.0788,  0.1598,  0.0727,  0.0502,  0.0667,  0.0998],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1444, 0.1834, 0.1681, 0.1643, 0.1671, 0.1727], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1086\n",
      "1086\n",
      "tensor([-0.1125,  0.1298,  0.0299,  0.0102,  0.0706,  0.0601],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1439, 0.1834, 0.1660, 0.1627, 0.1729, 0.1711], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1087\n",
      "1087\n",
      "tensor([-0.0975,  0.1183,  0.0321,  0.0369,  0.0566,  0.0766],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1454, 0.1804, 0.1655, 0.1663, 0.1696, 0.1730], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1088\n",
      "1088\n",
      "tensor([-0.0999,  0.1540,  0.0578,  0.0323,  0.0554,  0.1119],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1428, 0.1840, 0.1671, 0.1629, 0.1667, 0.1764], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1089\n",
      "1089\n",
      "tensor([-0.1089,  0.1195,  0.0471,  0.0245,  0.0897,  0.1379],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1415, 0.1778, 0.1654, 0.1617, 0.1726, 0.1811], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1090\n",
      "1090\n",
      "tensor([-0.0869,  0.1278,  0.0727,  0.0255,  0.0663,  0.0855],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1452, 0.1800, 0.1704, 0.1625, 0.1693, 0.1726], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1091\n",
      "1091\n",
      "tensor([-0.0723,  0.1334,  0.0760,  0.0545,  0.0660,  0.1009],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1458, 0.1790, 0.1691, 0.1655, 0.1674, 0.1733], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1092\n",
      "1092\n",
      "tensor([-0.1001,  0.1331,  0.0505,  0.0061,  0.0430,  0.0903],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1449, 0.1830, 0.1685, 0.1611, 0.1672, 0.1753], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1093\n",
      "1093\n",
      "tensor([-0.1132,  0.1347,  0.0590,  0.0194,  0.0671,  0.0885],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1422, 0.1822, 0.1689, 0.1624, 0.1703, 0.1740], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1094\n",
      "1094\n",
      "tensor([-0.0986,  0.1349,  0.0673,  0.0315,  0.0627,  0.0921],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1435, 0.1813, 0.1694, 0.1635, 0.1686, 0.1737], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1095\n",
      "1095\n",
      "tensor([-0.0987,  0.1353,  0.0493,  0.0354,  0.0654,  0.1068],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1434, 0.1812, 0.1663, 0.1640, 0.1690, 0.1761], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1096\n",
      "1096\n",
      "tensor([-0.0909,  0.1326,  0.0689,  0.0536,  0.0563,  0.0776],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1445, 0.1807, 0.1695, 0.1669, 0.1674, 0.1710], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1097\n",
      "1097\n",
      "tensor([-0.0803,  0.1272,  0.0850,  0.0484,  0.0777,  0.1241],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1440, 0.1772, 0.1698, 0.1638, 0.1686, 0.1766], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1098\n",
      "1098\n",
      "tensor([-0.1218,  0.1269,  0.0455,  0.0081,  0.0721,  0.0843],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1419, 0.1820, 0.1678, 0.1616, 0.1723, 0.1744], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1099\n",
      "1099\n",
      "tensor([-0.0827,  0.1385,  0.0519,  0.0445,  0.0689,  0.0805],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1456, 0.1816, 0.1666, 0.1653, 0.1694, 0.1714], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1100\n",
      "1100\n",
      "tensor([-0.0998,  0.1352,  0.0632,  0.0197,  0.0575,  0.0917],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1439, 0.1820, 0.1694, 0.1621, 0.1684, 0.1742], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1101\n",
      "1101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 of 100 episodes                \r",
      "tensor([-0.1122,  0.1166,  0.0554,  0.0239,  0.0726,  0.1019],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1423, 0.1789, 0.1683, 0.1631, 0.1712, 0.1763], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1102\n",
      "1102\n",
      "tensor([-0.1206,  0.1411,  0.0471,  0.0575,  0.0338,  0.1085],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1408, 0.1829, 0.1665, 0.1683, 0.1643, 0.1771], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1103\n",
      "1103\n",
      "tensor([-0.0860,  0.1320,  0.0542,  0.0257,  0.0644,  0.0646],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1463, 0.1819, 0.1683, 0.1635, 0.1700, 0.1700], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1104\n",
      "1104\n",
      "tensor([-0.0996,  0.1379,  0.0279,  0.0558,  0.0467,  0.1067],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1437, 0.1822, 0.1632, 0.1679, 0.1663, 0.1766], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1105\n",
      "1105\n",
      "tensor([-0.0816,  0.1455,  0.0730,  0.0154,  0.0601,  0.0718],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1462, 0.1834, 0.1706, 0.1610, 0.1684, 0.1704], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1106\n",
      "1106\n",
      "tensor([-0.1138,  0.1306,  0.0420,  0.0353,  0.0579,  0.1134],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1419, 0.1812, 0.1658, 0.1647, 0.1685, 0.1781], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1107\n",
      "1107\n",
      "tensor([-0.0841,  0.1424,  0.0717,  0.0317,  0.0769,  0.1151],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1441, 0.1807, 0.1684, 0.1618, 0.1693, 0.1758], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1108\n",
      "1108\n",
      "tensor([-0.0952,  0.1354,  0.0452,  0.0304,  0.0336,  0.0915],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1452, 0.1829, 0.1671, 0.1646, 0.1652, 0.1750], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1109\n",
      "1109\n",
      "tensor([-0.0879,  0.1228,  0.0647,  0.0208,  0.0622,  0.0834],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1457, 0.1799, 0.1697, 0.1624, 0.1693, 0.1729], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1110\n",
      "1110\n",
      "tensor([-0.0855,  0.1409,  0.0496,  0.0285,  0.0721,  0.1096],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1448, 0.1816, 0.1658, 0.1623, 0.1695, 0.1760], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1111\n",
      "1111\n",
      "tensor([-0.1156,  0.1179,  0.0576,  0.0267,  0.0594,  0.0981],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1422, 0.1796, 0.1690, 0.1639, 0.1693, 0.1760], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1112\n",
      "1112\n",
      "tensor([-0.0665,  0.1231,  0.0965,  0.0584,  0.0573,  0.0858],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1467, 0.1774, 0.1727, 0.1662, 0.1661, 0.1709], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1113\n",
      "1113\n",
      "tensor([-0.0672,  0.1553,  0.0864,  0.0134,  0.0733,  0.1232],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1458, 0.1821, 0.1700, 0.1580, 0.1678, 0.1763], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1114\n",
      "1114\n",
      "tensor([-0.0865,  0.1609,  0.0541,  0.0285,  0.0658,  0.0793],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1450, 0.1857, 0.1668, 0.1626, 0.1688, 0.1711], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1115\n",
      "1115\n",
      "tensor([-0.1047,  0.1311,  0.0662,  0.0514,  0.0624,  0.1073],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1421, 0.1798, 0.1685, 0.1661, 0.1679, 0.1756], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1116\n",
      "1116\n",
      "tensor([-0.0995,  0.1628,  0.0434, -0.0158,  0.0385,  0.0840],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1451, 0.1887, 0.1674, 0.1578, 0.1666, 0.1744], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1117\n",
      "1117\n",
      "tensor([-0.0856,  0.1508,  0.0551,  0.0678,  0.0622,  0.1025],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1439, 0.1823, 0.1656, 0.1677, 0.1668, 0.1737], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1118\n",
      "1118\n",
      "tensor([-0.1139,  0.1301,  0.0380,  0.0075,  0.0776,  0.0960],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1426, 0.1820, 0.1660, 0.1610, 0.1727, 0.1759], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1119\n",
      "1119\n",
      "tensor([-0.0767,  0.1226,  0.0548,  0.0172,  0.0636,  0.0980],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1470, 0.1795, 0.1677, 0.1615, 0.1692, 0.1751], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1120\n",
      "1120\n",
      "tensor([-0.1088,  0.1327,  0.0677,  0.0377,  0.0586,  0.1294],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1413, 0.1799, 0.1686, 0.1636, 0.1671, 0.1794], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1121\n",
      "1121\n",
      "tensor([-0.1000,  0.1393,  0.0576,  0.0566,  0.0400,  0.1032],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1431, 0.1818, 0.1676, 0.1674, 0.1647, 0.1754], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1122\n",
      "1122\n",
      "tensor([-0.1192,  0.1358,  0.0305, -0.0072,  0.0485,  0.1044],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1428, 0.1843, 0.1658, 0.1597, 0.1688, 0.1786], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1123\n",
      "1123\n",
      "tensor([-0.0622,  0.1214,  0.0950,  0.0222,  0.0487,  0.0861],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1484, 0.1783, 0.1737, 0.1615, 0.1659, 0.1722], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1124\n",
      "1124\n",
      "tensor([-0.1038,  0.1248,  0.0534,  0.0124,  0.0668,  0.0739],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1443, 0.1813, 0.1688, 0.1621, 0.1711, 0.1723], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1125\n",
      "1125\n",
      "tensor([-0.0792,  0.1425,  0.0277,  0.0881,  0.0521,  0.1091],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1451, 0.1811, 0.1615, 0.1716, 0.1655, 0.1752], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1126\n",
      "1126\n",
      "tensor([-0.1096,  0.1506,  0.0731,  0.0531,  0.0266,  0.0884],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1421, 0.1843, 0.1705, 0.1672, 0.1628, 0.1732], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1127\n",
      "1127\n",
      "tensor([-0.0787,  0.1503,  0.0599, -0.0164,  0.0984,  0.1075],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1456, 0.1831, 0.1672, 0.1549, 0.1738, 0.1754], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1128\n",
      "1128\n",
      "tensor([-0.0877,  0.1313,  0.0332,  0.0313,  0.0652,  0.1115],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1452, 0.1808, 0.1639, 0.1636, 0.1692, 0.1772], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1129\n",
      "1129\n",
      "tensor([-0.0930,  0.1341,  0.0468,  0.0399,  0.0873,  0.1198],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1432, 0.1797, 0.1647, 0.1636, 0.1715, 0.1772], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1130\n",
      "1130\n",
      "tensor([-0.0932,  0.1341,  0.0327,  0.0268,  0.0478,  0.0679],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1461, 0.1834, 0.1657, 0.1648, 0.1683, 0.1717], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1131\n",
      "1131\n",
      "tensor([-0.0698,  0.1530,  0.0906,  0.0087,  0.0685,  0.0796],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1467, 0.1834, 0.1723, 0.1587, 0.1685, 0.1704], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1132\n",
      "1132\n",
      "tensor([-0.1036,  0.1340,  0.0422,  0.0702,  0.0671,  0.1112],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1420, 0.1801, 0.1643, 0.1690, 0.1685, 0.1761], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1133\n",
      "1133\n",
      "tensor([-0.1193,  0.1278,  0.0599,  0.0466,  0.0551,  0.1082],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1408, 0.1802, 0.1684, 0.1662, 0.1676, 0.1768], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1134\n",
      "1134\n",
      "tensor([-0.0655,  0.1447,  0.0589,  0.0350,  0.0716,  0.0730],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1478, 0.1823, 0.1673, 0.1634, 0.1695, 0.1697], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1135\n",
      "1135\n",
      "tensor([-0.0881,  0.1727,  0.0388,  0.0251,  0.0550,  0.1142],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1443, 0.1873, 0.1638, 0.1616, 0.1665, 0.1766], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1136\n",
      "1136\n",
      "tensor([-0.1262,  0.1209,  0.0920,  0.0250,  0.0461,  0.1004],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1403, 0.1796, 0.1745, 0.1632, 0.1666, 0.1759], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1137\n",
      "1137\n",
      "tensor([-0.1064,  0.1803,  0.0463,  0.0652,  0.0494,  0.0793],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1417, 0.1888, 0.1651, 0.1682, 0.1656, 0.1706], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1138\n",
      "1138\n",
      "tensor([-0.0907,  0.1100,  0.0492,  0.0263,  0.0550,  0.0896],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1460, 0.1784, 0.1679, 0.1641, 0.1689, 0.1748], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1139\n",
      "1139\n",
      "tensor([-0.0794,  0.1160,  0.0625,  0.0791,  0.0352,  0.1049],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1457, 0.1771, 0.1679, 0.1707, 0.1634, 0.1752], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1140\n",
      "1140\n",
      "tensor([-0.0876,  0.1530,  0.0741,  0.0146,  0.0535,  0.0792],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1452, 0.1847, 0.1707, 0.1608, 0.1672, 0.1715], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1141\n",
      "1141\n",
      "tensor([-0.0795,  0.1168,  0.0536,  0.0393,  0.0781,  0.0941],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1461, 0.1778, 0.1669, 0.1645, 0.1710, 0.1738], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1142\n",
      "1142\n",
      "tensor([-0.0946,  0.1113,  0.0379,  0.0070,  0.0553,  0.0707],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1467, 0.1802, 0.1674, 0.1623, 0.1704, 0.1730], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1143\n",
      "1143\n",
      "tensor([-0.0821,  0.1254,  0.0501,  0.0277,  0.0995,  0.0854],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1456, 0.1791, 0.1661, 0.1625, 0.1746, 0.1721], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1144\n",
      "1144\n",
      "tensor([-0.1031,  0.1379,  0.0617,  0.0171,  0.0543,  0.1376],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1424, 0.1812, 0.1679, 0.1606, 0.1667, 0.1812], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1145\n",
      "1145\n",
      "tensor([-0.0972,  0.1068,  0.0588,  0.0393,  0.0785,  0.0810],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1443, 0.1770, 0.1687, 0.1654, 0.1721, 0.1725], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1146\n",
      "1146\n",
      "tensor([-0.0866,  0.1340,  0.0715,  0.0274,  0.0641,  0.1002],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1448, 0.1805, 0.1696, 0.1623, 0.1683, 0.1745], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1147\n",
      "1147\n",
      "tensor([-0.0827,  0.1345,  0.1069,  0.0510,  0.0286,  0.1182],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1442, 0.1792, 0.1743, 0.1648, 0.1612, 0.1763], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1148\n",
      "1148\n",
      "tensor([-0.0819,  0.1275,  0.0088,  0.0192,  0.0899,  0.1083],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1464, 0.1805, 0.1603, 0.1620, 0.1738, 0.1771], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1149\n",
      "1149\n",
      "tensor([-0.0943,  0.1552,  0.0875,  0.0506,  0.0445,  0.0615],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1438, 0.1845, 0.1724, 0.1662, 0.1652, 0.1680], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1150\n",
      "1150\n",
      "tensor([-0.1233,  0.1325,  0.0564,  0.0368,  0.0804,  0.0973],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1402, 0.1810, 0.1678, 0.1645, 0.1718, 0.1748], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1151\n",
      "1151\n",
      "tensor([-0.1136,  0.1355,  0.0675,  0.0324,  0.0726,  0.0924],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1414, 0.1814, 0.1695, 0.1636, 0.1703, 0.1738], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1152\n",
      "1152\n",
      "tensor([-0.0852,  0.1372,  0.0311,  0.0500,  0.0327,  0.0952],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1462, 0.1826, 0.1642, 0.1674, 0.1645, 0.1751], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1153\n",
      "1153\n",
      "tensor([-0.0892,  0.1272,  0.0468,  0.0434,  0.0774,  0.1114],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1443, 0.1791, 0.1653, 0.1647, 0.1704, 0.1763], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1154\n",
      "1154\n",
      "tensor([-0.0960,  0.1138,  0.0519,  0.0168,  0.0646,  0.0874],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1452, 0.1791, 0.1683, 0.1625, 0.1705, 0.1744], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1155\n",
      "1155\n",
      "tensor([-0.0690,  0.1259,  0.0353,  0.0715,  0.0525,  0.0885],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1476, 0.1793, 0.1638, 0.1698, 0.1667, 0.1728], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1156\n",
      "1156\n",
      "tensor([-0.0864,  0.1423,  0.0740,  0.0047,  0.0660,  0.0806],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1455, 0.1829, 0.1708, 0.1594, 0.1695, 0.1719], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1157\n",
      "1157\n",
      "tensor([-0.0891,  0.1146,  0.0641,  0.0099,  0.0626,  0.0744],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1463, 0.1793, 0.1705, 0.1615, 0.1702, 0.1722], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1158\n",
      "1158\n",
      "tensor([-0.1111,  0.1576,  0.0400,  0.0453,  0.0640,  0.0885],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1418, 0.1855, 0.1649, 0.1658, 0.1689, 0.1731], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1159\n",
      "1159\n",
      "tensor([-0.0858,  0.1259,  0.0600,  0.0335,  0.0626,  0.0988],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1453, 0.1796, 0.1681, 0.1637, 0.1686, 0.1748], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1160\n",
      "1160\n",
      "tensor([-0.1023,  0.1253,  0.0452,  0.0101,  0.0575,  0.1041],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1442, 0.1810, 0.1671, 0.1613, 0.1692, 0.1772], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1161\n",
      "1161\n",
      "tensor([-0.1007,  0.1652,  0.0700,  0.0011,  0.0614,  0.0753],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1435, 0.1873, 0.1703, 0.1589, 0.1688, 0.1712], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1162\n",
      "1162\n",
      "tensor([-0.1049,  0.1471,  0.0312,  0.0609,  0.0460,  0.1046],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1427, 0.1836, 0.1635, 0.1684, 0.1659, 0.1759], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1163\n",
      "1163\n",
      "tensor([-0.0949,  0.1236,  0.0553,  0.0294,  0.0482,  0.0948],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1449, 0.1803, 0.1684, 0.1641, 0.1672, 0.1752], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1164\n",
      "1164\n",
      "tensor([-0.0929,  0.1534,  0.0926,  0.0229,  0.0727,  0.0641],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1438, 0.1839, 0.1731, 0.1614, 0.1697, 0.1682], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1165\n",
      "1165\n",
      "tensor([-0.0947,  0.1272,  0.0620,  0.0255,  0.0607,  0.0957],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1444, 0.1803, 0.1689, 0.1629, 0.1687, 0.1747], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1166\n",
      "1166\n",
      "tensor([-0.1063,  0.1229,  0.0364,  0.0316,  0.0704,  0.1126],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1429, 0.1797, 0.1648, 0.1641, 0.1705, 0.1779], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1167\n",
      "1167\n",
      "tensor([-0.0787,  0.1579,  0.0520,  0.0209,  0.0574,  0.1020],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1459, 0.1848, 0.1662, 0.1612, 0.1671, 0.1748], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1168\n",
      "1168\n",
      "tensor([-0.1168,  0.1149,  0.0436,  0.0337,  0.0069,  0.0867],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1438, 0.1813, 0.1688, 0.1671, 0.1627, 0.1762], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1169\n",
      "1169\n",
      "tensor([-0.1082,  0.1437,  0.0749,  0.0193,  0.0822,  0.1197],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1411, 0.1815, 0.1694, 0.1602, 0.1706, 0.1772], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1170\n",
      "1170\n",
      "tensor([-0.0698,  0.1800,  0.0740,  0.0302,  0.0557,  0.0588],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1467, 0.1884, 0.1694, 0.1622, 0.1664, 0.1669], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1171\n",
      "1171\n",
      "tensor([-0.1346,  0.1292,  0.0148,  0.0442,  0.0596,  0.0913],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1403, 0.1827, 0.1629, 0.1678, 0.1704, 0.1759], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1172\n",
      "1172\n",
      "tensor([-0.0903,  0.1230,  0.0544,  0.0223,  0.0477,  0.0722],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1463, 0.1810, 0.1690, 0.1637, 0.1679, 0.1721], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1173\n",
      "1173\n",
      "tensor([-0.0942,  0.1204,  0.0455,  0.0298,  0.0496,  0.0988],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1452, 0.1799, 0.1669, 0.1643, 0.1676, 0.1761], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1174\n",
      "1174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1084,  0.1485,  0.0318,  0.0362,  0.0761,  0.0904],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1424, 0.1841, 0.1639, 0.1646, 0.1713, 0.1737], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1175\n",
      "1175\n",
      "tensor([-0.1207,  0.1540,  0.0791, -0.0010,  0.0671,  0.1183],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1400, 0.1843, 0.1710, 0.1578, 0.1690, 0.1778], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1176\n",
      "1176\n",
      "tensor([-0.0882,  0.1245,  0.0483, -0.0089,  0.0551,  0.0786],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1470, 0.1819, 0.1685, 0.1592, 0.1697, 0.1737], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1177\n",
      "1177\n",
      "tensor([-0.1015,  0.1671,  0.0642,  0.0541,  0.0113,  0.1162],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1425, 0.1864, 0.1681, 0.1664, 0.1595, 0.1771], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1178\n",
      "1178\n",
      "tensor([-0.0939,  0.1513,  0.0491,  0.0121,  0.0560,  0.0934],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1447, 0.1849, 0.1669, 0.1609, 0.1681, 0.1745], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1179\n",
      "1179\n",
      "tensor([-0.0981,  0.1128,  0.0302,  0.0249,  0.0729,  0.0611],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1457, 0.1800, 0.1657, 0.1648, 0.1729, 0.1709], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1180\n",
      "1180\n",
      "tensor([-0.0899,  0.1329,  0.0799,  0.0396,  0.0690,  0.1071],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1436, 0.1795, 0.1702, 0.1635, 0.1684, 0.1749], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1181\n",
      "1181\n",
      "tensor([-0.0791,  0.1318,  0.0639,  0.0263,  0.0543,  0.0869],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1466, 0.1810, 0.1691, 0.1629, 0.1675, 0.1730], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1182\n",
      "1182\n",
      "tensor([-0.1109,  0.1493,  0.0545, -0.0018,  0.0738,  0.1229],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1417, 0.1838, 0.1672, 0.1580, 0.1704, 0.1790], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1183\n",
      "1183\n",
      "tensor([-0.0991,  0.1079,  0.0710,  0.0246,  0.0669,  0.0779],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1445, 0.1777, 0.1713, 0.1635, 0.1706, 0.1725], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1184\n",
      "1184\n",
      "tensor([-0.0799,  0.1387,  0.0551,  0.0159,  0.0578,  0.0692],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1471, 0.1830, 0.1684, 0.1619, 0.1688, 0.1708], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1185\n",
      "1185\n",
      "tensor([-0.1192,  0.1369,  0.0610,  0.0464,  0.0421,  0.0934],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1412, 0.1824, 0.1691, 0.1667, 0.1659, 0.1747], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1186\n",
      "1186\n",
      "tensor([-0.0937,  0.1409,  0.0500,  0.0546,  0.0591,  0.1149],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1433, 0.1813, 0.1655, 0.1663, 0.1670, 0.1766], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1187\n",
      "1187\n",
      "tensor([-0.0944,  0.1079,  0.0277,  0.0480,  0.0663,  0.0987],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1450, 0.1776, 0.1639, 0.1672, 0.1703, 0.1759], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1188\n",
      "1188\n",
      "tensor([-0.0986,  0.1319,  0.0682,  0.0242,  0.0616,  0.0826],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1440, 0.1813, 0.1702, 0.1628, 0.1690, 0.1726], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1189\n",
      "1189\n",
      "tensor([-0.0773,  0.3529,  0.0014,  0.1245,  0.1670,  0.3718],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1301, 0.2000, 0.1407, 0.1592, 0.1661, 0.2038], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1190\n",
      "1190\n",
      "tensor([-0.1014,  0.1251,  0.0595,  0.0210,  0.0686,  0.0887],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1438, 0.1804, 0.1689, 0.1625, 0.1705, 0.1739], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1191\n",
      "1191\n",
      "tensor([-0.1014,  0.1251,  0.0595,  0.0210,  0.0686,  0.0887],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1438, 0.1804, 0.1689, 0.1625, 0.1705, 0.1739], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1192\n",
      "1192\n",
      "tensor([ 0.0599,  0.0831, -0.0395,  0.3388, -0.0691, -0.0991],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1671, 0.1711, 0.1513, 0.2209, 0.1469, 0.1426], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1193\n",
      "1193\n",
      "tensor([-0.0940,  0.1405,  0.0545,  0.0060,  0.0433,  0.0775],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1457, 0.1842, 0.1690, 0.1610, 0.1671, 0.1730], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1194\n",
      "1194\n",
      "tensor([-0.0959,  0.1329,  0.0388,  0.0316,  0.0826,  0.1122],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1436, 0.1805, 0.1643, 0.1631, 0.1717, 0.1768], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1195\n",
      "1195\n",
      "tensor([-0.1107,  0.1352,  0.0288,  0.0278,  0.0732,  0.1160],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1422, 0.1818, 0.1635, 0.1633, 0.1709, 0.1784], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1196\n",
      "1196\n",
      "tensor([-0.0606,  0.1035,  0.0645,  0.0260,  0.0671,  0.0939],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1491, 0.1757, 0.1690, 0.1626, 0.1694, 0.1741], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1197\n",
      "1197\n",
      "tensor([-0.0811,  0.1445,  0.0651,  0.0553,  0.0425,  0.0936],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1454, 0.1822, 0.1683, 0.1666, 0.1645, 0.1731], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1198\n",
      "1198\n",
      "tensor([-0.1159,  0.1207,  0.0797,  0.0032,  0.0774,  0.0806],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1420, 0.1800, 0.1727, 0.1600, 0.1723, 0.1729], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1199\n",
      "1199\n",
      "tensor([-0.0983,  0.1209,  0.0635,  0.0383,  0.0815,  0.1057],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1431, 0.1781, 0.1682, 0.1640, 0.1712, 0.1754], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1200\n",
      "1200\n",
      "tensor([-0.0943,  0.1307,  0.0672,  0.0507,  0.0452,  0.0875],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1443, 0.1806, 0.1695, 0.1667, 0.1658, 0.1730], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1201\n",
      "1201\n",
      "tensor([-0.1087,  0.1459,  0.0374,  0.0204,  0.0615,  0.1225],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1422, 0.1835, 0.1646, 0.1618, 0.1686, 0.1792], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1202\n",
      "1202\n",
      "tensor([-0.0838,  0.1464,  0.0759,  0.0566,  0.0900,  0.0866],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1437, 0.1809, 0.1686, 0.1654, 0.1710, 0.1704], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1203\n",
      "1203\n",
      "tensor([-0.0770,  0.1312,  0.0379,  0.0143,  0.0435,  0.1157],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([0.1473, 0.1814, 0.1652, 0.1614, 0.1661, 0.1786], dtype=torch.float64,\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "1204\n",
      "1204\n",
      "$$ [tensor(-1.7525, dtype=torch.float64), tensor(-1.6993, dtype=torch.float64), tensor(-1.7787, dtype=torch.float64), tensor(-1.7080, dtype=torch.float64), tensor(-1.7727, dtype=torch.float64), tensor(-1.7771, dtype=torch.float64), tensor(-1.9569, dtype=torch.float64), tensor(-1.7439, dtype=torch.float64), tensor(-1.7792, dtype=torch.float64), tensor(-1.7140, dtype=torch.float64), tensor(-1.7809, dtype=torch.float64), tensor(-1.9289, dtype=torch.float64), tensor(-1.9341, dtype=torch.float64), tensor(-1.7683, dtype=torch.float64), tensor(-1.7392, dtype=torch.float64), tensor(-1.9397, dtype=torch.float64), tensor(-1.7877, dtype=torch.float64), tensor(-1.9318, dtype=torch.float64), tensor(-1.7443, dtype=torch.float64), tensor(-1.9372, dtype=torch.float64), tensor(-1.7114, dtype=torch.float64), tensor(-1.7815, dtype=torch.float64), tensor(-1.7718, dtype=torch.float64), tensor(-1.7797, dtype=torch.float64), tensor(-1.8062, dtype=torch.float64), tensor(-1.6973, dtype=torch.float64), tensor(-1.9777, dtype=torch.float64), tensor(-1.7458, dtype=torch.float64), tensor(-1.7294, dtype=torch.float64), tensor(-1.9424, dtype=torch.float64), tensor(-1.8220, dtype=torch.float64), tensor(-1.7686, dtype=torch.float64), tensor(-1.9482, dtype=torch.float64), tensor(-1.7333, dtype=torch.float64), tensor(-1.9294, dtype=torch.float64), tensor(-1.8096, dtype=torch.float64), tensor(-1.7922, dtype=torch.float64), tensor(-1.7651, dtype=torch.float64), tensor(-1.7561, dtype=torch.float64), tensor(-1.7523, dtype=torch.float64), tensor(-1.6803, dtype=torch.float64), tensor(-1.8008, dtype=torch.float64), tensor(-1.8109, dtype=torch.float64), tensor(-1.7981, dtype=torch.float64), tensor(-1.9613, dtype=torch.float64), tensor(-1.7573, dtype=torch.float64), tensor(-1.7732, dtype=torch.float64), tensor(-1.8109, dtype=torch.float64), tensor(-1.9167, dtype=torch.float64), tensor(-1.7175, dtype=torch.float64), tensor(-1.8182, dtype=torch.float64), tensor(-1.7607, dtype=torch.float64), tensor(-1.7899, dtype=torch.float64), tensor(-1.8262, dtype=torch.float64), tensor(-1.8009, dtype=torch.float64), tensor(-1.8062, dtype=torch.float64), tensor(-1.7965, dtype=torch.float64), tensor(-1.7610, dtype=torch.float64), tensor(-1.6933, dtype=torch.float64), tensor(-1.7884, dtype=torch.float64), tensor(-1.7097, dtype=torch.float64), tensor(-1.7982, dtype=torch.float64), tensor(-1.7923, dtype=torch.float64), tensor(-1.7675, dtype=torch.float64), tensor(-1.7940, dtype=torch.float64), tensor(-1.7732, dtype=torch.float64), tensor(-1.8109, dtype=torch.float64), tensor(-1.7620, dtype=torch.float64), tensor(-1.7608, dtype=torch.float64), tensor(-1.7514, dtype=torch.float64), tensor(-1.8274, dtype=torch.float64), tensor(-1.7769, dtype=torch.float64), tensor(-1.7750, dtype=torch.float64), tensor(-1.7496, dtype=torch.float64), tensor(-1.7969, dtype=torch.float64), tensor(-1.7354, dtype=torch.float64), tensor(-1.7685, dtype=torch.float64), tensor(-1.7773, dtype=torch.float64), tensor(-1.7552, dtype=torch.float64), tensor(-1.9273, dtype=torch.float64), tensor(-1.7801, dtype=torch.float64), tensor(-1.7263, dtype=torch.float64), tensor(-1.8141, dtype=torch.float64), tensor(-1.7494, dtype=torch.float64), tensor(-1.7320, dtype=torch.float64), tensor(-1.8323, dtype=torch.float64), tensor(-1.7419, dtype=torch.float64), tensor(-1.7044, dtype=torch.float64), tensor(-1.9201, dtype=torch.float64), tensor(-1.7856, dtype=torch.float64), tensor(-1.8145, dtype=torch.float64), tensor(-1.7890, dtype=torch.float64), tensor(-1.7382, dtype=torch.float64), tensor(-1.7542, dtype=torch.float64), tensor(-1.7671, dtype=torch.float64), tensor(-1.8098, dtype=torch.float64), tensor(-1.7044, dtype=torch.float64), tensor(-1.7965, dtype=torch.float64), tensor(-1.6923, dtype=torch.float64), tensor(-1.7379, dtype=torch.float64), tensor(-1.7533, dtype=torch.float64), tensor(-1.7879, dtype=torch.float64), tensor(-1.7677, dtype=torch.float64), tensor(-1.7320, dtype=torch.float64), tensor(-1.7582, dtype=torch.float64), tensor(-1.8382, dtype=torch.float64), tensor(-1.8145, dtype=torch.float64), tensor(-1.7088, dtype=torch.float64), tensor(-1.7824, dtype=torch.float64), tensor(-1.9104, dtype=torch.float64), tensor(-1.7335, dtype=torch.float64), tensor(-1.7882, dtype=torch.float64), tensor(-1.7103, dtype=torch.float64), tensor(-1.7794, dtype=torch.float64), tensor(-1.7701, dtype=torch.float64), tensor(-1.7710, dtype=torch.float64), tensor(-1.7990, dtype=torch.float64), tensor(-1.6992, dtype=torch.float64), tensor(-1.9333, dtype=torch.float64), tensor(-1.7155, dtype=torch.float64), tensor(-1.8070, dtype=torch.float64), tensor(-1.7863, dtype=torch.float64), tensor(-1.7668, dtype=torch.float64), tensor(-1.7679, dtype=torch.float64), tensor(-1.7752, dtype=torch.float64), tensor(-1.9309, dtype=torch.float64), tensor(-1.7664, dtype=torch.float64), tensor(-1.6830, dtype=torch.float64), tensor(-1.9350, dtype=torch.float64), tensor(-1.6902, dtype=torch.float64), tensor(-1.7717, dtype=torch.float64), tensor(-1.9327, dtype=torch.float64), tensor(-1.9522, dtype=torch.float64), tensor(-1.7137, dtype=torch.float64), tensor(-1.7152, dtype=torch.float64), tensor(-1.7904, dtype=torch.float64), tensor(-1.7301, dtype=torch.float64), tensor(-1.7079, dtype=torch.float64), tensor(-1.8047, dtype=torch.float64), tensor(-1.7856, dtype=torch.float64), tensor(-1.7422, dtype=torch.float64), tensor(-1.9365, dtype=torch.float64), tensor(-1.7777, dtype=torch.float64), tensor(-1.6929, dtype=torch.float64), tensor(-1.7197, dtype=torch.float64), tensor(-1.8138, dtype=torch.float64), tensor(-1.7527, dtype=torch.float64), tensor(-1.9413, dtype=torch.float64), tensor(-1.7223, dtype=torch.float64), tensor(-1.6912, dtype=torch.float64), tensor(-1.7500, dtype=torch.float64), tensor(-1.7127, dtype=torch.float64), tensor(-1.7686, dtype=torch.float64), tensor(-1.7455, dtype=torch.float64), tensor(-1.9406, dtype=torch.float64), tensor(-1.7826, dtype=torch.float64), tensor(-1.8314, dtype=torch.float64), tensor(-1.8142, dtype=torch.float64), tensor(-1.8143, dtype=torch.float64), tensor(-1.7612, dtype=torch.float64), tensor(-1.7140, dtype=torch.float64), tensor(-1.8136, dtype=torch.float64), tensor(-1.9338, dtype=torch.float64), tensor(-1.6905, dtype=torch.float64), tensor(-1.8114, dtype=torch.float64), tensor(-1.8393, dtype=torch.float64), tensor(-1.7228, dtype=torch.float64), tensor(-1.9204, dtype=torch.float64), tensor(-1.7671, dtype=torch.float64), tensor(-1.7499, dtype=torch.float64), tensor(-1.7728, dtype=torch.float64), tensor(-1.7961, dtype=torch.float64), tensor(-1.7477, dtype=torch.float64), tensor(-1.9188, dtype=torch.float64), tensor(-1.9342, dtype=torch.float64), tensor(-1.7518, dtype=torch.float64), tensor(-1.7641, dtype=torch.float64), tensor(-1.7937, dtype=torch.float64), tensor(-1.7977, dtype=torch.float64), tensor(-1.7224, dtype=torch.float64), tensor(-1.7762, dtype=torch.float64), tensor(-1.7423, dtype=torch.float64), tensor(-1.9398, dtype=torch.float64), tensor(-1.7393, dtype=torch.float64), tensor(-1.8136, dtype=torch.float64), tensor(-1.7867, dtype=torch.float64), tensor(-1.9683, dtype=torch.float64), tensor(-1.7797, dtype=torch.float64), tensor(-1.7876, dtype=torch.float64), tensor(-1.8100, dtype=torch.float64), tensor(-1.8153, dtype=torch.float64), tensor(-1.6905, dtype=torch.float64), tensor(-1.7442, dtype=torch.float64), tensor(-1.7310, dtype=torch.float64), tensor(-1.7964, dtype=torch.float64), tensor(-1.7264, dtype=torch.float64), tensor(-1.7729, dtype=torch.float64), tensor(-1.7775, dtype=torch.float64), tensor(-1.8253, dtype=torch.float64), tensor(-1.8213, dtype=torch.float64), tensor(-1.7685, dtype=torch.float64), tensor(-1.7595, dtype=torch.float64), tensor(-1.7488, dtype=torch.float64), tensor(-1.7790, dtype=torch.float64), tensor(-1.7633, dtype=torch.float64), tensor(-1.7275, dtype=torch.float64), tensor(-1.7975, dtype=torch.float64), tensor(-1.7691, dtype=torch.float64), tensor(-1.9449, dtype=torch.float64), tensor(-1.9225, dtype=torch.float64), tensor(-1.7937, dtype=torch.float64), tensor(-1.9128, dtype=torch.float64), tensor(-1.7916, dtype=torch.float64), tensor(-1.7615, dtype=torch.float64), tensor(-1.8178, dtype=torch.float64), tensor(-1.7186, dtype=torch.float64), tensor(-1.8162, dtype=torch.float64), tensor(-1.6797, dtype=torch.float64), tensor(-1.7532, dtype=torch.float64), tensor(-1.7715, dtype=torch.float64), tensor(-1.7690, dtype=torch.float64), tensor(-1.7349, dtype=torch.float64), tensor(-1.7759, dtype=torch.float64), tensor(-1.8250, dtype=torch.float64), tensor(-1.6882, dtype=torch.float64), tensor(-1.7288, dtype=torch.float64), tensor(-1.9343, dtype=torch.float64), tensor(-1.8225, dtype=torch.float64), tensor(-1.7482, dtype=torch.float64), tensor(-1.9458, dtype=torch.float64), tensor(-1.7709, dtype=torch.float64), tensor(-1.8192, dtype=torch.float64), tensor(-1.7332, dtype=torch.float64), tensor(-1.8108, dtype=torch.float64), tensor(-1.7631, dtype=torch.float64), tensor(-1.7227, dtype=torch.float64), tensor(-1.7408, dtype=torch.float64), tensor(-1.7665, dtype=torch.float64), tensor(-1.7805, dtype=torch.float64), tensor(-1.7081, dtype=torch.float64), tensor(-1.8335, dtype=torch.float64), tensor(-1.7198, dtype=torch.float64), tensor(-1.7843, dtype=torch.float64), tensor(-1.7470, dtype=torch.float64), tensor(-1.7807, dtype=torch.float64), tensor(-1.9265, dtype=torch.float64), tensor(-1.8089, dtype=torch.float64), tensor(-1.7575, dtype=torch.float64), tensor(-1.6889, dtype=torch.float64), tensor(-1.6965, dtype=torch.float64), tensor(-1.7849, dtype=torch.float64), tensor(-1.8219, dtype=torch.float64), tensor(-1.7812, dtype=torch.float64), tensor(-1.9506, dtype=torch.float64), tensor(-1.7523, dtype=torch.float64), tensor(-1.7795, dtype=torch.float64), tensor(-1.9170, dtype=torch.float64), tensor(-1.7505, dtype=torch.float64), tensor(-1.9469, dtype=torch.float64), tensor(-1.7772, dtype=torch.float64), tensor(-1.8193, dtype=torch.float64), tensor(-1.8114, dtype=torch.float64), tensor(-1.7653, dtype=torch.float64), tensor(-1.7436, dtype=torch.float64), tensor(-1.7497, dtype=torch.float64), tensor(-1.7620, dtype=torch.float64), tensor(-1.7391, dtype=torch.float64), tensor(-1.7771, dtype=torch.float64), tensor(-1.7172, dtype=torch.float64), tensor(-1.9501, dtype=torch.float64), tensor(-1.9192, dtype=torch.float64), tensor(-1.7779, dtype=torch.float64), tensor(-1.8364, dtype=torch.float64), tensor(-1.7040, dtype=torch.float64), tensor(-1.8080, dtype=torch.float64), tensor(-1.9116, dtype=torch.float64), tensor(-1.8119, dtype=torch.float64), tensor(-1.7692, dtype=torch.float64), tensor(-1.7731, dtype=torch.float64), tensor(-1.7220, dtype=torch.float64), tensor(-1.7149, dtype=torch.float64), tensor(-1.7453, dtype=torch.float64), tensor(-1.9379, dtype=torch.float64), tensor(-1.7125, dtype=torch.float64), tensor(-1.7799, dtype=torch.float64), tensor(-1.9347, dtype=torch.float64), tensor(-1.7323, dtype=torch.float64), tensor(-1.8081, dtype=torch.float64), tensor(-1.6939, dtype=torch.float64), tensor(-1.7391, dtype=torch.float64), tensor(-1.9243, dtype=torch.float64), tensor(-1.7720, dtype=torch.float64), tensor(-1.9431, dtype=torch.float64), tensor(-1.8077, dtype=torch.float64), tensor(-1.7790, dtype=torch.float64), tensor(-1.7148, dtype=torch.float64), tensor(-1.7488, dtype=torch.float64), tensor(-1.8038, dtype=torch.float64), tensor(-1.8232, dtype=torch.float64), tensor(-1.7679, dtype=torch.float64), tensor(-1.8150, dtype=torch.float64), tensor(-1.6836, dtype=torch.float64), tensor(-1.9386, dtype=torch.float64), tensor(-1.7699, dtype=torch.float64), tensor(-1.8104, dtype=torch.float64), tensor(-1.7841, dtype=torch.float64), tensor(-1.9236, dtype=torch.float64), tensor(-1.8035, dtype=torch.float64), tensor(-1.7439, dtype=torch.float64), tensor(-1.6937, dtype=torch.float64), tensor(-1.8030, dtype=torch.float64), tensor(-1.7723, dtype=torch.float64), tensor(-1.7754, dtype=torch.float64), tensor(-1.7201, dtype=torch.float64), tensor(-1.7041, dtype=torch.float64), tensor(-1.7801, dtype=torch.float64), tensor(-1.7702, dtype=torch.float64), tensor(-1.9303, dtype=torch.float64), tensor(-1.8051, dtype=torch.float64), tensor(-1.7185, dtype=torch.float64), tensor(-1.7882, dtype=torch.float64), tensor(-1.7399, dtype=torch.float64), tensor(-1.6845, dtype=torch.float64), tensor(-1.7365, dtype=torch.float64), tensor(-1.7135, dtype=torch.float64), tensor(-1.7703, dtype=torch.float64), tensor(-1.7817, dtype=torch.float64), tensor(-1.7730, dtype=torch.float64), tensor(-1.7782, dtype=torch.float64), tensor(-1.9198, dtype=torch.float64), tensor(-1.7979, dtype=torch.float64), tensor(-1.6963, dtype=torch.float64), tensor(-1.9313, dtype=torch.float64), tensor(-1.7774, dtype=torch.float64), tensor(-1.7812, dtype=torch.float64), tensor(-1.7762, dtype=torch.float64), tensor(-1.7803, dtype=torch.float64), tensor(-1.7714, dtype=torch.float64), tensor(-1.8526, dtype=torch.float64), tensor(-1.8058, dtype=torch.float64), tensor(-1.7780, dtype=torch.float64), tensor(-1.9434, dtype=torch.float64), tensor(-1.7843, dtype=torch.float64), tensor(-1.7675, dtype=torch.float64), tensor(-1.7053, dtype=torch.float64), tensor(-1.7739, dtype=torch.float64), tensor(-1.7079, dtype=torch.float64), tensor(-1.8097, dtype=torch.float64), tensor(-1.7761, dtype=torch.float64), tensor(-1.7276, dtype=torch.float64), tensor(-1.7571, dtype=torch.float64), tensor(-1.7867, dtype=torch.float64), tensor(-1.7599, dtype=torch.float64), tensor(-1.9425, dtype=torch.float64), tensor(-1.7881, dtype=torch.float64), tensor(-1.7627, dtype=torch.float64), tensor(-1.7904, dtype=torch.float64), tensor(-1.7097, dtype=torch.float64), tensor(-1.6920, dtype=torch.float64), tensor(-1.8055, dtype=torch.float64), tensor(-1.8055, dtype=torch.float64), tensor(-1.8335, dtype=torch.float64), tensor(-1.7954, dtype=torch.float64), tensor(-1.7907, dtype=torch.float64), tensor(-1.7510, dtype=torch.float64), tensor(-1.8077, dtype=torch.float64), tensor(-1.7956, dtype=torch.float64), tensor(-1.7412, dtype=torch.float64), tensor(-1.7817, dtype=torch.float64), tensor(-1.7022, dtype=torch.float64), tensor(-1.7810, dtype=torch.float64), tensor(-1.9505, dtype=torch.float64), tensor(-1.7724, dtype=torch.float64), tensor(-1.9303, dtype=torch.float64), tensor(-1.8063, dtype=torch.float64), tensor(-1.7390, dtype=torch.float64), tensor(-1.8066, dtype=torch.float64), tensor(-1.7094, dtype=torch.float64), tensor(-1.7727, dtype=torch.float64), tensor(-1.7988, dtype=torch.float64), tensor(-1.7142, dtype=torch.float64), tensor(-1.8029, dtype=torch.float64), tensor(-1.7121, dtype=torch.float64), tensor(-1.7056, dtype=torch.float64), tensor(-1.9066, dtype=torch.float64), tensor(-1.7627, dtype=torch.float64), tensor(-1.7984, dtype=torch.float64), tensor(-1.7149, dtype=torch.float64), tensor(-1.7815, dtype=torch.float64), tensor(-1.7810, dtype=torch.float64), tensor(-1.7052, dtype=torch.float64), tensor(-1.7320, dtype=torch.float64), tensor(-1.7342, dtype=torch.float64), tensor(-1.7527, dtype=torch.float64), tensor(-1.9365, dtype=torch.float64), tensor(-1.7358, dtype=torch.float64), tensor(-1.8012, dtype=torch.float64), tensor(-1.8290, dtype=torch.float64), tensor(-1.7905, dtype=torch.float64), tensor(-1.7329, dtype=torch.float64), tensor(-1.7698, dtype=torch.float64), tensor(-1.8090, dtype=torch.float64), tensor(-1.8085, dtype=torch.float64), tensor(-1.7234, dtype=torch.float64), tensor(-1.7084, dtype=torch.float64), tensor(-1.7727, dtype=torch.float64), tensor(-1.6992, dtype=torch.float64), tensor(-1.8097, dtype=torch.float64), tensor(-1.7512, dtype=torch.float64), tensor(-1.7017, dtype=torch.float64), tensor(-1.8127, dtype=torch.float64), tensor(-1.7579, dtype=torch.float64), tensor(-1.7718, dtype=torch.float64), tensor(-1.8078, dtype=torch.float64), tensor(-1.7121, dtype=torch.float64), tensor(-1.7198, dtype=torch.float64), tensor(-1.7012, dtype=torch.float64), tensor(-1.7792, dtype=torch.float64), tensor(-1.9465, dtype=torch.float64), tensor(-1.7809, dtype=torch.float64), tensor(-1.7772, dtype=torch.float64), tensor(-1.6960, dtype=torch.float64), tensor(-1.9321, dtype=torch.float64), tensor(-1.9526, dtype=torch.float64), tensor(-1.7997, dtype=torch.float64), tensor(-1.7124, dtype=torch.float64), tensor(-1.7059, dtype=torch.float64), tensor(-1.7681, dtype=torch.float64), tensor(-1.7348, dtype=torch.float64), tensor(-1.8149, dtype=torch.float64), tensor(-1.8381, dtype=torch.float64), tensor(-1.8193, dtype=torch.float64), tensor(-1.9283, dtype=torch.float64), tensor(-1.7746, dtype=torch.float64), tensor(-1.7196, dtype=torch.float64), tensor(-1.7919, dtype=torch.float64), tensor(-1.7872, dtype=torch.float64), tensor(-1.9413, dtype=torch.float64), tensor(-1.7065, dtype=torch.float64), tensor(-1.7018, dtype=torch.float64), tensor(-1.7417, dtype=torch.float64), tensor(-1.7193, dtype=torch.float64), tensor(-1.9211, dtype=torch.float64), tensor(-1.9352, dtype=torch.float64), tensor(-1.7795, dtype=torch.float64), tensor(-1.8083, dtype=torch.float64), tensor(-1.7161, dtype=torch.float64), tensor(-1.7953, dtype=torch.float64), tensor(-1.7766, dtype=torch.float64), tensor(-1.7967, dtype=torch.float64), tensor(-1.7104, dtype=torch.float64), tensor(-1.7608, dtype=torch.float64), tensor(-1.7538, dtype=torch.float64), tensor(-1.6947, dtype=torch.float64), tensor(-1.8113, dtype=torch.float64), tensor(-1.9304, dtype=torch.float64), tensor(-1.7652, dtype=torch.float64), tensor(-1.9240, dtype=torch.float64), tensor(-1.7672, dtype=torch.float64), tensor(-1.6907, dtype=torch.float64), tensor(-1.7714, dtype=torch.float64), tensor(-1.7719, dtype=torch.float64), tensor(-1.8120, dtype=torch.float64), tensor(-1.7832, dtype=torch.float64), tensor(-1.7634, dtype=torch.float64), tensor(-1.9046, dtype=torch.float64), tensor(-1.6946, dtype=torch.float64), tensor(-1.7870, dtype=torch.float64), tensor(-1.7169, dtype=torch.float64), tensor(-1.7953, dtype=torch.float64), tensor(-1.7168, dtype=torch.float64), tensor(-1.7343, dtype=torch.float64), tensor(-1.7808, dtype=torch.float64), tensor(-1.9330, dtype=torch.float64), tensor(-1.7629, dtype=torch.float64), tensor(-1.9156, dtype=torch.float64), tensor(-1.7466, dtype=torch.float64), tensor(-1.7581, dtype=torch.float64), tensor(-1.7900, dtype=torch.float64), tensor(-1.8018, dtype=torch.float64), tensor(-1.9372, dtype=torch.float64), tensor(-1.7904, dtype=torch.float64), tensor(-1.8029, dtype=torch.float64), tensor(-1.7792, dtype=torch.float64), tensor(-1.7043, dtype=torch.float64), tensor(-1.7930, dtype=torch.float64), tensor(-1.8117, dtype=torch.float64), tensor(-1.9250, dtype=torch.float64), tensor(-1.8238, dtype=torch.float64), tensor(-1.7559, dtype=torch.float64), tensor(-1.8221, dtype=torch.float64), tensor(-1.7802, dtype=torch.float64), tensor(-1.8016, dtype=torch.float64), tensor(-1.7630, dtype=torch.float64), tensor(-1.8098, dtype=torch.float64), tensor(-1.7470, dtype=torch.float64), tensor(-1.7189, dtype=torch.float64), tensor(-1.7134, dtype=torch.float64), tensor(-1.6987, dtype=torch.float64), tensor(-1.7736, dtype=torch.float64), tensor(-1.8183, dtype=torch.float64), tensor(-1.7974, dtype=torch.float64), tensor(-1.8108, dtype=torch.float64), tensor(-1.7767, dtype=torch.float64), tensor(-1.7893, dtype=torch.float64), tensor(-1.7986, dtype=torch.float64), tensor(-1.9260, dtype=torch.float64), tensor(-1.8044, dtype=torch.float64), tensor(-1.7030, dtype=torch.float64), tensor(-1.7763, dtype=torch.float64), tensor(-1.7751, dtype=torch.float64), tensor(-1.7969, dtype=torch.float64), tensor(-1.7761, dtype=torch.float64), tensor(-1.7551, dtype=torch.float64), tensor(-1.7989, dtype=torch.float64), tensor(-1.7102, dtype=torch.float64), tensor(-1.7050, dtype=torch.float64), tensor(-1.8108, dtype=torch.float64), tensor(-1.7554, dtype=torch.float64), tensor(-1.7154, dtype=torch.float64), tensor(-1.9406, dtype=torch.float64), tensor(-1.8111, dtype=torch.float64), tensor(-1.9240, dtype=torch.float64), tensor(-1.7220, dtype=torch.float64), tensor(-1.7745, dtype=torch.float64), tensor(-1.9202, dtype=torch.float64), tensor(-1.7741, dtype=torch.float64), tensor(-1.6991, dtype=torch.float64), tensor(-1.8236, dtype=torch.float64), tensor(-1.7899, dtype=torch.float64), tensor(-1.9624, dtype=torch.float64), tensor(-1.7980, dtype=torch.float64), tensor(-1.9074, dtype=torch.float64), tensor(-1.9427, dtype=torch.float64), tensor(-1.7633, dtype=torch.float64), tensor(-1.7016, dtype=torch.float64), tensor(-1.9416, dtype=torch.float64), tensor(-1.8224, dtype=torch.float64), tensor(-1.7850, dtype=torch.float64), tensor(-1.7133, dtype=torch.float64), tensor(-1.8073, dtype=torch.float64), tensor(-1.7472, dtype=torch.float64), tensor(-1.9554, dtype=torch.float64), tensor(-1.7137, dtype=torch.float64), tensor(-1.7116, dtype=torch.float64), tensor(-1.7627, dtype=torch.float64), tensor(-1.7563, dtype=torch.float64), tensor(-1.9376, dtype=torch.float64), tensor(-1.9518, dtype=torch.float64), tensor(-1.7426, dtype=torch.float64), tensor(-1.7817, dtype=torch.float64), tensor(-1.7684, dtype=torch.float64), tensor(-1.8304, dtype=torch.float64), tensor(-1.7834, dtype=torch.float64), tensor(-1.8320, dtype=torch.float64), tensor(-1.7147, dtype=torch.float64), tensor(-1.7649, dtype=torch.float64), tensor(-1.9309, dtype=torch.float64), tensor(-1.7869, dtype=torch.float64), tensor(-1.8030, dtype=torch.float64), tensor(-1.9296, dtype=torch.float64), tensor(-1.7662, dtype=torch.float64), tensor(-1.7976, dtype=torch.float64), tensor(-1.7225, dtype=torch.float64), tensor(-1.9312, dtype=torch.float64), tensor(-1.7727, dtype=torch.float64), tensor(-1.7272, dtype=torch.float64), tensor(-1.7927, dtype=torch.float64), tensor(-1.7769, dtype=torch.float64), tensor(-1.7522, dtype=torch.float64), tensor(-1.8038, dtype=torch.float64), tensor(-1.9556, dtype=torch.float64), tensor(-1.7086, dtype=torch.float64), tensor(-1.7777, dtype=torch.float64), tensor(-1.9340, dtype=torch.float64), tensor(-1.8104, dtype=torch.float64), tensor(-1.7855, dtype=torch.float64), tensor(-1.7783, dtype=torch.float64), tensor(-1.7933, dtype=torch.float64), tensor(-1.9368, dtype=torch.float64), tensor(-1.7860, dtype=torch.float64), tensor(-1.7508, dtype=torch.float64), tensor(-1.7145, dtype=torch.float64), tensor(-1.7086, dtype=torch.float64), tensor(-1.9313, dtype=torch.float64), tensor(-1.7634, dtype=torch.float64), tensor(-1.6944, dtype=torch.float64), tensor(-1.7410, dtype=torch.float64), tensor(-1.7250, dtype=torch.float64), tensor(-1.7059, dtype=torch.float64), tensor(-1.6785, dtype=torch.float64), tensor(-1.9425, dtype=torch.float64), tensor(-1.7421, dtype=torch.float64), tensor(-1.9494, dtype=torch.float64), tensor(-1.7785, dtype=torch.float64), tensor(-1.8067, dtype=torch.float64), tensor(-1.8121, dtype=torch.float64), tensor(-1.7347, dtype=torch.float64), tensor(-1.9551, dtype=torch.float64), tensor(-1.7060, dtype=torch.float64), tensor(-1.7095, dtype=torch.float64), tensor(-1.8405, dtype=torch.float64), tensor(-1.8102, dtype=torch.float64), tensor(-1.7660, dtype=torch.float64), tensor(-1.9414, dtype=torch.float64), tensor(-1.9557, dtype=torch.float64), tensor(-1.7693, dtype=torch.float64), tensor(-1.6803, dtype=torch.float64), tensor(-1.7022, dtype=torch.float64), tensor(-1.9234, dtype=torch.float64), tensor(-1.8089, dtype=torch.float64), tensor(-1.7230, dtype=torch.float64), tensor(-1.7600, dtype=torch.float64), tensor(-1.7493, dtype=torch.float64), tensor(-1.7088, dtype=torch.float64), tensor(-1.7047, dtype=torch.float64), tensor(-1.7670, dtype=torch.float64), tensor(-1.9096, dtype=torch.float64), tensor(-1.7320, dtype=torch.float64), tensor(-1.7592, dtype=torch.float64), tensor(-1.8058, dtype=torch.float64), tensor(-1.7282, dtype=torch.float64), tensor(-1.7785, dtype=torch.float64), tensor(-1.7909, dtype=torch.float64), tensor(-1.7967, dtype=torch.float64), tensor(-1.7281, dtype=torch.float64), tensor(-1.7758, dtype=torch.float64), tensor(-1.7776, dtype=torch.float64), tensor(-1.7520, dtype=torch.float64), tensor(-1.7490, dtype=torch.float64), tensor(-1.7002, dtype=torch.float64), tensor(-1.7410, dtype=torch.float64), tensor(-1.7277, dtype=torch.float64), tensor(-1.7570, dtype=torch.float64), tensor(-1.8144, dtype=torch.float64), tensor(-1.7036, dtype=torch.float64), tensor(-1.9417, dtype=torch.float64), tensor(-1.6654, dtype=torch.float64), tensor(-1.7745, dtype=torch.float64), tensor(-1.7824, dtype=torch.float64), tensor(-1.8375, dtype=torch.float64), tensor(-1.7385, dtype=torch.float64), tensor(-1.9487, dtype=torch.float64), tensor(-1.7821, dtype=torch.float64), tensor(-1.7940, dtype=torch.float64), tensor(-1.7822, dtype=torch.float64), tensor(-1.7557, dtype=torch.float64), tensor(-1.8030, dtype=torch.float64), tensor(-1.7550, dtype=torch.float64), tensor(-1.7664, dtype=torch.float64), tensor(-1.8052, dtype=torch.float64), tensor(-1.7687, dtype=torch.float64), tensor(-1.8028, dtype=torch.float64), tensor(-1.9313, dtype=torch.float64), tensor(-1.7167, dtype=torch.float64), tensor(-1.7060, dtype=torch.float64), tensor(-1.6913, dtype=torch.float64), tensor(-1.7643, dtype=torch.float64), tensor(-1.7558, dtype=torch.float64), tensor(-1.7114, dtype=torch.float64), tensor(-1.8073, dtype=torch.float64), tensor(-1.7767, dtype=torch.float64), tensor(-1.7886, dtype=torch.float64), tensor(-1.7646, dtype=torch.float64), tensor(-1.9438, dtype=torch.float64), tensor(-1.8077, dtype=torch.float64), tensor(-1.8112, dtype=torch.float64), tensor(-1.7148, dtype=torch.float64), tensor(-1.7625, dtype=torch.float64), tensor(-1.7937, dtype=torch.float64), tensor(-1.7584, dtype=torch.float64), tensor(-1.7624, dtype=torch.float64), tensor(-1.7408, dtype=torch.float64), tensor(-1.7598, dtype=torch.float64), tensor(-1.7857, dtype=torch.float64), tensor(-1.7260, dtype=torch.float64), tensor(-1.7803, dtype=torch.float64), tensor(-1.7578, dtype=torch.float64), tensor(-1.8000, dtype=torch.float64), tensor(-1.9598, dtype=torch.float64), tensor(-1.7560, dtype=torch.float64), tensor(-1.9335, dtype=torch.float64), tensor(-1.7690, dtype=torch.float64), tensor(-1.5265, dtype=torch.float64), tensor(-1.7388, dtype=torch.float64), tensor(-1.7626, dtype=torch.float64), tensor(-1.8233, dtype=torch.float64), tensor(-1.7848, dtype=torch.float64), tensor(-1.7421, dtype=torch.float64), tensor(-1.8093, dtype=torch.float64), tensor(-1.9049, dtype=torch.float64), tensor(-1.8003, dtype=torch.float64), tensor(-1.9542, dtype=torch.float64), tensor(-1.7818, dtype=torch.float64), tensor(-1.7846, dtype=torch.float64), tensor(-1.9443, dtype=torch.float64), tensor(-1.7469, dtype=torch.float64), tensor(-1.9415, dtype=torch.float64), tensor(-1.7464, dtype=torch.float64), tensor(-1.7331, dtype=torch.float64), tensor(-1.7198, dtype=torch.float64), tensor(-1.7935, dtype=torch.float64), tensor(-1.7346, dtype=torch.float64), tensor(-1.7982, dtype=torch.float64), tensor(-1.7694, dtype=torch.float64), tensor(-1.7737, dtype=torch.float64), tensor(-1.9697, dtype=torch.float64), tensor(-1.7853, dtype=torch.float64), tensor(-1.6965, dtype=torch.float64), tensor(-1.8353, dtype=torch.float64), tensor(-1.7599, dtype=torch.float64), tensor(-1.7060, dtype=torch.float64), tensor(-1.8250, dtype=torch.float64), tensor(-1.7869, dtype=torch.float64), tensor(-1.7673, dtype=torch.float64), tensor(-1.7750, dtype=torch.float64), tensor(-1.7945, dtype=torch.float64), tensor(-1.8289, dtype=torch.float64), tensor(-1.7860, dtype=torch.float64), tensor(-1.7201, dtype=torch.float64), tensor(-1.9360, dtype=torch.float64), tensor(-1.8111, dtype=torch.float64), tensor(-1.7576, dtype=torch.float64), tensor(-1.9627, dtype=torch.float64), tensor(-1.7561, dtype=torch.float64), tensor(-1.7454, dtype=torch.float64), tensor(-1.7890, dtype=torch.float64), tensor(-1.8402, dtype=torch.float64), tensor(-1.9436, dtype=torch.float64), tensor(-1.6920, dtype=torch.float64), tensor(-1.9558, dtype=torch.float64), tensor(-1.7474, dtype=torch.float64), tensor(-1.7520, dtype=torch.float64), tensor(-1.8163, dtype=torch.float64), tensor(-1.9089, dtype=torch.float64), tensor(-1.8192, dtype=torch.float64), tensor(-1.7222, dtype=torch.float64), tensor(-1.6961, dtype=torch.float64), tensor(-1.7483, dtype=torch.float64), tensor(-1.9232, dtype=torch.float64), tensor(-1.9334, dtype=torch.float64), tensor(-1.7975, dtype=torch.float64), tensor(-1.8196, dtype=torch.float64), tensor(-1.7069, dtype=torch.float64), tensor(-1.7980, dtype=torch.float64), tensor(-1.7905, dtype=torch.float64), tensor(-1.7928, dtype=torch.float64), tensor(-1.7038, dtype=torch.float64), tensor(-1.8104, dtype=torch.float64), tensor(-1.7045, dtype=torch.float64), tensor(-1.8012, dtype=torch.float64), tensor(-1.7576, dtype=torch.float64), tensor(-1.7038, dtype=torch.float64), tensor(-1.7732, dtype=torch.float64), tensor(-1.7857, dtype=torch.float64), tensor(-1.7555, dtype=torch.float64), tensor(-1.9526, dtype=torch.float64), tensor(-1.6812, dtype=torch.float64), tensor(-1.7918, dtype=torch.float64), tensor(-1.6995, dtype=torch.float64), tensor(-1.7288, dtype=torch.float64), tensor(-1.8070, dtype=torch.float64), tensor(-1.8270, dtype=torch.float64), tensor(-1.9160, dtype=torch.float64), tensor(-1.7915, dtype=torch.float64), tensor(-1.7502, dtype=torch.float64), tensor(-1.7145, dtype=torch.float64), tensor(-1.7639, dtype=torch.float64), tensor(-1.7917, dtype=torch.float64), tensor(-1.7819, dtype=torch.float64), tensor(-1.7851, dtype=torch.float64), tensor(-1.8133, dtype=torch.float64), tensor(-1.7594, dtype=torch.float64), tensor(-1.6959, dtype=torch.float64), tensor(-1.7806, dtype=torch.float64), tensor(-1.8070, dtype=torch.float64), tensor(-1.9425, dtype=torch.float64), tensor(-1.7599, dtype=torch.float64), tensor(-1.7655, dtype=torch.float64), tensor(-1.7462, dtype=torch.float64), tensor(-1.8142, dtype=torch.float64), tensor(-1.7674, dtype=torch.float64), tensor(-1.7794, dtype=torch.float64), tensor(-1.7705, dtype=torch.float64), tensor(-1.6834, dtype=torch.float64), tensor(-1.7971, dtype=torch.float64), tensor(-1.7955, dtype=torch.float64), tensor(-1.8130, dtype=torch.float64), tensor(-1.7352, dtype=torch.float64), tensor(-1.7162, dtype=torch.float64), tensor(-1.7077, dtype=torch.float64), tensor(-1.7365, dtype=torch.float64), tensor(-1.7171, dtype=torch.float64), tensor(-1.8001, dtype=torch.float64), tensor(-1.7526, dtype=torch.float64), tensor(-1.8077, dtype=torch.float64), tensor(-1.8046, dtype=torch.float64), tensor(-1.7912, dtype=torch.float64), tensor(-1.7639, dtype=torch.float64), tensor(-1.7213, dtype=torch.float64), tensor(-1.7751, dtype=torch.float64), tensor(-1.8030, dtype=torch.float64), tensor(-1.7583, dtype=torch.float64), tensor(-1.7522, dtype=torch.float64), tensor(-1.9244, dtype=torch.float64), tensor(-1.6884, dtype=torch.float64), tensor(-1.7022, dtype=torch.float64), tensor(-1.7901, dtype=torch.float64), tensor(-1.9335, dtype=torch.float64), tensor(-1.7109, dtype=torch.float64), tensor(-1.8218, dtype=torch.float64), tensor(-1.7856, dtype=torch.float64), tensor(-1.8077, dtype=torch.float64), tensor(-1.7800, dtype=torch.float64), tensor(-1.7413, dtype=torch.float64), tensor(-1.7908, dtype=torch.float64), tensor(-1.7769, dtype=torch.float64), tensor(-1.7730, dtype=torch.float64), tensor(-1.7195, dtype=torch.float64), tensor(-1.7475, dtype=torch.float64), tensor(-1.7569, dtype=torch.float64), tensor(-1.7464, dtype=torch.float64), tensor(-1.8233, dtype=torch.float64), tensor(-1.7543, dtype=torch.float64), tensor(-1.7780, dtype=torch.float64), tensor(-1.7652, dtype=torch.float64), tensor(-1.7140, dtype=torch.float64), tensor(-1.7352, dtype=torch.float64), tensor(-1.7182, dtype=torch.float64), tensor(-1.7799, dtype=torch.float64), tensor(-1.8159, dtype=torch.float64), tensor(-1.7132, dtype=torch.float64), tensor(-1.8032, dtype=torch.float64), tensor(-1.9587, dtype=torch.float64), tensor(-1.7876, dtype=torch.float64), tensor(-1.7467, dtype=torch.float64), tensor(-1.9362, dtype=torch.float64), tensor(-1.9129, dtype=torch.float64), tensor(-1.7666, dtype=torch.float64), tensor(-1.9447, dtype=torch.float64), tensor(-1.9225, dtype=torch.float64), tensor(-1.7257, dtype=torch.float64), tensor(-1.9601, dtype=torch.float64), tensor(-1.7253, dtype=torch.float64), tensor(-1.7299, dtype=torch.float64), tensor(-1.7790, dtype=torch.float64), tensor(-1.7353, dtype=torch.float64), tensor(-1.7243, dtype=torch.float64), tensor(-1.8086, dtype=torch.float64), tensor(-1.7874, dtype=torch.float64), tensor(-1.8026, dtype=torch.float64), tensor(-1.7503, dtype=torch.float64), tensor(-1.9487, dtype=torch.float64), tensor(-1.6959, dtype=torch.float64), tensor(-1.8228, dtype=torch.float64), tensor(-1.7728, dtype=torch.float64), tensor(-1.7575, dtype=torch.float64), tensor(-1.7997, dtype=torch.float64), tensor(-1.9310, dtype=torch.float64), tensor(-1.7206, dtype=torch.float64), tensor(-1.6924, dtype=torch.float64), tensor(-1.7677, dtype=torch.float64), tensor(-1.7711, dtype=torch.float64), tensor(-1.7049, dtype=torch.float64), tensor(-1.8021, dtype=torch.float64), tensor(-1.8073, dtype=torch.float64), tensor(-1.9139, dtype=torch.float64), tensor(-1.7408, dtype=torch.float64), tensor(-1.8189, dtype=torch.float64), tensor(-1.8298, dtype=torch.float64), tensor(-1.6957, dtype=torch.float64), tensor(-1.7722, dtype=torch.float64), tensor(-1.6920, dtype=torch.float64), tensor(-1.7520, dtype=torch.float64), tensor(-1.7875, dtype=torch.float64), tensor(-1.7385, dtype=torch.float64), tensor(-1.8244, dtype=torch.float64), tensor(-1.7808, dtype=torch.float64), tensor(-1.8413, dtype=torch.float64), tensor(-1.7979, dtype=torch.float64), tensor(-1.7655, dtype=torch.float64), tensor(-1.9507, dtype=torch.float64), tensor(-1.8210, dtype=torch.float64), tensor(-1.7570, dtype=torch.float64), tensor(-1.8066, dtype=torch.float64), tensor(-1.7410, dtype=torch.float64), tensor(-1.7108, dtype=torch.float64), tensor(-1.7450, dtype=torch.float64), tensor(-1.9320, dtype=torch.float64), tensor(-1.7598, dtype=torch.float64), tensor(-1.8198, dtype=torch.float64), tensor(-1.7593, dtype=torch.float64), tensor(-1.7187, dtype=torch.float64), tensor(-1.7614, dtype=torch.float64), tensor(-1.7629, dtype=torch.float64), tensor(-1.7922, dtype=torch.float64), tensor(-1.7578, dtype=torch.float64), tensor(-1.7056, dtype=torch.float64), tensor(-1.7790, dtype=torch.float64), tensor(-1.7006, dtype=torch.float64), tensor(-1.7857, dtype=torch.float64), tensor(-1.7636, dtype=torch.float64), tensor(-1.7893, dtype=torch.float64), tensor(-1.8266, dtype=torch.float64), tensor(-1.7236, dtype=torch.float64), tensor(-1.7047, dtype=torch.float64), tensor(-1.9163, dtype=torch.float64), tensor(-1.7470, dtype=torch.float64), tensor(-1.9351, dtype=torch.float64), tensor(-1.8036, dtype=torch.float64), tensor(-1.8056, dtype=torch.float64), tensor(-1.8161, dtype=torch.float64), tensor(-1.9219, dtype=torch.float64), tensor(-1.9388, dtype=torch.float64), tensor(-1.6284, dtype=torch.float64), tensor(-1.7785, dtype=torch.float64), tensor(-1.8184, dtype=torch.float64), tensor(-1.7788, dtype=torch.float64), tensor(-1.9555, dtype=torch.float64), tensor(-1.8227, dtype=torch.float64), tensor(-1.9391, dtype=torch.float64), tensor(-1.7865, dtype=torch.float64), tensor(-1.7997, dtype=torch.float64), tensor(-1.8195, dtype=torch.float64), tensor(-1.9183, dtype=torch.float64), tensor(-1.7722, dtype=torch.float64), tensor(-1.7885, dtype=torch.float64), tensor(-1.7865, dtype=torch.float64), tensor(-1.7961, dtype=torch.float64), tensor(-1.7931, dtype=torch.float64), tensor(-1.7565, dtype=torch.float64), tensor(-1.7308, dtype=torch.float64), tensor(-1.6950, dtype=torch.float64), tensor(-1.7073, dtype=torch.float64), tensor(-1.9335, dtype=torch.float64), tensor(-1.8126, dtype=torch.float64), tensor(-1.7852, dtype=torch.float64), tensor(-1.8121, dtype=torch.float64), tensor(-1.8231, dtype=torch.float64), tensor(-1.7536, dtype=torch.float64), tensor(-1.6865, dtype=torch.float64), tensor(-1.7239, dtype=torch.float64), tensor(-1.7528, dtype=torch.float64), tensor(-1.8050, dtype=torch.float64), tensor(-1.9197, dtype=torch.float64), tensor(-1.7936, dtype=torch.float64), tensor(-1.9533, dtype=torch.float64), tensor(-1.7836, dtype=torch.float64), tensor(-1.7128, dtype=torch.float64), tensor(-1.7727, dtype=torch.float64), tensor(-1.7193, dtype=torch.float64), tensor(-1.7024, dtype=torch.float64), tensor(-1.8297, dtype=torch.float64), tensor(-1.9476, dtype=torch.float64), tensor(-1.6939, dtype=torch.float64), tensor(-1.9232, dtype=torch.float64), tensor(-1.6938, dtype=torch.float64), tensor(-1.6997, dtype=torch.float64), tensor(-1.9607, dtype=torch.float64), tensor(-1.7508, dtype=torch.float64), tensor(-1.7255, dtype=torch.float64), tensor(-1.8019, dtype=torch.float64), tensor(-1.7697, dtype=torch.float64), tensor(-1.6770, dtype=torch.float64), tensor(-1.7523, dtype=torch.float64), tensor(-1.7917, dtype=torch.float64), tensor(-1.8261, dtype=torch.float64), tensor(-1.7674, dtype=torch.float64), tensor(-1.7210, dtype=torch.float64), tensor(-1.7988, dtype=torch.float64), tensor(-1.7571, dtype=torch.float64), tensor(-1.6960, dtype=torch.float64), tensor(-1.6858, dtype=torch.float64), tensor(-1.9355, dtype=torch.float64), tensor(-1.7277, dtype=torch.float64), tensor(-1.6940, dtype=torch.float64), tensor(-1.7094, dtype=torch.float64), tensor(-1.7741, dtype=torch.float64), tensor(-1.9361, dtype=torch.float64), tensor(-1.7779, dtype=torch.float64), tensor(-1.7490, dtype=torch.float64), tensor(-1.9143, dtype=torch.float64), tensor(-1.7973, dtype=torch.float64), tensor(-1.8240, dtype=torch.float64), tensor(-1.7381, dtype=torch.float64), tensor(-1.6944, dtype=torch.float64), tensor(-1.7683, dtype=torch.float64), tensor(-1.7716, dtype=torch.float64), tensor(-1.7791, dtype=torch.float64), tensor(-1.7988, dtype=torch.float64), tensor(-1.8120, dtype=torch.float64), tensor(-1.7416, dtype=torch.float64), tensor(-1.7259, dtype=torch.float64), tensor(-1.7216, dtype=torch.float64), tensor(-1.7297, dtype=torch.float64), tensor(-1.7726, dtype=torch.float64), tensor(-1.7909, dtype=torch.float64), tensor(-1.7624, dtype=torch.float64), tensor(-1.7869, dtype=torch.float64), tensor(-1.7963, dtype=torch.float64), tensor(-1.7537, dtype=torch.float64), tensor(-1.6906, dtype=torch.float64), tensor(-1.8014, dtype=torch.float64), tensor(-1.7653, dtype=torch.float64), tensor(-1.8328, dtype=torch.float64), tensor(-1.7434, dtype=torch.float64), tensor(-1.7026, dtype=torch.float64), tensor(-1.7230, dtype=torch.float64), tensor(-1.8445, dtype=torch.float64), tensor(-1.7832, dtype=torch.float64), tensor(-1.7368, dtype=torch.float64), tensor(-1.9340, dtype=torch.float64), tensor(-1.7575, dtype=torch.float64), tensor(-1.9272, dtype=torch.float64), tensor(-1.7878, dtype=torch.float64), tensor(-1.9807, dtype=torch.float64), tensor(-1.7658, dtype=torch.float64), tensor(-1.7323, dtype=torch.float64), tensor(-1.7783, dtype=torch.float64), tensor(-1.7241, dtype=torch.float64), tensor(-1.7724, dtype=torch.float64), tensor(-1.8240, dtype=torch.float64), tensor(-1.7496, dtype=torch.float64), tensor(-1.7692, dtype=torch.float64), tensor(-1.7531, dtype=torch.float64), tensor(-1.7960, dtype=torch.float64), tensor(-1.8015, dtype=torch.float64), tensor(-1.7663, dtype=torch.float64), tensor(-1.7724, dtype=torch.float64), tensor(-1.7987, dtype=torch.float64), tensor(-1.8174, dtype=torch.float64), tensor(-1.8177, dtype=torch.float64), tensor(-1.7046, dtype=torch.float64), tensor(-1.7998, dtype=torch.float64), tensor(-1.7900, dtype=torch.float64), tensor(-1.7739, dtype=torch.float64), tensor(-1.9180, dtype=torch.float64), tensor(-1.7394, dtype=torch.float64), tensor(-1.7030, dtype=torch.float64), tensor(-1.8116, dtype=torch.float64), tensor(-1.9571, dtype=torch.float64), tensor(-1.9269, dtype=torch.float64), tensor(-1.8036, dtype=torch.float64), tensor(-1.7578, dtype=torch.float64), tensor(-1.7986, dtype=torch.float64), tensor(-1.7683, dtype=torch.float64), tensor(-1.6868, dtype=torch.float64), tensor(-1.7190, dtype=torch.float64), tensor(-1.7814, dtype=torch.float64), tensor(-1.8193, dtype=torch.float64), tensor(-1.9249, dtype=torch.float64), tensor(-1.8096, dtype=torch.float64), tensor(-1.7062, dtype=torch.float64), tensor(-1.8066, dtype=torch.float64), tensor(-1.7176, dtype=torch.float64), tensor(-1.7074, dtype=torch.float64), tensor(-1.9482, dtype=torch.float64), tensor(-1.7416, dtype=torch.float64), tensor(-1.7718, dtype=torch.float64), tensor(-1.7275, dtype=torch.float64), tensor(-1.8731, dtype=torch.float64), tensor(-1.7740, dtype=torch.float64), tensor(-1.7379, dtype=torch.float64), tensor(-1.7114, dtype=torch.float64), tensor(-1.7665, dtype=torch.float64), tensor(-1.9672, dtype=torch.float64), tensor(-1.8327, dtype=torch.float64), tensor(-1.7815, dtype=torch.float64), tensor(-1.7809, dtype=torch.float64), tensor(-1.7904, dtype=torch.float64), tensor(-1.8207, dtype=torch.float64), tensor(-1.9800, dtype=torch.float64), tensor(-1.7934, dtype=torch.float64), tensor(-1.9137, dtype=torch.float64), tensor(-1.6819, dtype=torch.float64), tensor(-1.7939, dtype=torch.float64), tensor(-1.7931, dtype=torch.float64), tensor(-1.7105, dtype=torch.float64), tensor(-1.7889, dtype=torch.float64), tensor(-1.7723, dtype=torch.float64), tensor(-1.7123, dtype=torch.float64), tensor(-1.9417, dtype=torch.float64), tensor(-1.7794, dtype=torch.float64), tensor(-1.7684, dtype=torch.float64), tensor(-1.7567, dtype=torch.float64), tensor(-1.8107, dtype=torch.float64), tensor(-1.6965, dtype=torch.float64), tensor(-1.8026, dtype=torch.float64), tensor(-1.7945, dtype=torch.float64), tensor(-1.7207, dtype=torch.float64), tensor(-1.7706, dtype=torch.float64), tensor(-1.8020, dtype=torch.float64), tensor(-1.6975, dtype=torch.float64), tensor(-1.9458, dtype=torch.float64), tensor(-1.9443, dtype=torch.float64), tensor(-1.7415, dtype=torch.float64), tensor(-1.7665, dtype=torch.float64), tensor(-1.8100, dtype=torch.float64), tensor(-1.7459, dtype=torch.float64), tensor(-1.7014, dtype=torch.float64), tensor(-1.9399, dtype=torch.float64), tensor(-1.7700, dtype=torch.float64), tensor(-1.9573, dtype=torch.float64), tensor(-1.7055, dtype=torch.float64), tensor(-1.7749, dtype=torch.float64), tensor(-1.7713, dtype=torch.float64), tensor(-1.7795, dtype=torch.float64), tensor(-1.8242, dtype=torch.float64), tensor(-1.9346, dtype=torch.float64), tensor(-1.7514, dtype=torch.float64), tensor(-1.7747, dtype=torch.float64), tensor(-1.7842, dtype=torch.float64), tensor(-1.7504, dtype=torch.float64), tensor(-1.7737, dtype=torch.float64), tensor(-1.7641, dtype=torch.float64), tensor(-1.7883, dtype=torch.float64), tensor(-1.7835, dtype=torch.float64), tensor(-1.7012, dtype=torch.float64), tensor(-1.8190, dtype=torch.float64), tensor(-1.9169, dtype=torch.float64), tensor(-1.8053, dtype=torch.float64), tensor(-1.7861, dtype=torch.float64), tensor(-1.9390, dtype=torch.float64), tensor(-1.7177, dtype=torch.float64), tensor(-1.7091, dtype=torch.float64), tensor(-1.7650, dtype=torch.float64), tensor(-1.7865, dtype=torch.float64), tensor(-1.8634, dtype=torch.float64), tensor(-1.7780, dtype=torch.float64), tensor(-1.7609, dtype=torch.float64), tensor(-1.9233, dtype=torch.float64), tensor(-1.8445, dtype=torch.float64), tensor(-1.7736, dtype=torch.float64), tensor(-1.7165, dtype=torch.float64), tensor(-1.7902, dtype=torch.float64), tensor(-1.6750, dtype=torch.float64), tensor(-1.7465, dtype=torch.float64), tensor(-1.7760, dtype=torch.float64), tensor(-1.8082, dtype=torch.float64), tensor(-1.7889, dtype=torch.float64), tensor(-1.7875, dtype=torch.float64), tensor(-1.9158, dtype=torch.float64), tensor(-1.9132, dtype=torch.float64), tensor(-1.9306, dtype=torch.float64), tensor(-1.7847, dtype=torch.float64), tensor(-1.9294, dtype=torch.float64), tensor(-1.7835, dtype=torch.float64), tensor(-1.8083, dtype=torch.float64), tensor(-1.8314, dtype=torch.float64), tensor(-1.8024, dtype=torch.float64), tensor(-1.9607, dtype=torch.float64), tensor(-1.7672, dtype=torch.float64), tensor(-1.7961, dtype=torch.float64), tensor(-1.9377, dtype=torch.float64), tensor(-1.7862, dtype=torch.float64), tensor(-1.7114, dtype=torch.float64), tensor(-1.7003, dtype=torch.float64), tensor(-1.7605, dtype=torch.float64), tensor(-1.9512, dtype=torch.float64), tensor(-1.7808, dtype=torch.float64), tensor(-1.9406, dtype=torch.float64), tensor(-1.7729, dtype=torch.float64), tensor(-1.6969, dtype=torch.float64), tensor(-1.8093, dtype=torch.float64), tensor(-1.6923, dtype=torch.float64), tensor(-1.7437, dtype=torch.float64), tensor(-1.8000, dtype=torch.float64), tensor(-1.7985, dtype=torch.float64), tensor(-1.9363, dtype=torch.float64), tensor(-1.7694, dtype=torch.float64), tensor(-1.7714, dtype=torch.float64), tensor(-1.8116, dtype=torch.float64), tensor(-1.7066, dtype=torch.float64), tensor(-1.8100, dtype=torch.float64), tensor(-1.6867, dtype=torch.float64), tensor(-1.7711, dtype=torch.float64), tensor(-1.7563, dtype=torch.float64), tensor(-1.7919, dtype=torch.float64), tensor(-1.9283, dtype=torch.float64), tensor(-1.7138, dtype=torch.float64), tensor(-1.7178, dtype=torch.float64), tensor(-1.7789, dtype=torch.float64), tensor(-1.7170, dtype=torch.float64), tensor(-1.8060, dtype=torch.float64), tensor(-1.7678, dtype=torch.float64), tensor(-1.9658, dtype=torch.float64), tensor(-1.7367, dtype=torch.float64), tensor(-1.7251, dtype=torch.float64), tensor(-1.8180, dtype=torch.float64), tensor(-1.6135, dtype=torch.float64), tensor(-1.7681, dtype=torch.float64), tensor(-1.7695, dtype=torch.float64), tensor(-1.7908, dtype=torch.float64), tensor(-1.6874, dtype=torch.float64), tensor(-1.8024, dtype=torch.float64), tensor(-1.8064, dtype=torch.float64), tensor(-1.7515, dtype=torch.float64), tensor(-1.7938, dtype=torch.float64), tensor(-1.7549, dtype=torch.float64), tensor(-1.7661, dtype=torch.float64), tensor(-1.7904, dtype=torch.float64), tensor(-1.7962, dtype=torch.float64), tensor(-1.7637, dtype=torch.float64), tensor(-1.7248, dtype=torch.float64)]\n",
      "%% [0.0, -1.0, 0.0, -1.0, -1.0, 0.0, 0.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.0, -1.0, -1.0, 0.0, 0.0, -1.0, -1.0, 0.0, -1.0, -1.0, 0.0, 0.0, -1.0, 0.0, -1.0, 0.0, 10.0, 0.0, -1.0, 0.0, -1.0, -1.0, -1.0, 0.0, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, -1.0, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, -1.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, -1.0, 0.0, 0.0, -1.0, 0.0, -1.0, -1.0, 0.0, -1.0, -1.0, 0.0, 0.0, 10.0, 0.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, -1.0, -1.0, -1.0, 10.0, 0.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, -1.0, 0.0, 10.0, 0.0, 0.0, -1.0, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, -1.0, 0.0, -1.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 10.0, -1.0, 0.0, -1.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 10.0, 0.0, 0.0, -1.0, 0.0, -1.0, -1.0, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -1.0, -1.0, 0.0, 0.0, -1.0, -1.0, 0.0, -1.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, -1.0, -1.0, -1.0, 0.0, 0.0, 10.0, 0.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, -1.0, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, -1.0, -1.0, -1.0, 0.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, -1.0, 0.0, -1.0, 0.0, 0.0, -1.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.0, 0.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, -1.0, 0.0, -1.0, 0.0, 0.0, -1.0, -1.0, -1.0, 0.0, 0.0, -1.0, 0.0, -1.0, 0.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, 0.0, 0.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -1.0, 0.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, -1.0, 0.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, -1.0, 0.0, -1.0, -1.0, -1.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, -1.0, -1.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, -1.0, -1.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, -1.0, 0.0, -1.0, 0.0, 0.0, 10.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, -1.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -1.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, -1.0, -1.0, 0.0, -1.0, -1.0, 0.0, 0.0, -1.0, -1.0, 0.0, -1.0, -1.0, 0.0, 0.0, -1.0, 0.0, -1.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, -1.0, -1.0, 0.0, -1.0, -1.0, -1.0, 0.0, 0.0, -1.0, -1.0, -1.0, 0.0, -1.0, -1.0, 0.0, 0.0, 10.0, -1.0, 0.0, 0.0, 0.0, -1.0, -1.0, 0.0, -1.0, -1.0, -1.0, 0.0, -1.0, -1.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, -1.0, 0.0, -1.0, -1.0, 0.0, 0.0, -1.0, -1.0, 0.0, -1.0, 0.0, 0.0, -15.0, 0.0, -1.0, 0.0, -1.0, -1.0, -1.0, 0.0, -1.0, -1.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, -1.0, -1.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, -1.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -15.0, 0.0, -1.0, 0.0, -1.0, 0.0, -1.0, -1.0, 0.0, 0.0, -1.0, 0.0, -1.0, 0.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.0, -1.0, -1.0, -1.0, 0.0, 0.0, 0.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, -1.0, 0.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, 0.0, -1.0, -1.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -1.0, -1.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, -1.0, 0.0, 0.0, -1.0, -1.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -16.0, 0.0, 0.0, -1.0, 0.0, -1.0, -1.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -1.0, -15.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, -1.0, 0.0, -1.0, -1.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 10.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, -1.0, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, -1.0, -1.0, -1.0, -1.0, 10.0, 0.0, -1.0, 0.0, -1.0, 0.0, -1.0, -1.0, -1.0, -1.0, 0.0, 10.0, -1.0, 0.0, -1.0, -1.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 0.0, -1.0, -1.0, 0.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.0, 0.0, -1.0, 10.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 10.0, -1.0, 0.0, -1.0, -1.0, 0.0, 0.0, 10.0, 0.0, 0.0, -1.0, -1.0, 0.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, -1.0, -1.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 15.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, -1.0, -1.0, -1.0, 0.0, 0.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.0, -1.0, -1.0, 0.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, -1.0, 0.0, -1.0, -16.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nick\\AppData\\Local\\Temp\\ipykernel_26616\\2061264130.py:109: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  returns = torch.tensor(discount_rewards(model.rewards))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([0.9981], dtype=torch.float64), tensor([0.9369], dtype=torch.float64), tensor([1.0547], dtype=torch.float64), tensor([0.9822], dtype=torch.float64), tensor([1.0936], dtype=torch.float64), tensor([1.1714], dtype=torch.float64), tensor([1.2561], dtype=torch.float64), tensor([1.0891], dtype=torch.float64), tensor([1.1864], dtype=torch.float64), tensor([1.2162], dtype=torch.float64), tensor([1.3406], dtype=torch.float64), tensor([1.5362], dtype=torch.float64), tensor([1.5097], dtype=torch.float64), tensor([1.3520], dtype=torch.float64), tensor([1.4058], dtype=torch.float64), tensor([1.6536], dtype=torch.float64), tensor([1.4967], dtype=torch.float64), tensor([1.7033], dtype=torch.float64), tensor([1.5119], dtype=torch.float64), tensor([1.7658], dtype=torch.float64), tensor([1.5348], dtype=torch.float64), tensor([1.6780], dtype=torch.float64), tensor([1.7495], dtype=torch.float64), tensor([1.7326], dtype=torch.float64), tensor([1.7330], dtype=torch.float64), tensor([1.7061], dtype=torch.float64), tensor([2.0792], dtype=torch.float64), tensor([1.8124], dtype=torch.float64), tensor([1.8757], dtype=torch.float64), tensor([2.1980], dtype=torch.float64), tensor([2.0390], dtype=torch.float64), tensor([1.9570], dtype=torch.float64), tensor([2.2477], dtype=torch.float64), tensor([1.9786], dtype=torch.float64), tensor([2.2942], dtype=torch.float64), tensor([2.1302], dtype=torch.float64), tensor([1.0147], dtype=torch.float64), tensor([0.9673], dtype=torch.float64), tensor([1.0353], dtype=torch.float64), tensor([1.0017], dtype=torch.float64), tensor([1.0307], dtype=torch.float64), tensor([1.1807], dtype=torch.float64), tensor([1.2645], dtype=torch.float64), tensor([1.2253], dtype=torch.float64), tensor([1.3032], dtype=torch.float64), tensor([1.1374], dtype=torch.float64), tensor([1.2232], dtype=torch.float64), tensor([1.3271], dtype=torch.float64), tensor([1.3730], dtype=torch.float64), tensor([1.2017], dtype=torch.float64), tensor([1.3505], dtype=torch.float64), tensor([1.2790], dtype=torch.float64), tensor([1.3778], dtype=torch.float64), tensor([1.3763], dtype=torch.float64), tensor([1.3280], dtype=torch.float64), tensor([1.3022], dtype=torch.float64), tensor([1.3730], dtype=torch.float64), tensor([1.4228], dtype=torch.float64), tensor([1.3415], dtype=torch.float64), tensor([1.4956], dtype=torch.float64), tensor([1.5058], dtype=torch.float64), tensor([1.6645], dtype=torch.float64), tensor([1.7404], dtype=torch.float64), tensor([1.7973], dtype=torch.float64), tensor([1.9074], dtype=torch.float64), tensor([1.8619], dtype=torch.float64), tensor([1.8774], dtype=torch.float64), tensor([1.8032], dtype=torch.float64), tensor([1.7780], dtype=torch.float64), tensor([1.7446], dtype=torch.float64), tensor([1.9044], dtype=torch.float64), tensor([1.8281], dtype=torch.float64), tensor([1.8022], dtype=torch.float64), tensor([1.8574], dtype=torch.float64), tensor([1.9916], dtype=torch.float64), tensor([2.0053], dtype=torch.float64), tensor([2.1279], dtype=torch.float64), tensor([2.1177], dtype=torch.float64), tensor([2.1757], dtype=torch.float64), tensor([2.4826], dtype=torch.float64), tensor([2.2736], dtype=torch.float64), tensor([2.1859], dtype=torch.float64), tensor([2.3857], dtype=torch.float64), tensor([2.2820], dtype=torch.float64), tensor([2.3446], dtype=torch.float64), tensor([2.5714], dtype=torch.float64), tensor([2.4276], dtype=torch.float64), tensor([2.4608], dtype=torch.float64), tensor([2.8693], dtype=torch.float64), tensor([2.6527], dtype=torch.float64), tensor([2.6795], dtype=torch.float64), tensor([1.5541], dtype=torch.float64), tensor([1.4837], dtype=torch.float64), tensor([1.5757], dtype=torch.float64), tensor([1.6669], dtype=torch.float64), tensor([1.7897], dtype=torch.float64), tensor([1.6617], dtype=torch.float64), tensor([1.8340], dtype=torch.float64), tensor([1.7046], dtype=torch.float64), tensor([1.8308], dtype=torch.float64), tensor([1.9289], dtype=torch.float64), tensor([2.0512], dtype=torch.float64), tensor([2.1122], dtype=torch.float64), tensor([2.1527], dtype=torch.float64), tensor([2.2708], dtype=torch.float64), tensor([2.4643], dtype=torch.float64), tensor([2.4137], dtype=torch.float64), tensor([2.2553], dtype=torch.float64), tensor([2.4404], dtype=torch.float64), tensor([2.5964], dtype=torch.float64), tensor([2.3385], dtype=torch.float64), tensor([2.5010], dtype=torch.float64), tensor([2.4778], dtype=torch.float64), tensor([2.6681], dtype=torch.float64), tensor([2.7446], dtype=torch.float64), tensor([1.6706], dtype=torch.float64), tensor([1.6712], dtype=torch.float64), tensor([1.6556], dtype=torch.float64), tensor([1.9723], dtype=torch.float64), tensor([1.7269], dtype=torch.float64), tensor([1.9025], dtype=torch.float64), tensor([1.8570], dtype=torch.float64), tensor([1.9189], dtype=torch.float64), tensor([2.0032], dtype=torch.float64), tensor([1.9894], dtype=torch.float64), tensor([0.9829], dtype=torch.float64), tensor([0.8661], dtype=torch.float64), tensor([0.7934], dtype=torch.float64), tensor([0.9910], dtype=torch.float64), tensor([0.8341], dtype=torch.float64), tensor([0.9469], dtype=torch.float64), tensor([0.9972], dtype=torch.float64), tensor([0.9708], dtype=torch.float64), tensor([0.8199], dtype=torch.float64), tensor([0.8907], dtype=torch.float64), tensor([1.0036], dtype=torch.float64), tensor([0.9383], dtype=torch.float64), tensor([0.9971], dtype=torch.float64), tensor([1.1293], dtype=torch.float64), tensor([1.0860], dtype=torch.float64), tensor([1.0287], dtype=torch.float64), tensor([1.2247], dtype=torch.float64), tensor([1.0932], dtype=torch.float64), tensor([1.0111], dtype=torch.float64), tensor([-0.0337], dtype=torch.float64), tensor([0.0294], dtype=torch.float64), tensor([-0.0132], dtype=torch.float64), tensor([0.0552], dtype=torch.float64), tensor([0.0083], dtype=torch.float64), tensor([0.0692], dtype=torch.float64), tensor([0.1353], dtype=torch.float64), tensor([0.1955], dtype=torch.float64), tensor([0.2676], dtype=torch.float64), tensor([0.3296], dtype=torch.float64), tensor([0.4401], dtype=torch.float64), tensor([0.3658], dtype=torch.float64), tensor([0.3358], dtype=torch.float64), tensor([0.4014], dtype=torch.float64), tensor([0.3621], dtype=torch.float64), tensor([0.3130], dtype=torch.float64), tensor([0.3694], dtype=torch.float64), tensor([0.4602], dtype=torch.float64), tensor([0.4495], dtype=torch.float64), tensor([0.3565], dtype=torch.float64), tensor([-0.7425], dtype=torch.float64), tensor([-0.8055], dtype=torch.float64), tensor([-0.8032], dtype=torch.float64), tensor([-0.8352], dtype=torch.float64), tensor([-0.8185], dtype=torch.float64), tensor([-0.7557], dtype=torch.float64), tensor([-0.7095], dtype=torch.float64), tensor([-0.7690], dtype=torch.float64), tensor([-0.6928], dtype=torch.float64), tensor([-0.8142], dtype=torch.float64), tensor([-0.8752], dtype=torch.float64), tensor([-0.8425], dtype=torch.float64), tensor([-0.7934], dtype=torch.float64), tensor([-0.8577], dtype=torch.float64), tensor([-0.8036], dtype=torch.float64), tensor([-0.8189], dtype=torch.float64), tensor([-0.7890], dtype=torch.float64), tensor([-0.8234], dtype=torch.float64), tensor([-0.8561], dtype=torch.float64), tensor([-0.8169], dtype=torch.float64), tensor([-0.7951], dtype=torch.float64), tensor([-0.8338], dtype=torch.float64), tensor([-0.8570], dtype=torch.float64), tensor([-0.8252], dtype=torch.float64), tensor([-0.7728], dtype=torch.float64), tensor([-0.8337], dtype=torch.float64), tensor([-0.8879], dtype=torch.float64), tensor([-0.8756], dtype=torch.float64), tensor([-0.8497], dtype=torch.float64), tensor([-0.7895], dtype=torch.float64), tensor([-0.7629], dtype=torch.float64), tensor([-0.7817], dtype=torch.float64), tensor([-0.7470], dtype=torch.float64), tensor([-0.6925], dtype=torch.float64), tensor([-0.7619], dtype=torch.float64), tensor([-0.8114], dtype=torch.float64), tensor([-0.8381], dtype=torch.float64), tensor([-0.7789], dtype=torch.float64), tensor([-0.7190], dtype=torch.float64), tensor([-0.6747], dtype=torch.float64), tensor([-0.6120], dtype=torch.float64), tensor([-0.5434], dtype=torch.float64), tensor([-0.5064], dtype=torch.float64), tensor([-0.4397], dtype=torch.float64), tensor([-0.4182], dtype=torch.float64), tensor([-0.4635], dtype=torch.float64), tensor([-0.4797], dtype=torch.float64), tensor([-0.4478], dtype=torch.float64), tensor([-0.4664], dtype=torch.float64), tensor([-0.5053], dtype=torch.float64), tensor([-0.5701], dtype=torch.float64), tensor([-0.5855], dtype=torch.float64), tensor([-0.5596], dtype=torch.float64), tensor([-0.5629], dtype=torch.float64), tensor([-0.5303], dtype=torch.float64), tensor([-0.4774], dtype=torch.float64), tensor([-0.5238], dtype=torch.float64), tensor([-0.5603], dtype=torch.float64), tensor([-0.5154], dtype=torch.float64), tensor([-0.4693], dtype=torch.float64), tensor([-0.4788], dtype=torch.float64), tensor([-0.4330], dtype=torch.float64), tensor([-0.4197], dtype=torch.float64), tensor([-0.4430], dtype=torch.float64), tensor([-0.4710], dtype=torch.float64), tensor([-0.4594], dtype=torch.float64), tensor([-0.4646], dtype=torch.float64), tensor([-0.5255], dtype=torch.float64), tensor([-0.5472], dtype=torch.float64), tensor([-0.5122], dtype=torch.float64), tensor([-0.5459], dtype=torch.float64), tensor([-0.5799], dtype=torch.float64), tensor([-0.5292], dtype=torch.float64), tensor([-0.4788], dtype=torch.float64), tensor([-0.4233], dtype=torch.float64), tensor([-0.3487], dtype=torch.float64), tensor([-0.3120], dtype=torch.float64), tensor([-0.3367], dtype=torch.float64), tensor([-0.2886], dtype=torch.float64), tensor([-0.2225], dtype=torch.float64), tensor([-0.1649], dtype=torch.float64), tensor([-0.1109], dtype=torch.float64), tensor([-0.1483], dtype=torch.float64), tensor([-0.1876], dtype=torch.float64), tensor([-0.1212], dtype=torch.float64), tensor([-0.0619], dtype=torch.float64), tensor([-0.0015], dtype=torch.float64), tensor([-0.0450], dtype=torch.float64), tensor([-0.0870], dtype=torch.float64), tensor([-1.3113], dtype=torch.float64), tensor([-1.2318], dtype=torch.float64), tensor([-1.1994], dtype=torch.float64), tensor([-1.2361], dtype=torch.float64), tensor([-1.1819], dtype=torch.float64), tensor([-1.2577], dtype=torch.float64), tensor([-1.2021], dtype=torch.float64), tensor([-1.1775], dtype=torch.float64), tensor([-1.2275], dtype=torch.float64), tensor([-1.2505], dtype=torch.float64), tensor([-1.2893], dtype=torch.float64), tensor([-1.2438], dtype=torch.float64), tensor([-1.2017], dtype=torch.float64), tensor([-1.1354], dtype=torch.float64), tensor([-1.1080], dtype=torch.float64), tensor([-1.0196], dtype=torch.float64), tensor([-1.0993], dtype=torch.float64), tensor([-1.1387], dtype=torch.float64), tensor([-1.1079], dtype=torch.float64), tensor([-1.0898], dtype=torch.float64), tensor([-1.0621], dtype=torch.float64), tensor([-1.0733], dtype=torch.float64), tensor([-1.1918], dtype=torch.float64), tensor([-1.1844], dtype=torch.float64), tensor([-1.2104], dtype=torch.float64), tensor([-1.1615], dtype=torch.float64), tensor([-1.1805], dtype=torch.float64), tensor([-1.1258], dtype=torch.float64), tensor([-1.0944], dtype=torch.float64), tensor([-1.1576], dtype=torch.float64), tensor([-1.0743], dtype=torch.float64), tensor([-1.0637], dtype=torch.float64), tensor([-1.0982], dtype=torch.float64), tensor([-1.0346], dtype=torch.float64), tensor([-1.0256], dtype=torch.float64), tensor([-1.0111], dtype=torch.float64), tensor([-0.9858], dtype=torch.float64), tensor([-1.0326], dtype=torch.float64), tensor([-1.0027], dtype=torch.float64), tensor([-1.0407], dtype=torch.float64), tensor([-1.0211], dtype=torch.float64), tensor([-1.0576], dtype=torch.float64), tensor([-0.9679], dtype=torch.float64), tensor([-0.9341], dtype=torch.float64), tensor([-0.9082], dtype=torch.float64), tensor([-0.9708], dtype=torch.float64), tensor([-0.9931], dtype=torch.float64), tensor([-1.0732], dtype=torch.float64), tensor([-1.0458], dtype=torch.float64), tensor([-1.1465], dtype=torch.float64), tensor([-1.0996], dtype=torch.float64), tensor([-1.0709], dtype=torch.float64), tensor([-1.1086], dtype=torch.float64), tensor([-1.2533], dtype=torch.float64), tensor([-1.2300], dtype=torch.float64), tensor([-1.2430], dtype=torch.float64), tensor([-1.1584], dtype=torch.float64), tensor([-1.1806], dtype=torch.float64), tensor([-1.2147], dtype=torch.float64), tensor([-1.2715], dtype=torch.float64), tensor([-1.1823], dtype=torch.float64), tensor([-1.1218], dtype=torch.float64), tensor([-1.1195], dtype=torch.float64), tensor([-1.0608], dtype=torch.float64), tensor([-1.0989], dtype=torch.float64), tensor([-1.0811], dtype=torch.float64), tensor([-0.9777], dtype=torch.float64), tensor([-0.9633], dtype=torch.float64), tensor([-0.8840], dtype=torch.float64), tensor([-0.8039], dtype=torch.float64), tensor([-0.7745], dtype=torch.float64), tensor([-0.7102], dtype=torch.float64), tensor([-0.6774], dtype=torch.float64), tensor([-0.6245], dtype=torch.float64), tensor([-0.5638], dtype=torch.float64), tensor([-0.6137], dtype=torch.float64), tensor([-0.7151], dtype=torch.float64), tensor([-0.7194], dtype=torch.float64), tensor([-0.7261], dtype=torch.float64), tensor([-0.7655], dtype=torch.float64), tensor([-0.7541], dtype=torch.float64), tensor([-0.8059], dtype=torch.float64), tensor([-0.8541], dtype=torch.float64), tensor([-0.9073], dtype=torch.float64), tensor([-0.9542], dtype=torch.float64), tensor([-0.9412], dtype=torch.float64), tensor([-0.9699], dtype=torch.float64), tensor([-1.0070], dtype=torch.float64), tensor([-1.0418], dtype=torch.float64), tensor([-1.0088], dtype=torch.float64), tensor([-0.9457], dtype=torch.float64), tensor([-0.8603], dtype=torch.float64), tensor([-0.8400], dtype=torch.float64), tensor([-0.8577], dtype=torch.float64), tensor([-0.8528], dtype=torch.float64), tensor([-0.8879], dtype=torch.float64), tensor([-0.8101], dtype=torch.float64), tensor([-0.7690], dtype=torch.float64), tensor([-0.7255], dtype=torch.float64), tensor([-0.7638], dtype=torch.float64), tensor([-0.7817], dtype=torch.float64), tensor([-0.7695], dtype=torch.float64), tensor([-0.8084], dtype=torch.float64), tensor([-0.7649], dtype=torch.float64), tensor([-0.7786], dtype=torch.float64), tensor([-0.7173], dtype=torch.float64), tensor([-0.7082], dtype=torch.float64), tensor([-0.7584], dtype=torch.float64), tensor([-0.8218], dtype=torch.float64), tensor([-0.8557], dtype=torch.float64), tensor([-0.9049], dtype=torch.float64), tensor([-0.9356], dtype=torch.float64), tensor([-0.9105], dtype=torch.float64), tensor([-0.9564], dtype=torch.float64), tensor([-0.9784], dtype=torch.float64), tensor([-0.9471], dtype=torch.float64), tensor([-0.9547], dtype=torch.float64), tensor([-0.9448], dtype=torch.float64), tensor([-0.9749], dtype=torch.float64), tensor([-0.9371], dtype=torch.float64), tensor([-1.0770], dtype=torch.float64), tensor([-1.0611], dtype=torch.float64), tensor([-1.0735], dtype=torch.float64), tensor([-1.0614], dtype=torch.float64), tensor([-1.0553], dtype=torch.float64), tensor([-1.0416], dtype=torch.float64), tensor([-1.1105], dtype=torch.float64), tensor([-1.1099], dtype=torch.float64), tensor([-1.1142], dtype=torch.float64), tensor([-1.1097], dtype=torch.float64), tensor([-1.0552], dtype=torch.float64), tensor([-1.1228], dtype=torch.float64), tensor([-1.0906], dtype=torch.float64), tensor([-1.0592], dtype=torch.float64), tensor([-1.0612], dtype=torch.float64), tensor([-1.0493], dtype=torch.float64), tensor([-1.1022], dtype=torch.float64), tensor([-1.1067], dtype=torch.float64), tensor([-1.0730], dtype=torch.float64), tensor([-1.0227], dtype=torch.float64), tensor([-0.9810], dtype=torch.float64), tensor([-1.0251], dtype=torch.float64), tensor([-0.9696], dtype=torch.float64), tensor([-0.9513], dtype=torch.float64), tensor([-1.0195], dtype=torch.float64), tensor([-1.0508], dtype=torch.float64), tensor([-1.0687], dtype=torch.float64), tensor([-1.0388], dtype=torch.float64), tensor([-1.0073], dtype=torch.float64), tensor([-1.0604], dtype=torch.float64), tensor([-1.0619], dtype=torch.float64), tensor([-1.0017], dtype=torch.float64), tensor([-0.9861], dtype=torch.float64), tensor([-0.8935], dtype=torch.float64), tensor([-0.8961], dtype=torch.float64), tensor([-0.9177], dtype=torch.float64), tensor([-0.8395], dtype=torch.float64), tensor([-0.8380], dtype=torch.float64), tensor([-0.8628], dtype=torch.float64), tensor([-0.8146], dtype=torch.float64), tensor([-0.8827], dtype=torch.float64), tensor([-0.8854], dtype=torch.float64), tensor([-0.8364], dtype=torch.float64), tensor([-0.7744], dtype=torch.float64), tensor([-0.7540], dtype=torch.float64), tensor([-0.8797], dtype=torch.float64), tensor([-0.8555], dtype=torch.float64), tensor([-0.7984], dtype=torch.float64), tensor([-0.8101], dtype=torch.float64), tensor([-0.8626], dtype=torch.float64), tensor([-0.9272], dtype=torch.float64), tensor([-0.9062], dtype=torch.float64), tensor([-0.8093], dtype=torch.float64), tensor([-0.7529], dtype=torch.float64), tensor([-0.7246], dtype=torch.float64), tensor([-0.6556], dtype=torch.float64), tensor([-0.6274], dtype=torch.float64), tensor([-0.6858], dtype=torch.float64), tensor([-0.7291], dtype=torch.float64), tensor([-0.8266], dtype=torch.float64), tensor([-0.8108], dtype=torch.float64), tensor([-0.7316], dtype=torch.float64), tensor([-0.7056], dtype=torch.float64), tensor([-0.6464], dtype=torch.float64), tensor([-0.7556], dtype=torch.float64), tensor([-0.7117], dtype=torch.float64), tensor([-0.6556], dtype=torch.float64), tensor([-0.6150], dtype=torch.float64), tensor([-0.5513], dtype=torch.float64), tensor([-0.5531], dtype=torch.float64), tensor([-0.6090], dtype=torch.float64), tensor([-0.6081], dtype=torch.float64), tensor([-0.6674], dtype=torch.float64), tensor([-0.6808], dtype=torch.float64), tensor([-0.6547], dtype=torch.float64), tensor([-0.6969], dtype=torch.float64), tensor([-0.6471], dtype=torch.float64), tensor([-0.6631], dtype=torch.float64), tensor([-0.6262], dtype=torch.float64), tensor([-0.5668], dtype=torch.float64), tensor([-0.4922], dtype=torch.float64), tensor([-0.4661], dtype=torch.float64), tensor([-0.5479], dtype=torch.float64), tensor([-0.5482], dtype=torch.float64), tensor([-0.5343], dtype=torch.float64), tensor([-0.5379], dtype=torch.float64), tensor([-0.4589], dtype=torch.float64), tensor([-0.4219], dtype=torch.float64), tensor([-0.3624], dtype=torch.float64), tensor([-0.3091], dtype=torch.float64), tensor([-0.3499], dtype=torch.float64), tensor([-0.3916], dtype=torch.float64), tensor([-0.3586], dtype=torch.float64), tensor([-0.3627], dtype=torch.float64), tensor([-0.3220], dtype=torch.float64), tensor([-0.2507], dtype=torch.float64), tensor([-0.2001], dtype=torch.float64), tensor([-0.2343], dtype=torch.float64), tensor([-0.1766], dtype=torch.float64), tensor([-0.1190], dtype=torch.float64), tensor([-0.1767], dtype=torch.float64), tensor([-0.2049], dtype=torch.float64), tensor([-0.2706], dtype=torch.float64), tensor([-0.2909], dtype=torch.float64), tensor([-0.2325], dtype=torch.float64), tensor([-0.2818], dtype=torch.float64), tensor([-0.3296], dtype=torch.float64), tensor([-0.4042], dtype=torch.float64), tensor([-0.4201], dtype=torch.float64), tensor([-0.3624], dtype=torch.float64), tensor([-0.4037], dtype=torch.float64), tensor([-0.3292], dtype=torch.float64), tensor([-0.2853], dtype=torch.float64), tensor([-0.3345], dtype=torch.float64), tensor([-0.4049], dtype=torch.float64), tensor([-0.4311], dtype=torch.float64), tensor([-0.4612], dtype=torch.float64), tensor([-0.4177], dtype=torch.float64), tensor([-0.4548], dtype=torch.float64), tensor([-0.5079], dtype=torch.float64), tensor([-0.5442], dtype=torch.float64), tensor([-0.4991], dtype=torch.float64), tensor([-0.5283], dtype=torch.float64), tensor([-0.5662], dtype=torch.float64), tensor([-0.5083], dtype=torch.float64), tensor([-0.4479], dtype=torch.float64), tensor([-0.4085], dtype=torch.float64), tensor([-0.3575], dtype=torch.float64), tensor([-0.3999], dtype=torch.float64), tensor([-0.3417], dtype=torch.float64), tensor([-0.3811], dtype=torch.float64), tensor([-0.3232], dtype=torch.float64), tensor([-0.3711], dtype=torch.float64), tensor([-0.4474], dtype=torch.float64), tensor([-0.4665], dtype=torch.float64), tensor([-0.4854], dtype=torch.float64), tensor([-0.4475], dtype=torch.float64), tensor([-0.3877], dtype=torch.float64), tensor([-0.3317], dtype=torch.float64), tensor([-0.3736], dtype=torch.float64), tensor([-0.4148], dtype=torch.float64), tensor([-0.4725], dtype=torch.float64), tensor([-0.4945], dtype=torch.float64), tensor([-0.4366], dtype=torch.float64), tensor([-0.4032], dtype=torch.float64), tensor([-0.4367], dtype=torch.float64), tensor([-0.3693], dtype=torch.float64), tensor([-0.3521], dtype=torch.float64), tensor([-0.3751], dtype=torch.float64), tensor([-0.4485], dtype=torch.float64), tensor([-0.4466], dtype=torch.float64), tensor([-0.4009], dtype=torch.float64), tensor([-0.3691], dtype=torch.float64), tensor([-0.3868], dtype=torch.float64), tensor([-0.3130], dtype=torch.float64), tensor([-0.2737], dtype=torch.float64), tensor([-0.3141], dtype=torch.float64), tensor([-0.3947], dtype=torch.float64), tensor([-0.4082], dtype=torch.float64), tensor([-0.4830], dtype=torch.float64), tensor([-0.5433], dtype=torch.float64), tensor([-0.5402], dtype=torch.float64), tensor([-0.4653], dtype=torch.float64), tensor([-0.4663], dtype=torch.float64), tensor([-0.4856], dtype=torch.float64), tensor([-0.5231], dtype=torch.float64), tensor([-0.4454], dtype=torch.float64), tensor([-0.4096], dtype=torch.float64), tensor([-0.4416], dtype=torch.float64), tensor([-0.4288], dtype=torch.float64), tensor([-0.4206], dtype=torch.float64), tensor([-0.3626], dtype=torch.float64), tensor([-0.3137], dtype=torch.float64), tensor([-0.2525], dtype=torch.float64), tensor([-0.3277], dtype=torch.float64), tensor([-0.3800], dtype=torch.float64), tensor([-0.3843], dtype=torch.float64), tensor([-0.3327], dtype=torch.float64), tensor([-0.2699], dtype=torch.float64), tensor([-0.2162], dtype=torch.float64), tensor([-0.2554], dtype=torch.float64), tensor([-0.1990], dtype=torch.float64), tensor([-0.2291], dtype=torch.float64), tensor([-0.1747], dtype=torch.float64), tensor([-0.1235], dtype=torch.float64), tensor([-0.1581], dtype=torch.float64), tensor([-0.0962], dtype=torch.float64), tensor([-0.1500], dtype=torch.float64), tensor([-0.1809], dtype=torch.float64), tensor([-1.3057], dtype=torch.float64), tensor([-1.3050], dtype=torch.float64), tensor([-1.4083], dtype=torch.float64), tensor([-1.3481], dtype=torch.float64), tensor([-1.3680], dtype=torch.float64), tensor([-1.3697], dtype=torch.float64), tensor([-1.4137], dtype=torch.float64), tensor([-1.3451], dtype=torch.float64), tensor([-1.3337], dtype=torch.float64), tensor([-1.5072], dtype=torch.float64), tensor([-1.3710], dtype=torch.float64), tensor([-1.3768], dtype=torch.float64), tensor([-1.5592], dtype=torch.float64), tensor([-1.5175], dtype=torch.float64), tensor([-1.5544], dtype=torch.float64), tensor([-1.6063], dtype=torch.float64), tensor([-1.6790], dtype=torch.float64), tensor([-1.8779], dtype=torch.float64), tensor([-1.7919], dtype=torch.float64), tensor([-1.8161], dtype=torch.float64), tensor([-1.7346], dtype=torch.float64), tensor([-1.6846], dtype=torch.float64), tensor([-1.8538], dtype=torch.float64), tensor([-1.7518], dtype=torch.float64), tensor([-1.6393], dtype=torch.float64), tensor([-1.6387], dtype=torch.float64), tensor([-1.5779], dtype=torch.float64), tensor([-1.5147], dtype=torch.float64), tensor([-1.4450], dtype=torch.float64), tensor([-1.6192], dtype=torch.float64), tensor([-1.5085], dtype=torch.float64), tensor([-1.6348], dtype=torch.float64), tensor([-1.5490], dtype=torch.float64), tensor([-1.6326], dtype=torch.float64), tensor([-1.6973], dtype=torch.float64), tensor([-1.6826], dtype=torch.float64), tensor([-1.8451], dtype=torch.float64), tensor([-1.6671], dtype=torch.float64), tensor([-1.6257], dtype=torch.float64), tensor([-1.7017], dtype=torch.float64), tensor([-1.7339], dtype=torch.float64), tensor([-1.7508], dtype=torch.float64), tensor([-1.8742], dtype=torch.float64), tensor([-1.9538], dtype=torch.float64), tensor([-1.8277], dtype=torch.float64), tensor([-1.7934], dtype=torch.float64), tensor([-1.7738], dtype=torch.float64), tensor([-1.9553], dtype=torch.float64), tensor([-1.9007], dtype=torch.float64), tensor([-1.8698], dtype=torch.float64), tensor([-1.8659], dtype=torch.float64), tensor([-1.8103], dtype=torch.float64), tensor([-1.8270], dtype=torch.float64), tensor([-1.7797], dtype=torch.float64), tensor([-1.7997], dtype=torch.float64), tensor([-2.0102], dtype=torch.float64), tensor([-1.8830], dtype=torch.float64), tensor([-1.8685], dtype=torch.float64), tensor([-1.8723], dtype=torch.float64), tensor([-1.8513], dtype=torch.float64), tensor([-1.8603], dtype=torch.float64), tensor([-1.8278], dtype=torch.float64), tensor([-1.8951], dtype=torch.float64), tensor([-1.8825], dtype=torch.float64), tensor([-1.8899], dtype=torch.float64), tensor([-1.9535], dtype=torch.float64), tensor([-1.8816], dtype=torch.float64), tensor([-1.9392], dtype=torch.float64), tensor([-1.8429], dtype=torch.float64), tensor([-1.8435], dtype=torch.float64), tensor([-1.7856], dtype=torch.float64), tensor([-1.7710], dtype=torch.float64), tensor([-1.7819], dtype=torch.float64), tensor([-1.7307], dtype=torch.float64), tensor([-1.9226], dtype=torch.float64), tensor([-1.7054], dtype=torch.float64), tensor([-1.7716], dtype=torch.float64), tensor([-1.8400], dtype=torch.float64), tensor([-1.9600], dtype=torch.float64), tensor([-1.9147], dtype=torch.float64), tensor([-2.0976], dtype=torch.float64), tensor([-1.9802], dtype=torch.float64), tensor([-2.0563], dtype=torch.float64), tensor([-1.9993], dtype=torch.float64), tensor([-2.0314], dtype=torch.float64), tensor([-2.0422], dtype=torch.float64), tensor([-1.9447], dtype=torch.float64), tensor([-2.0194], dtype=torch.float64), tensor([-2.0195], dtype=torch.float64), tensor([-1.9350], dtype=torch.float64), tensor([-1.9273], dtype=torch.float64), tensor([-2.1316], dtype=torch.float64), tensor([-1.9549], dtype=torch.float64), tensor([-1.9009], dtype=torch.float64), tensor([-1.8427], dtype=torch.float64), tensor([-1.8780], dtype=torch.float64), tensor([-1.9298], dtype=torch.float64), tensor([-1.8383], dtype=torch.float64), tensor([-1.8958], dtype=torch.float64), tensor([-1.9251], dtype=torch.float64), tensor([-2.0002], dtype=torch.float64), tensor([-3.0924], dtype=torch.float64), tensor([-3.3709], dtype=torch.float64), tensor([-3.2097], dtype=torch.float64), tensor([-3.2917], dtype=torch.float64), tensor([-3.1889], dtype=torch.float64), tensor([-3.2474], dtype=torch.float64), tensor([-3.2736], dtype=torch.float64), tensor([-3.2834], dtype=torch.float64), tensor([-3.2608], dtype=torch.float64), tensor([-3.1906], dtype=torch.float64), tensor([-3.1947], dtype=torch.float64), tensor([-3.3170], dtype=torch.float64), tensor([-3.1763], dtype=torch.float64), tensor([-3.2453], dtype=torch.float64), tensor([-3.2787], dtype=torch.float64), tensor([-3.3264], dtype=torch.float64), tensor([-3.7051], dtype=torch.float64), tensor([-3.3952], dtype=torch.float64), tensor([-3.7066], dtype=torch.float64), tensor([-3.4677], dtype=torch.float64), tensor([-2.9676], dtype=torch.float64), tensor([-3.4560], dtype=torch.float64), tensor([-3.4752], dtype=torch.float64), tensor([-3.5655], dtype=torch.float64), tensor([-3.5682], dtype=torch.float64), tensor([-3.5595], dtype=torch.float64), tensor([-3.6690], dtype=torch.float64), tensor([-3.8333], dtype=torch.float64), tensor([-3.7023], dtype=torch.float64), tensor([-3.9892], dtype=torch.float64), tensor([-3.7164], dtype=torch.float64), tensor([-3.8025], dtype=torch.float64), tensor([-2.4840], dtype=torch.float64), tensor([-2.2962], dtype=torch.float64), tensor([-2.5077], dtype=torch.float64), tensor([-2.3203], dtype=torch.float64), tensor([-2.2634], dtype=torch.float64), tensor([-2.2068], dtype=torch.float64), tensor([-2.2600], dtype=torch.float64), tensor([-2.2493], dtype=torch.float64), tensor([-2.2905], dtype=torch.float64), tensor([-2.2129], dtype=torch.float64), tensor([-2.2830], dtype=torch.float64), tensor([-2.4900], dtype=torch.float64), tensor([-2.3223], dtype=torch.float64), tensor([-2.2697], dtype=torch.float64), tensor([-2.4139], dtype=torch.float64), tensor([-2.3803], dtype=torch.float64), tensor([-2.2691], dtype=torch.float64), tensor([-2.3863], dtype=torch.float64), tensor([-2.4027], dtype=torch.float64), tensor([-2.3367], dtype=torch.float64), tensor([-2.3066], dtype=torch.float64), tensor([-2.3984], dtype=torch.float64), tensor([-2.5127], dtype=torch.float64), tensor([-2.5212], dtype=torch.float64), tensor([-2.4938], dtype=torch.float64), tensor([-2.7655], dtype=torch.float64), tensor([-2.6564], dtype=torch.float64), tensor([-2.6459], dtype=torch.float64), tensor([-2.9139], dtype=torch.float64), tensor([-2.6755], dtype=torch.float64), tensor([-2.7277], dtype=torch.float64), tensor([-2.7596], dtype=torch.float64), tensor([-2.8011], dtype=torch.float64), tensor([-3.0346], dtype=torch.float64), tensor([-2.7089], dtype=torch.float64), tensor([-3.0924], dtype=torch.float64), tensor([-2.8327], dtype=torch.float64), tensor([-2.8057], dtype=torch.float64), tensor([-2.8726], dtype=torch.float64), tensor([-3.0950], dtype=torch.float64), tensor([-3.0229], dtype=torch.float64), tensor([-2.9317], dtype=torch.float64), tensor([-2.8554], dtype=torch.float64), tensor([-2.9101], dtype=torch.float64), tensor([-3.1643], dtype=torch.float64), tensor([-3.2593], dtype=torch.float64), tensor([-3.1038], dtype=torch.float64), tensor([-3.2172], dtype=torch.float64), tensor([-3.0891], dtype=torch.float64), tensor([-3.2220], dtype=torch.float64), tensor([-3.1765], dtype=torch.float64), tensor([-1.6446], dtype=torch.float64), tensor([-1.6195], dtype=torch.float64), tensor([-1.6730], dtype=torch.float64), tensor([-1.6318], dtype=torch.float64), tensor([-1.6769], dtype=torch.float64), tensor([-1.6948], dtype=torch.float64), tensor([-1.5981], dtype=torch.float64), tensor([-1.6162], dtype=torch.float64), tensor([-1.6866], dtype=torch.float64), tensor([-1.7168], dtype=torch.float64), tensor([-1.8585], dtype=torch.float64), tensor([-1.6565], dtype=torch.float64), tensor([-1.7187], dtype=torch.float64), tensor([-1.6873], dtype=torch.float64), tensor([-1.6714], dtype=torch.float64), tensor([-1.6996], dtype=torch.float64), tensor([-1.7794], dtype=torch.float64), tensor([-1.8159], dtype=torch.float64), tensor([-1.7578], dtype=torch.float64), tensor([-1.6717], dtype=torch.float64), tensor([-1.5923], dtype=torch.float64), tensor([-1.5912], dtype=torch.float64), tensor([-1.6754], dtype=torch.float64), tensor([-1.6189], dtype=torch.float64), tensor([-1.6808], dtype=torch.float64), tensor([-1.6593], dtype=torch.float64), tensor([-1.6682], dtype=torch.float64), tensor([-1.5632], dtype=torch.float64), tensor([-1.5937], dtype=torch.float64), tensor([-1.5686], dtype=torch.float64), tensor([-1.7497], dtype=torch.float64), tensor([-1.6432], dtype=torch.float64), tensor([-1.7073], dtype=torch.float64), tensor([-1.6428], dtype=torch.float64), tensor([-1.6586], dtype=torch.float64), tensor([-1.6744], dtype=torch.float64), tensor([-1.6387], dtype=torch.float64), tensor([-1.6893], dtype=torch.float64), tensor([-1.5617], dtype=torch.float64), tensor([-1.6193], dtype=torch.float64), tensor([-1.6771], dtype=torch.float64), tensor([-1.7539], dtype=torch.float64), tensor([-1.7370], dtype=torch.float64), tensor([-1.6735], dtype=torch.float64), tensor([-1.6206], dtype=torch.float64), tensor([-1.6020], dtype=torch.float64), tensor([-1.5382], dtype=torch.float64), tensor([-1.5640], dtype=torch.float64), tensor([-1.5800], dtype=torch.float64), tensor([-1.5810], dtype=torch.float64), tensor([-1.5293], dtype=torch.float64), tensor([-1.5760], dtype=torch.float64), tensor([-1.6098], dtype=torch.float64), tensor([-1.5248], dtype=torch.float64), tensor([-1.5244], dtype=torch.float64), tensor([-1.4990], dtype=torch.float64), tensor([-1.4133], dtype=torch.float64), tensor([-1.3595], dtype=torch.float64), tensor([-1.4388], dtype=torch.float64), tensor([-1.3155], dtype=torch.float64), tensor([-1.2783], dtype=torch.float64), tensor([-1.2934], dtype=torch.float64), tensor([-1.4574], dtype=torch.float64), tensor([-1.3434], dtype=torch.float64), tensor([-1.3793], dtype=torch.float64), tensor([-1.4082], dtype=torch.float64), tensor([-1.4832], dtype=torch.float64), tensor([-1.4111], dtype=torch.float64), tensor([-1.4360], dtype=torch.float64), tensor([-1.4273], dtype=torch.float64), tensor([-1.4729], dtype=torch.float64), tensor([-1.4207], dtype=torch.float64), tensor([-1.4327], dtype=torch.float64), tensor([-1.4078], dtype=torch.float64), tensor([-1.3664], dtype=torch.float64), tensor([-1.3091], dtype=torch.float64), tensor([-1.3149], dtype=torch.float64), tensor([-1.3198], dtype=torch.float64), tensor([-1.2871], dtype=torch.float64), tensor([-1.2272], dtype=torch.float64), tensor([-1.1419], dtype=torch.float64), tensor([-1.1052], dtype=torch.float64), tensor([-1.1464], dtype=torch.float64), tensor([-1.1355], dtype=torch.float64), tensor([-1.2135], dtype=torch.float64), tensor([-1.1973], dtype=torch.float64), tensor([-1.2081], dtype=torch.float64), tensor([-1.2550], dtype=torch.float64), tensor([-1.1996], dtype=torch.float64), tensor([-1.1211], dtype=torch.float64), tensor([-1.1855], dtype=torch.float64), tensor([-1.2288], dtype=torch.float64), tensor([-1.1884], dtype=torch.float64), tensor([-1.3679], dtype=torch.float64), tensor([-1.4119], dtype=torch.float64), tensor([-1.3214], dtype=torch.float64), tensor([-1.4454], dtype=torch.float64), tensor([-1.3263], dtype=torch.float64), tensor([-1.2809], dtype=torch.float64), tensor([-1.2665], dtype=torch.float64), tensor([-1.2893], dtype=torch.float64), tensor([-1.2320], dtype=torch.float64), tensor([-1.2401], dtype=torch.float64), tensor([-1.2807], dtype=torch.float64), tensor([-1.3477], dtype=torch.float64), tensor([-1.3636], dtype=torch.float64), tensor([-1.4633], dtype=torch.float64), tensor([-1.3268], dtype=torch.float64), tensor([-1.3748], dtype=torch.float64), tensor([-1.3930], dtype=torch.float64), tensor([-1.4369], dtype=torch.float64), tensor([-1.4214], dtype=torch.float64), tensor([-1.4710], dtype=torch.float64), tensor([-1.3650], dtype=torch.float64), tensor([-1.2953], dtype=torch.float64), tensor([-1.3029], dtype=torch.float64), tensor([-1.2548], dtype=torch.float64), tensor([-1.1587], dtype=torch.float64), tensor([-1.1722], dtype=torch.float64), tensor([-1.2306], dtype=torch.float64), tensor([-1.3621], dtype=torch.float64), tensor([-1.2930], dtype=torch.float64), tensor([-1.2991], dtype=torch.float64), tensor([-1.3638], dtype=torch.float64), tensor([-1.3171], dtype=torch.float64), tensor([-1.3266], dtype=torch.float64), tensor([-1.2184], dtype=torch.float64), tensor([-1.2113], dtype=torch.float64), tensor([-1.1839], dtype=torch.float64), tensor([-1.1005], dtype=torch.float64), tensor([-1.1008], dtype=torch.float64), tensor([-1.1279], dtype=torch.float64), tensor([-1.1117], dtype=torch.float64), tensor([-1.1393], dtype=torch.float64), tensor([-1.1723], dtype=torch.float64), tensor([-1.2381], dtype=torch.float64), tensor([-1.2109], dtype=torch.float64), tensor([-1.2222], dtype=torch.float64), tensor([-1.3125], dtype=torch.float64), tensor([-1.2148], dtype=torch.float64), tensor([-1.1442], dtype=torch.float64), tensor([-1.1161], dtype=torch.float64), tensor([-1.1785], dtype=torch.float64), tensor([-1.0210], dtype=torch.float64), tensor([-1.0009], dtype=torch.float64), tensor([-1.0194], dtype=torch.float64), tensor([-0.9440], dtype=torch.float64), tensor([-0.9138], dtype=torch.float64), tensor([-0.8603], dtype=torch.float64), tensor([-0.8189], dtype=torch.float64), tensor([-0.7480], dtype=torch.float64), tensor([-0.6717], dtype=torch.float64), tensor([-0.6436], dtype=torch.float64), tensor([-0.5601], dtype=torch.float64), tensor([1.0747], dtype=torch.float64), tensor([1.0300], dtype=torch.float64), tensor([1.0129], dtype=torch.float64), tensor([1.1102], dtype=torch.float64), tensor([1.0170], dtype=torch.float64), tensor([1.0774], dtype=torch.float64), tensor([1.2925], dtype=torch.float64), tensor([1.1484], dtype=torch.float64), tensor([0.0795], dtype=torch.float64), tensor([0.0318], dtype=torch.float64), tensor([-0.0110], dtype=torch.float64), tensor([-0.0545], dtype=torch.float64), tensor([-0.1042], dtype=torch.float64), tensor([-0.1525], dtype=torch.float64), tensor([-0.1682], dtype=torch.float64), tensor([-0.1216], dtype=torch.float64), tensor([-0.1690], dtype=torch.float64), tensor([-0.2094], dtype=torch.float64), tensor([-0.2793], dtype=torch.float64), tensor([-0.1973], dtype=torch.float64), tensor([-0.2583], dtype=torch.float64), tensor([-0.2830], dtype=torch.float64), tensor([-0.3310], dtype=torch.float64), tensor([-0.3815], dtype=torch.float64), tensor([-0.4521], dtype=torch.float64), tensor([-0.4642], dtype=torch.float64), tensor([-0.5159], dtype=torch.float64), tensor([-0.4562], dtype=torch.float64), tensor([-0.5062], dtype=torch.float64), tensor([-0.4458], dtype=torch.float64), tensor([1.0952], dtype=torch.float64), tensor([1.1524], dtype=torch.float64), tensor([1.2010], dtype=torch.float64), tensor([1.2835], dtype=torch.float64), tensor([1.5378], dtype=torch.float64), tensor([1.4130], dtype=torch.float64), tensor([1.3630], dtype=torch.float64), tensor([1.4628], dtype=torch.float64), tensor([1.4430], dtype=torch.float64), tensor([1.3601], dtype=torch.float64), tensor([1.3821], dtype=torch.float64), tensor([1.4890], dtype=torch.float64), tensor([1.5925], dtype=torch.float64), tensor([1.7214], dtype=torch.float64), tensor([1.8035], dtype=torch.float64), tensor([1.6592], dtype=torch.float64), tensor([1.7785], dtype=torch.float64), tensor([1.5978], dtype=torch.float64), tensor([1.6116], dtype=torch.float64), tensor([1.7486], dtype=torch.float64), tensor([1.7751], dtype=torch.float64), tensor([1.8366], dtype=torch.float64), tensor([2.0598], dtype=torch.float64), tensor([2.1682], dtype=torch.float64), tensor([1.8644], dtype=torch.float64), tensor([2.2074], dtype=torch.float64), tensor([1.9233], dtype=torch.float64), tensor([2.0107], dtype=torch.float64), tensor([2.4135], dtype=torch.float64), tensor([2.1351], dtype=torch.float64), tensor([2.1877], dtype=torch.float64), tensor([2.3724], dtype=torch.float64), tensor([2.4174], dtype=torch.float64), tensor([2.3743], dtype=torch.float64), tensor([2.5691], dtype=torch.float64), tensor([2.7179], dtype=torch.float64), tensor([2.7544], dtype=torch.float64), tensor([2.6506], dtype=torch.float64), tensor([1.5351], dtype=torch.float64), tensor([1.6854], dtype=torch.float64), tensor([1.7263], dtype=torch.float64), tensor([1.7442], dtype=torch.float64), tensor([1.8120], dtype=torch.float64), tensor([2.1710], dtype=torch.float64), tensor([1.9163], dtype=torch.float64), tensor([1.9589], dtype=torch.float64), tensor([2.0583], dtype=torch.float64), tensor([2.2216], dtype=torch.float64), tensor([2.5187], dtype=torch.float64), tensor([2.2938], dtype=torch.float64), tensor([2.3424], dtype=torch.float64), tensor([2.6586], dtype=torch.float64), tensor([2.4783], dtype=torch.float64), tensor([2.6063], dtype=torch.float64), tensor([2.4672], dtype=torch.float64), tensor([2.4904], dtype=torch.float64), tensor([2.6889], dtype=torch.float64), tensor([2.6788], dtype=torch.float64), tensor([2.7815], dtype=torch.float64), tensor([2.7978], dtype=torch.float64), tensor([2.8035], dtype=torch.float64), tensor([2.6801], dtype=torch.float64), tensor([2.7450], dtype=torch.float64), tensor([2.8278], dtype=torch.float64), tensor([2.9322], dtype=torch.float64), tensor([3.0990], dtype=torch.float64), tensor([3.1199], dtype=torch.float64), tensor([3.0591], dtype=torch.float64), tensor([3.0904], dtype=torch.float64), tensor([3.0950], dtype=torch.float64), tensor([3.1154], dtype=torch.float64), tensor([2.9933], dtype=torch.float64), tensor([3.2865], dtype=torch.float64), tensor([3.2110], dtype=torch.float64), tensor([3.4336], dtype=torch.float64), tensor([3.2574], dtype=torch.float64), tensor([3.1726], dtype=torch.float64), tensor([3.3050], dtype=torch.float64), tensor([3.6404], dtype=torch.float64), tensor([3.5123], dtype=torch.float64), tensor([3.4139], dtype=torch.float64), tensor([3.9098], dtype=torch.float64), tensor([3.5467], dtype=torch.float64), tensor([3.8825], dtype=torch.float64), tensor([3.5953], dtype=torch.float64), tensor([4.0948], dtype=torch.float64), tensor([3.6453], dtype=torch.float64), tensor([3.6746], dtype=torch.float64), tensor([3.8745], dtype=torch.float64), tensor([3.8564], dtype=torch.float64), tensor([4.0683], dtype=torch.float64), tensor([3.0928], dtype=torch.float64), tensor([2.9548], dtype=torch.float64), tensor([3.0818], dtype=torch.float64), tensor([3.0428], dtype=torch.float64), tensor([3.2135], dtype=torch.float64), tensor([3.2127], dtype=torch.float64), tensor([3.2455], dtype=torch.float64), tensor([3.3534], dtype=torch.float64), tensor([3.5024], dtype=torch.float64), tensor([3.6400], dtype=torch.float64), tensor([3.6339], dtype=torch.float64), tensor([2.3804], dtype=torch.float64), tensor([2.6036], dtype=torch.float64), tensor([2.5729], dtype=torch.float64), tensor([2.6394], dtype=torch.float64), tensor([2.9517], dtype=torch.float64), tensor([2.6623], dtype=torch.float64), tensor([2.6942], dtype=torch.float64), tensor([2.9602], dtype=torch.float64), tensor([3.1835], dtype=torch.float64), tensor([3.1201], dtype=torch.float64), tensor([2.9068], dtype=torch.float64), tensor([2.8196], dtype=torch.float64), tensor([2.9790], dtype=torch.float64), tensor([3.0222], dtype=torch.float64), tensor([2.9728], dtype=torch.float64), tensor([3.1220], dtype=torch.float64), tensor([3.3322], dtype=torch.float64), tensor([3.3939], dtype=torch.float64), tensor([3.5813], dtype=torch.float64), tensor([3.3575], dtype=torch.float64), tensor([3.2592], dtype=torch.float64), tensor([3.5509], dtype=torch.float64), tensor([3.3690], dtype=torch.float64), tensor([3.4443], dtype=torch.float64), tensor([4.0400], dtype=torch.float64), tensor([3.6064], dtype=torch.float64), tensor([3.7697], dtype=torch.float64), tensor([3.6714], dtype=torch.float64), tensor([4.0885], dtype=torch.float64), tensor([3.8690], dtype=torch.float64), tensor([3.7870], dtype=torch.float64), tensor([3.8285], dtype=torch.float64), tensor([2.8914], dtype=torch.float64), tensor([3.2054], dtype=torch.float64), tensor([2.9726], dtype=torch.float64), tensor([2.8763], dtype=torch.float64), tensor([2.8619], dtype=torch.float64), tensor([2.9707], dtype=torch.float64), tensor([3.1170], dtype=torch.float64), tensor([3.3768], dtype=torch.float64), tensor([3.0465], dtype=torch.float64), tensor([3.2380], dtype=torch.float64), tensor([2.8344], dtype=torch.float64), tensor([3.1183], dtype=torch.float64), tensor([3.1056], dtype=torch.float64), tensor([3.0540], dtype=torch.float64), tensor([3.2906], dtype=torch.float64), tensor([3.3569], dtype=torch.float64), tensor([3.2352], dtype=torch.float64), tensor([3.7756], dtype=torch.float64), tensor([3.4524], dtype=torch.float64), tensor([3.4234], dtype=torch.float64), tensor([3.4984], dtype=torch.float64), tensor([3.5993], dtype=torch.float64), tensor([2.3494], dtype=torch.float64), tensor([2.5866], dtype=torch.float64), tensor([2.5581], dtype=torch.float64), tensor([2.5396], dtype=torch.float64), tensor([2.7035], dtype=torch.float64), tensor([2.7362], dtype=torch.float64), tensor([2.5629], dtype=torch.float64), tensor([1.7555], dtype=torch.float64), tensor([1.7254], dtype=torch.float64), tensor([1.5195], dtype=torch.float64), tensor([1.6205], dtype=torch.float64), tensor([1.7424], dtype=torch.float64), tensor([1.6559], dtype=torch.float64), tensor([1.6913], dtype=torch.float64), tensor([2.0177], dtype=torch.float64), tensor([1.8174], dtype=torch.float64), tensor([2.1005], dtype=torch.float64), tensor([1.8080], dtype=torch.float64), tensor([1.9645], dtype=torch.float64), tensor([1.9380], dtype=torch.float64), tensor([1.9241], dtype=torch.float64), tensor([2.0581], dtype=torch.float64), tensor([2.1585], dtype=torch.float64), tensor([1.9320], dtype=torch.float64), tensor([2.0414], dtype=torch.float64), tensor([2.1374], dtype=torch.float64), tensor([2.0763], dtype=torch.float64), tensor([2.0827], dtype=torch.float64), tensor([2.0503], dtype=torch.float64), tensor([2.1638], dtype=torch.float64), tensor([2.2440], dtype=torch.float64), tensor([2.1215], dtype=torch.float64), tensor([2.3568], dtype=torch.float64), tensor([2.4629], dtype=torch.float64), tensor([2.2999], dtype=torch.float64), tensor([2.2558], dtype=torch.float64), tensor([2.4273], dtype=torch.float64), tensor([2.1309], dtype=torch.float64), tensor([2.2033], dtype=torch.float64), tensor([2.3619], dtype=torch.float64), tensor([2.3721], dtype=torch.float64), tensor([2.4547], dtype=torch.float64), tensor([2.3234], dtype=torch.float64), tensor([2.3878], dtype=torch.float64), tensor([2.7035], dtype=torch.float64), tensor([2.5750], dtype=torch.float64), tensor([2.4587], dtype=torch.float64), tensor([2.3625], dtype=torch.float64), tensor([2.5534], dtype=torch.float64), tensor([2.3731], dtype=torch.float64), tensor([2.5623], dtype=torch.float64), tensor([2.5896], dtype=torch.float64), tensor([2.6200], dtype=torch.float64), tensor([2.5753], dtype=torch.float64), tensor([2.5567], dtype=torch.float64), tensor([2.8369], dtype=torch.float64), tensor([2.8160], dtype=torch.float64), tensor([2.8241], dtype=torch.float64), tensor([2.5945], dtype=torch.float64), tensor([2.7871], dtype=torch.float64), tensor([2.5598], dtype=torch.float64), tensor([2.6867], dtype=torch.float64), tensor([2.7048], dtype=torch.float64), tensor([2.6457], dtype=torch.float64), tensor([2.9778], dtype=torch.float64), tensor([2.6688], dtype=torch.float64), tensor([1.0831], dtype=torch.float64), tensor([1.1340], dtype=torch.float64), tensor([1.0132], dtype=torch.float64), tensor([0.9398], dtype=torch.float64), tensor([1.0043], dtype=torch.float64), tensor([1.1138], dtype=torch.float64), tensor([1.3172], dtype=torch.float64), tensor([1.1718], dtype=torch.float64), tensor([1.3598], dtype=torch.float64), tensor([1.2124], dtype=torch.float64), tensor([1.1317], dtype=torch.float64), tensor([1.2840], dtype=torch.float64), tensor([1.1727], dtype=torch.float64), tensor([1.2833], dtype=torch.float64), tensor([1.4030], dtype=torch.float64), tensor([1.3730], dtype=torch.float64), tensor([1.4469], dtype=torch.float64), tensor([1.2933], dtype=torch.float64), tensor([1.3716], dtype=torch.float64), tensor([1.3736], dtype=torch.float64), tensor([1.2663], dtype=torch.float64), tensor([1.4218], dtype=torch.float64), tensor([1.2980], dtype=torch.float64), tensor([1.4405], dtype=torch.float64), tensor([1.5063], dtype=torch.float64), tensor([1.6168], dtype=torch.float64), tensor([1.7114], dtype=torch.float64), tensor([1.4954], dtype=torch.float64), tensor([1.5760], dtype=torch.float64), tensor([1.7126], dtype=torch.float64), tensor([1.6287], dtype=torch.float64), tensor([1.7955], dtype=torch.float64), tensor([1.7331], dtype=torch.float64), tensor([2.0174], dtype=torch.float64), tensor([1.7588], dtype=torch.float64), tensor([1.8268], dtype=torch.float64), tensor([2.0101], dtype=torch.float64), tensor([1.7636], dtype=torch.float64), tensor([2.0157], dtype=torch.float64), tensor([2.1014], dtype=torch.float64), tensor([2.2127], dtype=torch.float64), tensor([2.0657], dtype=torch.float64), tensor([2.2937], dtype=torch.float64), tensor([2.2789], dtype=torch.float64), tensor([2.1901], dtype=torch.float64), tensor([2.3303], dtype=torch.float64), tensor([2.2608], dtype=torch.float64), tensor([2.2560], dtype=torch.float64), tensor([2.3747], dtype=torch.float64), tensor([2.4711], dtype=torch.float64), tensor([2.4089], dtype=torch.float64), tensor([2.4416], dtype=torch.float64)]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 117\u001b[0m\n\u001b[0;32m    115\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m    116\u001b[0m loss \u001b[38;5;241m=\u001b[39m episode_losss\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m--> 117\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m    120\u001b[0m model\u001b[38;5;241m.\u001b[39mlog_probss\u001b[38;5;241m.\u001b[39mclear()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "\n",
    "n_episodes = 100\n",
    "last_i = 0\n",
    "env = gym.make(\n",
    "    'ALE/DemonAttack-v5', # alternate games can be chosen here \n",
    "    obs_type='grayscale', # saves RGB preprocessing reduction\n",
    "    render_mode='human' if render else None, # rendering shows popup but limits training speed\n",
    ")\n",
    "        \n",
    "if record_rewards:\n",
    "    reward_list = list()\n",
    "if record_probs:\n",
    "    prob_list = list()\n",
    "if record_eps_iters:\n",
    "    eps_iters_list = list()\n",
    "\n",
    "model = TwoLayerReinforcement(DIM, 64, 6).double()\n",
    "criterion = AtariReward()\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=0.001)\n",
    "\n",
    "def process_probs(probs, i, last_i, timer_i=1000, corner_correct=True):\n",
    "    initial_shape = probs.shape\n",
    "    i_since_r = i - last_i\n",
    "    if i_since_r > timer_i:\n",
    "        terminated = True\n",
    "        truncated = False\n",
    "        print('Timer causing reset               ')\n",
    "    else:\n",
    "        terminated = False\n",
    "        truncated = False\n",
    "        \n",
    "    if corner_correct: # heavily biases agent from getting 'stuck' in corner\n",
    "        probs = add_noise(probs, i, i_since_r, timer_i)\n",
    "        probs = balance_lr(probs, i_since_r, timer_i)\n",
    "\n",
    "    if torch.round(torch.sum(probs), decimals=4) != 1:\n",
    "        warnings.warn(str(probs) + ' | ' + str(torch.sum(probs)) + ' != 1')\n",
    "        probs /= torch.sum(probs)\n",
    "        \n",
    "    assert probs.shape == initial_shape\n",
    "    return probs, i, terminated, truncated\n",
    "\n",
    "eps = np.finfo(np.float32).eps.item()\n",
    "episode_number = 0\n",
    "prev_lives = 0\n",
    "i = 0\n",
    "obs, info = env.reset()\n",
    "while episode_number <= n_episodes:\n",
    "    curr_x = preprocess(obs, downsample=DOWNSAMPLE, xmin=XMIN, xmax=XMAX, ymin=YMIN, ymax=YMAX)\n",
    "    x = curr_x - prev_x if prev_x is not None else np.zeros(DIM) # only monitor change between frames\n",
    "#     xs.append(x)\n",
    "\n",
    "    prev_x = curr_x\n",
    "\n",
    "    model_probs = model(x) # autograd performed here\n",
    "    probs, last_i, terminated, truncated = process_probs(model_probs, i, last_i, timer_i=timer_i, corner_correct=corner_correct)\n",
    "    \n",
    "    m = torch.distributions.Categorical(probs)\n",
    "    action = m.sample()\n",
    "    log_probs = m.log_prob(action)\n",
    "    model.log_probss.append(log_probs)\n",
    "    action = action.item()\n",
    "    \n",
    "    ######################################################################################\n",
    "    # fold this into model\n",
    "    # fix log probs here\n",
    "    # https://github.com/pytorch/examples/blob/main/reinforcement_learning/reinforce.py\n",
    "    # log_prob = prob.clamp(min=1e-6).log()\n",
    "    # entropy = - (probs * probs.clamp(min=1e-6).log()).sum()\n",
    "    # https://discuss.pytorch.org/t/policy-gradient-using-loss-as-reward/13877\n",
    "    ######################################################################################\n",
    "    \n",
    "    prev_lives = info['lives'] # lives not available through general step return\n",
    "    obs, reward, terminated, truncated, info = env.step(action) # step returns all other relevant information \n",
    "    if reward > 0: # reset the iterations since last reward if reward is accrued\n",
    "        last_i = i\n",
    "\n",
    "    reward_sum += reward # total round reward incremented\n",
    "    adj_reward = modify_reward(action, reward, info, prev_lives) # adjusted reward may better lead agent toward short term optimums\n",
    "    adj_reward_sum += adj_reward\n",
    "\n",
    "    model.rewards.append(adj_reward)\n",
    "    print(len(model.log_probss))\n",
    "    print(len(model.rewards))\n",
    "    ######################################################\n",
    "\n",
    "    if terminated: # an episode finished\n",
    "        episode_number += 1\n",
    "#         print(f'Episode: {episode_number}              ')\n",
    "\n",
    "        if record_rewards:\n",
    "            reward_list.append(reward_sum)\n",
    "        if record_eps_iters:\n",
    "            eps_iters_list.append(i)\n",
    "        \n",
    "        # stack together all inputs, hidden states, action gradients, and rewards for this episode\n",
    "        if not no_grad:\n",
    "            print('$$', model.log_probss)\n",
    "            print('%%', model.rewards)\n",
    "\n",
    "#             epdlogp = -torch.cat(model.log_probss, dim=0)\n",
    "#             epr = torch.cat(model.rewards, dim=0)\n",
    "\n",
    "#             discounted_epr = standardize(discount_rewards(epr))\n",
    "            def standardize(returns):\n",
    "                returns -= returns.mean()\n",
    "                returns /= (returns.std() + eps)\n",
    "                return returns\n",
    "\n",
    "            returns = torch.tensor(discount_rewards(model.rewards))\n",
    "            returns = standardize(returns)\n",
    "            episode_losss = [(-log_prob * r).unsqueeze(dim=0) for log_prob, r in zip(model.log_probss, returns)]\n",
    "            print(episode_losss)\n",
    "            episode_losss = torch.cat(episode_losss)\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "            loss = episode_losss.sum()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            model.log_probss.clear()\n",
    "            model.rewards.clear()\n",
    "\n",
    "        reward_sum = 0 # reset all totals\n",
    "        adj_reward_sum = 0\n",
    "        \n",
    "        obs, info = env.reset() # reset env\n",
    "        prev_x = None\n",
    "    elif truncated: # an episode terminated unexpectedly, shouldn't maintain results\n",
    "        model.log_probss.clear()\n",
    "        model.rewards.clear()\n",
    "        \n",
    "        reward_sum = 0\n",
    "        adj_reward_sum = 0\n",
    "        \n",
    "        obs, info = env.reset()\n",
    "        prev_x = None\n",
    "    \n",
    "\n",
    "        \n",
    "    if not i % 100:\n",
    "        print(f'Episode {episode_number} of {n_episodes} episodes                ', end='\\r')\n",
    "        torch.save(model, save_path)\n",
    "    i += 1\n",
    "\n",
    "env.close()\n",
    "prob_list = model.log_probss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299817c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_probs(prob_list, eps_iters_list, batch_size=64, step=1):\n",
    "    probs_arr = torch.vstack(prob_list).detach().numpy()\n",
    "    fig, axs = plt.subplots(nrows=3, ncols=2, figsize=(16,12), dpi=200, sharex=True, sharey=True)\n",
    "    fig.suptitle('Single Episode Action Probabilities')\n",
    "    colors = sns.color_palette('Spectral', 7)\n",
    "    colors = colors[:3] + colors[4:]\n",
    "    for i, (ax, color) in enumerate(zip(axs.flatten(), colors)):\n",
    "        sns.lineplot(data=probs_arr[::step,i], color=color, label=action_dict[i], alpha=.7, dashes=False, ax=ax)\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Probability')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "if record_probs:\n",
    "    plot_probs(prob_list, eps_iters_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111d293d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(a, window_size) :\n",
    "    ret = np.cumsum(a, dtype=float)\n",
    "    ret[window_size:] = ret[window_size:] - ret[:-window_size]\n",
    "    return ret[window_size - 1:] / window_size\n",
    "\n",
    "def plot_rewards(reward_list, window_size=10):\n",
    "    plt.figure(figsize=(16,5))\n",
    "    plt.title('Rewards Over Time')\n",
    "    plt.ylabel('Total Reward')\n",
    "    plt.xlabel('Episode Number')\n",
    "    x = np.arange(0, len(reward_list), 1)\n",
    "    assert len(x) == len(reward_list)\n",
    "    plt.plot(x, reward_list, color='black', linestyle='dashed', label='Reward Per Episode')\n",
    "    plt.plot(x[window_size-1:], moving_average(reward_list, window_size), color='red', label='Reward Moving Average')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "print(reward_list)\n",
    "if record_rewards:\n",
    "    plot_rewards(reward_list, window_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cc5c3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
